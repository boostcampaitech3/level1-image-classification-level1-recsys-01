{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, random_split, SubsetRandomSampler, DataLoader\n",
    "from typing import Callable, Optional, Any\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard logs, model.state_dict() saved PATH & DIRECTORY\n",
    "\n",
    "tensorboard_saved_dir = 'logs'\n",
    "param_saved_dir = 'saved'\n",
    "\n",
    "os.makedirs(tensorboard_saved_dir, exist_ok=True)\n",
    "os.makedirs(param_saved_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>file_name</th>\n",
       "      <th>absolute_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>incorrect_mask.jpg</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000001</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>mask4.jpg</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000001</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>mask2.jpg</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000001</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>mask1.jpg</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000001</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>mask3.jpg</td>\n",
       "      <td>/opt/ml/input/data/train/images/000001_female_...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                    path           file_name  \\\n",
       "0  000001  000001_female_Asian_45  incorrect_mask.jpg   \n",
       "1  000001  000001_female_Asian_45           mask4.jpg   \n",
       "2  000001  000001_female_Asian_45           mask2.jpg   \n",
       "3  000001  000001_female_Asian_45           mask1.jpg   \n",
       "4  000001  000001_female_Asian_45           mask3.jpg   \n",
       "\n",
       "                                       absolute_path  label  \n",
       "0  /opt/ml/input/data/train/images/000001_female_...     10  \n",
       "1  /opt/ml/input/data/train/images/000001_female_...      4  \n",
       "2  /opt/ml/input/data/train/images/000001_female_...      4  \n",
       "3  /opt/ml/input/data/train/images/000001_female_...      4  \n",
       "4  /opt/ml/input/data/train/images/000001_female_...      4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data path\n",
    "train_data_path = '/opt/ml/code/dataset'\n",
    "\n",
    "train_csv = pd.read_csv(os.path.join(train_data_path, 'image_label.csv'))\n",
    "\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDataset(Dataset):\n",
    "\n",
    "    def __init__(self,table,transform:Optional[callable]=None):\n",
    "        self.table = table\n",
    "        self.transform = transform\n",
    "\n",
    "        self.x, self.y = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        x,y = [],[]\n",
    "        for i in tqdm(range(len(self.table))):\n",
    "            im = Image.open(self.table['absolute_path'][i])\n",
    "\n",
    "            if self.transform:\n",
    "                im = self.transform(im)\n",
    "            \n",
    "            x.append(im)\n",
    "            y.append(torch.tensor(self.table['label'][i]))\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.CenterCrop(150),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18900/18900 [02:07<00:00, 147.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# make dataset\n",
    "\n",
    "mask_dataset = MaskDataset(train_csv, image_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified KFold 설정\n",
    "\n",
    "k = 5\n",
    "skfold = StratifiedKFold(n_splits=k, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 함수\n",
    "def model_train(model,device,dataloader,criterion, optimizer):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    acc, f1,losses = 0,0,0\n",
    "    for x,y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss = criterion(y_pred,y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        y = y.flatten().to('cpu').detach().numpy()\n",
    "        y_pred = torch.argmax(y_pred,dim=-1).to('cpu').detach().numpy()\n",
    "        acc += accuracy_score(y,y_pred)\n",
    "        f1 += f1_score(y,y_pred,average='macro')\n",
    "        losses += loss\n",
    "    return acc / len(dataloader), f1 / len(dataloader), loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate 함수\n",
    "def model_val(model,device,dataloader,criterion):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    acc, f1,losses = 0,0,0\n",
    "    with torch.no_grad():\n",
    "        for x,y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "\n",
    "            loss = criterion(y_pred,y)\n",
    "\n",
    "            y = y.flatten().to('cpu').detach().numpy()\n",
    "            y_pred = torch.argmax(y_pred,dim=-1).to('cpu').detach().numpy()\n",
    "            acc += accuracy_score(y,y_pred)\n",
    "            f1 += f1_score(y,y_pred,average='macro')\n",
    "            losses += loss\n",
    "    return acc / len(dataloader), f1 / len(dataloader), loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskResNet18,self).__init__()\n",
    "        self.resnet18 = models.resnet18(pretrained=True)\n",
    "        self.resnet18.fc = nn.Linear(in_features=128,out_features=18)\n",
    "\n",
    "    def frozen(self):\n",
    "        for param in self.resnet18.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.resnet18.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def unfrozen(self):\n",
    "        for param in self.resnet18.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet18.conv1(x)\n",
    "        x = self.resnet18.bn1(x)\n",
    "        x = self.resnet18.relu(x)\n",
    "        x = self.resnet18.maxpool(x)\n",
    "        x = self.resnet18.layer1(x)\n",
    "        x = self.resnet18.layer2(x)\n",
    "        x = self.resnet18.avgpool(x)\n",
    "\n",
    "        x = x.flatten(1)\n",
    "        x = self.resnet18.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = MaskResNet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(tensorboard_saved_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "EPOCH: 0 train_acc: 0.43974867724867706, train_f1: 0.1703040245563125, loss: 0.003077421337366104\n",
      "EPOCH: 0 val_acc:0.5276455026455024, val_f1:0.2251404051101525, loss: 0.0022668696474283934\n",
      "EPOCH: 1 train_acc: 0.6146164021164007, train_f1: 0.3202116809145975, loss: 0.0016764879692345858\n",
      "EPOCH: 1 val_acc:0.698544973544973, val_f1:0.43257243520383065, loss: 0.002298537874594331\n",
      "EPOCH: 2 train_acc: 0.7306878306878306, train_f1: 0.4931482978913052, loss: 0.0011985249584540725\n",
      "EPOCH: 2 val_acc:0.7545634920634925, val_f1:0.5542364661206166, loss: 0.0018170926487073302\n",
      "EPOCH: 3 train_acc: 0.8179894179894175, train_f1: 0.63740022514339, loss: 0.0011417614296078682\n",
      "EPOCH: 3 val_acc:0.8660052910052901, val_f1:0.7188184541647106, loss: 0.001402572263032198\n",
      "EPOCH: 4 train_acc: 0.8534391534391527, train_f1: 0.7038131449170523, loss: 0.0014214685652405024\n",
      "EPOCH: 4 val_acc:0.8608465608465595, val_f1:0.7265722890957965, loss: 0.0014630734222009778\n",
      "EPOCH: 5 train_acc: 0.8769841269841255, train_f1: 0.7397804302817906, loss: 0.0008554051746614277\n",
      "EPOCH: 5 val_acc:0.8884920634920614, val_f1:0.7645549320563567, loss: 0.0006629795534536242\n",
      "EPOCH: 6 train_acc: 0.8923941798941784, train_f1: 0.7702616532030142, loss: 0.0007886055391281843\n",
      "EPOCH: 6 val_acc:0.9057539682539658, val_f1:0.7790055567297657, loss: 0.0005629102815873921\n",
      "EPOCH: 7 train_acc: 0.904894179894177, train_f1: 0.7917022634697846, loss: 0.0006083862390369177\n",
      "EPOCH: 7 val_acc:0.9109126984126947, val_f1:0.8057583698860846, loss: 0.00048196734860539436\n",
      "EPOCH: 8 train_acc: 0.9170634920634896, train_f1: 0.8136818328076851, loss: 0.0004984424449503422\n",
      "EPOCH: 8 val_acc:0.920238095238092, val_f1:0.8301743253809336, loss: 0.00048813820467330515\n",
      "EPOCH: 9 train_acc: 0.9275793650793613, train_f1: 0.8310299981498104, loss: 0.0006821650895290077\n",
      "EPOCH: 9 val_acc:0.9411375661375624, val_f1:0.8595220448475237, loss: 0.00041980930836871266\n",
      "Fold 2\n",
      "EPOCH: 0 train_acc: 0.9303571428571402, train_f1: 0.8451505663233155, loss: 0.0002052133932011202\n",
      "EPOCH: 0 val_acc:0.9115079365079333, val_f1:0.8044332256674004, loss: 0.0005066962330602109\n",
      "EPOCH: 1 train_acc: 0.9448412698412658, train_f1: 0.8727460291764255, loss: 0.00039257912430912256\n",
      "EPOCH: 1 val_acc:0.943783068783066, val_f1:0.8625087134254055, loss: 0.0006473557441495359\n",
      "EPOCH: 2 train_acc: 0.9504629629629592, train_f1: 0.886029284567648, loss: 0.00031218407093547285\n",
      "EPOCH: 2 val_acc:0.954100529100526, val_f1:0.9015509477083978, loss: 0.00032252815435640514\n",
      "EPOCH: 3 train_acc: 0.9601851851851807, train_f1: 0.9100231777945328, loss: 0.00018901305156759918\n",
      "EPOCH: 3 val_acc:0.9731481481481438, val_f1:0.924830860275536, loss: 0.0002599801809992641\n",
      "EPOCH: 4 train_acc: 0.9682539682539638, train_f1: 0.9250308682489126, loss: 0.00028017209842801094\n",
      "EPOCH: 4 val_acc:0.974801587301584, val_f1:0.9309624497135571, loss: 8.947822061600164e-05\n",
      "EPOCH: 5 train_acc: 0.9732142857142825, train_f1: 0.9348454734207848, loss: 0.0002589664072729647\n",
      "EPOCH: 5 val_acc:0.9851851851851817, val_f1:0.9591309459931101, loss: 0.00021767604630440474\n",
      "EPOCH: 6 train_acc: 0.9771164021163984, train_f1: 0.9471606427632095, loss: 0.0003093351551797241\n",
      "EPOCH: 6 val_acc:0.9767857142857107, val_f1:0.9498470894121809, loss: 0.0002584810135886073\n",
      "EPOCH: 7 train_acc: 0.9814153439153404, train_f1: 0.9595723077700128, loss: 9.474524995312095e-05\n",
      "EPOCH: 7 val_acc:0.9867063492063458, val_f1:0.967903168901928, loss: 0.0001835774164646864\n",
      "EPOCH: 8 train_acc: 0.9841931216931185, train_f1: 0.9622306758009923, loss: 0.0001324206532444805\n",
      "EPOCH: 8 val_acc:0.9855158730158692, val_f1:0.9668057582616506, loss: 9.590075205778703e-05\n",
      "EPOCH: 9 train_acc: 0.9883597883597858, train_f1: 0.9723961229893056, loss: 0.00013525027316063643\n",
      "EPOCH: 9 val_acc:0.9923280423280404, val_f1:0.9809516605934173, loss: 2.729806692514103e-05\n",
      "Fold 3\n",
      "EPOCH: 0 train_acc: 0.9808862433862389, train_f1: 0.9582274436146082, loss: 0.00018771423492580652\n",
      "EPOCH: 0 val_acc:0.9763227513227464, val_f1:0.960051153657677, loss: 0.00024489942006766796\n",
      "EPOCH: 1 train_acc: 0.985846560846558, train_f1: 0.9709410601334901, loss: 7.14189518475905e-05\n",
      "EPOCH: 1 val_acc:0.9925264550264528, val_f1:0.9811389788111625, loss: 2.8888143788208254e-05\n",
      "EPOCH: 2 train_acc: 0.9890873015872989, train_f1: 0.9761606309842261, loss: 4.105206244275905e-05\n",
      "EPOCH: 2 val_acc:0.9527777777777738, val_f1:0.9370604001275662, loss: 0.0002744771772995591\n",
      "EPOCH: 3 train_acc: 0.9911375661375634, train_f1: 0.9794308177345856, loss: 7.164822454797104e-05\n",
      "EPOCH: 3 val_acc:0.9803571428571395, val_f1:0.9503085000229421, loss: 0.00021390870097093284\n",
      "EPOCH: 4 train_acc: 0.9916005291005274, train_f1: 0.981900635130053, loss: 3.5481221857480705e-05\n",
      "EPOCH: 4 val_acc:0.9946428571428554, val_f1:0.9889464642001641, loss: 6.272830069065094e-05\n",
      "EPOCH: 5 train_acc: 0.9919973544973526, train_f1: 0.9822316753526653, loss: 3.608903716667555e-05\n",
      "EPOCH: 5 val_acc:0.9938492063492046, val_f1:0.9862710597815226, loss: 6.75741393934004e-05\n",
      "EPOCH: 6 train_acc: 0.9942460317460308, train_f1: 0.9873707146090488, loss: 4.677634569816291e-05\n",
      "EPOCH: 6 val_acc:0.998544973544973, val_f1:0.9959181221482807, loss: 1.9549739590729587e-05\n",
      "EPOCH: 7 train_acc: 0.9931216931216905, train_f1: 0.9851582387406577, loss: 5.260254692984745e-05\n",
      "EPOCH: 7 val_acc:0.9974206349206338, val_f1:0.9931640192962004, loss: 1.7573049262864515e-05\n",
      "EPOCH: 8 train_acc: 0.9947089947089927, train_f1: 0.9886917566928988, loss: 5.424560004030354e-05\n",
      "EPOCH: 8 val_acc:0.9909391534391505, val_f1:0.9792533661041646, loss: 2.9967084628879093e-05\n",
      "EPOCH: 9 train_acc: 0.9951719576719567, train_f1: 0.9902408131667076, loss: 6.868930358905345e-05\n",
      "EPOCH: 9 val_acc:0.9994047619047618, val_f1:0.9987505256131999, loss: 1.063994386640843e-05\n",
      "Fold 4\n",
      "EPOCH: 0 train_acc: 0.9916005291005265, train_f1: 0.9821940470528941, loss: 2.908760870923288e-05\n",
      "EPOCH: 0 val_acc:0.9935846560846542, val_f1:0.993432090661248, loss: 2.361210499657318e-05\n",
      "EPOCH: 1 train_acc: 0.9941137566137551, train_f1: 0.9889391945544599, loss: 6.557750748470426e-05\n",
      "EPOCH: 1 val_acc:0.9978174603174597, val_f1:0.9941174283066216, loss: 1.4260126590670552e-05\n",
      "EPOCH: 2 train_acc: 0.9935185185185167, train_f1: 0.9864644262834765, loss: 2.514081643312238e-05\n",
      "EPOCH: 2 val_acc:0.987566137566134, val_f1:0.9743101603641018, loss: 6.0413829487515613e-05\n",
      "EPOCH: 3 train_acc: 0.9945105820105808, train_f1: 0.9886517685770476, loss: 1.9716466340469196e-05\n",
      "EPOCH: 3 val_acc:0.9904761904761881, val_f1:0.9831197210490153, loss: 3.4313430660404265e-05\n",
      "EPOCH: 4 train_acc: 0.9960317460317448, train_f1: 0.9937932796066761, loss: 2.3641789084649645e-05\n",
      "EPOCH: 4 val_acc:0.9945767195767179, val_f1:0.9922382720587265, loss: 4.971323141944595e-05\n",
      "EPOCH: 5 train_acc: 0.9960978835978822, train_f1: 0.9909570632867328, loss: 2.1433885194710456e-05\n",
      "EPOCH: 5 val_acc:0.9904100529100508, val_f1:0.9873286217993407, loss: 2.0344728909549303e-05\n",
      "EPOCH: 6 train_acc: 0.994113756613755, train_f1: 0.9888068433182939, loss: 2.066936212941073e-05\n",
      "EPOCH: 6 val_acc:0.9890873015872984, val_f1:0.9766532712820435, loss: 0.00014795326569583267\n",
      "EPOCH: 7 train_acc: 0.9978835978835974, train_f1: 0.9956352873522746, loss: 1.9974690076196566e-05\n",
      "EPOCH: 7 val_acc:0.9988095238095236, val_f1:0.9976368693971014, loss: 1.1975972483924124e-05\n",
      "EPOCH: 8 train_acc: 0.9980158730158726, train_f1: 0.9967731526759376, loss: 2.8549149647005834e-05\n",
      "EPOCH: 8 val_acc:0.9974206349206338, val_f1:0.9955535763904111, loss: 1.2798998795915395e-05\n",
      "EPOCH: 9 train_acc: 0.9963624338624326, train_f1: 0.9928520753002146, loss: 0.0002078480611089617\n",
      "EPOCH: 9 val_acc:0.9135582010581985, val_f1:0.8302838381326709, loss: 0.000818176893517375\n",
      "Fold 5\n",
      "EPOCH: 0 train_acc: 0.9935185185185174, train_f1: 0.9888066228155136, loss: 1.0859589565370698e-05\n",
      "EPOCH: 0 val_acc:0.9981481481481477, val_f1:0.9972259115958172, loss: 8.33704871183727e-06\n",
      "EPOCH: 1 train_acc: 0.9969576719576714, train_f1: 0.994403660446149, loss: 5.711754965886939e-06\n",
      "EPOCH: 1 val_acc:0.9745370370370332, val_f1:0.9660429375975101, loss: 0.00014295805885922164\n",
      "EPOCH: 2 train_acc: 0.9966931216931207, train_f1: 0.9932467948014942, loss: 5.03173578181304e-06\n",
      "EPOCH: 2 val_acc:0.9939814814814796, val_f1:0.9890707151249473, loss: 3.457771526882425e-05\n",
      "EPOCH: 3 train_acc: 0.9947751322751307, train_f1: 0.9918476080209438, loss: 6.9443165557459e-05\n",
      "EPOCH: 3 val_acc:0.9920634920634894, val_f1:0.9847342673164262, loss: 4.5234533899929374e-05\n",
      "EPOCH: 4 train_acc: 0.9968915343915338, train_f1: 0.9928541109164849, loss: 9.556651093589608e-06\n",
      "EPOCH: 4 val_acc:0.9978174603174597, val_f1:0.9970114514594101, loss: 7.320617442019284e-06\n",
      "EPOCH: 5 train_acc: 0.998412698412698, train_f1: 0.997073539217094, loss: 7.085633569658967e-06\n",
      "EPOCH: 5 val_acc:0.9993386243386242, val_f1:0.9994547484150801, loss: 5.478217190102441e-06\n",
      "EPOCH: 6 train_acc: 0.9955026455026444, train_f1: 0.99196137498833, loss: 4.0765230551187415e-06\n",
      "EPOCH: 6 val_acc:0.998214285714285, val_f1:0.9981130837767136, loss: 0.00014742728671990335\n",
      "EPOCH: 7 train_acc: 0.9976851851851848, train_f1: 0.9948565997115234, loss: 2.0389657038322184e-06\n",
      "EPOCH: 7 val_acc:0.9998677248677249, val_f1:0.9996252204585538, loss: 1.3958523368273745e-06\n",
      "EPOCH: 8 train_acc: 0.9992724867724861, train_f1: 0.9987491626521712, loss: 1.685161259956658e-05\n",
      "EPOCH: 8 val_acc:0.9943121693121677, val_f1:0.9911993803169564, loss: 2.5730178094818257e-05\n",
      "EPOCH: 9 train_acc: 0.9953042328042309, train_f1: 0.9909826782194693, loss: 4.650689515983686e-05\n",
      "EPOCH: 9 val_acc:0.972685185185181, val_f1:0.9434468445903903, loss: 0.0003295558854006231\n"
     ]
    }
   ],
   "source": [
    "BATCH = 30\n",
    "EPOCH = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mymodel.parameters(),lr=0.0001)\n",
    "\n",
    "\n",
    "pre_train_f1, pre_train_acc = 0,0\n",
    "pre_val_f1, pre_val_acc = 0,0\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skfold.split(torch.arange(len(mask_dataset)),mask_dataset.y)):\n",
    "    print('Fold {}'.format(fold+1))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    val_sampler = SubsetRandomSampler(val_idx)\n",
    "\n",
    "    train_loader = DataLoader(mask_dataset,batch_size=BATCH,sampler=train_sampler,shuffle=False)\n",
    "    val_loader = DataLoader(mask_dataset,batch_size=BATCH,sampler=val_sampler,shuffle=False)\n",
    "    for epoch in range(EPOCH):\n",
    "        train_acc, train_f1, train_loss = model_train(mymodel, device, train_loader,criterion,optimizer)\n",
    "        val_acc, val_f1, val_loss = model_val(mymodel, device, train_loader,criterion)\n",
    "\n",
    "        if pre_train_f1 < train_f1:\n",
    "            pre_train_acc, pre_train_f1 = train_acc, train_f1\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict':mymodel.state_dict(),\n",
    "                'optimizer_state_dict':optimizer.state_dict(),\n",
    "                'train_acc': train_acc,\n",
    "                'train_f1': train_f1\n",
    "            },f\"saved/checkpoint_model_train_{fold}_{epoch}_{train_acc}_{train_f1}.pt\") \n",
    "        if pre_val_f1 < val_f1:\n",
    "            pre_val_f1, pre_val_acc = val_f1, val_acc\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict':mymodel.state_dict(),\n",
    "                'optimizer_state_dict':optimizer.state_dict(),\n",
    "                'train_acc': val_acc,\n",
    "                'train_f1': val_f1\n",
    "            },f\"saved/checkpoint_model_val_{fold}_{epoch}_{val_acc}_{val_f1}.pt\") \n",
    "        \n",
    "        writer.add_scalar(f'Acc/fold{fold}/train',train_acc,epoch)\n",
    "        writer.add_scalar(f'f1/fold{fold}/train',train_f1,epoch)\n",
    "        writer.add_scalar(f'loss/fold{fold}/train',train_loss,epoch)\n",
    "\n",
    "        writer.add_scalar(f'Acc/fold{fold}/val',val_acc,epoch)\n",
    "        writer.add_scalar(f'f1/fold{fold}/val',val_f1,epoch)\n",
    "        writer.add_scalar(f'loss/fold{fold}/train',val_loss,epoch)\n",
    "        \n",
    "        print(f\"EPOCH: {epoch} train_acc: {train_acc}, train_f1: {train_f1}, loss: {train_loss}\")\n",
    "        print(f\"EPOCH: {epoch} val_acc:{val_acc}, val_f1:{val_f1}, loss: {val_loss}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
