{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Augmentor\n",
    "import os\n",
    "from PIL import Image\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 압축 풀기\n",
    "filename = \"/opt/ml/input/data/train/images.zip\"\n",
    "extract_dir = \"/opt/ml/input/data/train\"\n",
    "archive_format = \"zip\"\n",
    "\n",
    "shutil.unpack_archive(filename, extract_dir, archive_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 Path\n",
    "path = \"/opt/ml/input/data/train/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 폴더명 저장\n",
    "profiles = os.listdir(path)\n",
    "profiles = [profile for profile in profiles if not profile.startswith('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9014C0>: 100%|██████████| 7/7 [00:00<00:00, 74.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD250>: 100%|██████████| 7/7 [00:00<00:00, 85.67 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003945_male_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003756_female_Asian_48."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53670>: 100%|██████████| 7/7 [00:00<00:00, 106.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919610>: 100%|██████████| 7/7 [00:00<00:00, 81.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198B0>: 100%|██████████| 7/7 [00:00<00:00, 111.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D538B0>: 100%|██████████| 7/7 [00:00<00:00, 121.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53CA0>: 100%|██████████| 7/7 [00:00<00:00, 103.87 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005428_female_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006267_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58AC0>: 100%|██████████| 7/7 [00:00<00:00, 66.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A93D0>: 100%|██████████| 7/7 [00:00<00:00, 82.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9014C0>: 100%|██████████| 7/7 [00:00<00:00, 96.84 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003046_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001759_female_Asian_46."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD550>: 100%|██████████| 7/7 [00:00<00:00, 98.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58850>: 100%|██████████| 7/7 [00:00<00:00, 101.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA90>: 100%|██████████| 7/7 [00:00<00:00, 129.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B820>: 100%|██████████| 7/7 [00:00<00:00, 101.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61AF0>: 100%|██████████| 7/7 [00:00<00:00, 106.67 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000751_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005267_male_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B700>: 100%|██████████| 7/7 [00:00<00:00, 126.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68160>: 100%|██████████| 7/7 [00:00<00:00, 87.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BAC0>: 100%|██████████| 7/7 [00:00<00:00, 105.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68C70>:  29%|██▊       | 2/7 [00:00<00:00, 44.61 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003405_female_Asian_49.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004021_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1610>: 100%|██████████| 7/7 [00:00<00:00, 97.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D681C0>: 100%|██████████| 7/7 [00:00<00:00, 101.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD4F0>:  86%|████████▌ | 6/7 [00:00<00:00,  8.31 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006166_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD4F0>: 100%|██████████| 7/7 [00:00<00:00, 34.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F37F0>: 100%|██████████| 7/7 [00:00<00:00, 35.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A19D0>: 100%|██████████| 7/7 [00:00<00:00, 104.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3BB0>: 100%|██████████| 7/7 [00:00<00:00, 93.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDF10>:  29%|██▊       | 2/7 [00:00<00:00, 47.32 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005038_female_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005440_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA60>: 100%|██████████| 7/7 [00:00<00:00, 110.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D90>: 100%|██████████| 7/7 [00:00<00:00, 105.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FD0>: 100%|██████████| 7/7 [00:00<00:00, 80.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68FA0>: 100%|██████████| 7/7 [00:00<00:00, 95.96 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003403-1_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006351_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D60>: 100%|██████████| 7/7 [00:00<00:00, 111.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A9520>: 100%|██████████| 7/7 [00:00<00:00, 110.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A9340>: 100%|██████████| 7/7 [00:00<00:00, 119.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31AC0>: 100%|██████████| 7/7 [00:00<00:00, 105.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61580>:  29%|██▊       | 2/7 [00:00<00:00, 35.02 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001821_female_Asian_36.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000594_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A14F0>: 100%|██████████| 7/7 [00:00<00:00, 82.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58790>: 100%|██████████| 7/7 [00:00<00:00, 121.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D589A0>: 100%|██████████| 7/7 [00:00<00:00, 77.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58DC0>: 100%|██████████| 7/7 [00:00<00:00, 99.44 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006605_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003352_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1430>: 100%|██████████| 7/7 [00:00<00:00, 100.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58B80>: 100%|██████████| 7/7 [00:00<00:00, 89.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CA0>: 100%|██████████| 7/7 [00:00<00:00, 74.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3520>: 100%|██████████| 7/7 [00:00<00:00, 107.50 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000742_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006071_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536D0>: 100%|██████████| 7/7 [00:00<00:00, 42.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCA0>: 100%|██████████| 7/7 [00:00<00:00, 56.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919BE0>: 100%|██████████| 7/7 [00:00<00:00, 112.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919820>: 100%|██████████| 7/7 [00:00<00:00, 102.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>: 100%|██████████| 7/7 [00:00<00:00, 113.62 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001775-1_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003293_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53670>: 100%|██████████| 7/7 [00:00<00:00, 85.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C10>: 100%|██████████| 7/7 [00:00<00:00, 97.64 Samples/s]          \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1160>: 100%|██████████| 7/7 [00:00<00:00, 117.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1820>:  29%|██▊       | 2/7 [00:00<00:00, 38.94 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006383_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001024_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F40>: 100%|██████████| 7/7 [00:00<00:00, 77.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD850>: 100%|██████████| 7/7 [00:00<00:00, 80.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD250>: 100%|██████████| 7/7 [00:00<00:00, 66.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD040>: 100%|██████████| 7/7 [00:00<00:00, 95.33 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003943_male_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001984_female_Asian_33."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7E668E0>: 100%|██████████| 7/7 [00:00<00:00, 104.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1BE0>: 100%|██████████| 7/7 [00:00<00:00, 107.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A13A0>: 100%|██████████| 7/7 [00:00<00:00, 106.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD370>: 100%|██████████| 7/7 [00:00<00:00, 97.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F10>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006655_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001561_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919E20>: 100%|██████████| 7/7 [00:00<00:00, 89.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919640>: 100%|██████████| 7/7 [00:00<00:00, 94.64 Samples/s]          \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D588E0>: 100%|██████████| 7/7 [00:00<00:00, 125.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1BE0>: 100%|██████████| 7/7 [00:00<00:00, 98.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A90>:  43%|████▎     | 3/7 [00:00<00:00, 45.67 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001730_female_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003235_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53310>: 100%|██████████| 7/7 [00:00<00:00, 88.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A10A0>: 100%|██████████| 7/7 [00:00<00:00, 72.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53910>: 100%|██████████| 7/7 [00:00<00:00, 96.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDFA0>: 100%|██████████| 7/7 [00:00<00:00, 121.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7D60>:  57%|█████▋    | 4/7 [00:00<00:00, 62.80 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000669_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005424_male_Asian_36."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58A30>: 100%|██████████| 7/7 [00:00<00:00, 84.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D90>: 100%|██████████| 7/7 [00:00<00:00, 74.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1F10>: 100%|██████████| 7/7 [00:00<00:00, 100.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C190>: 100%|██████████| 7/7 [00:00<00:00, 113.08 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBC880>:  71%|███████▏  | 5/7 [00:00<00:00, 79.12 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003551_female_Asian_34.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003145_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDB20>: 100%|██████████| 7/7 [00:00<00:00, 106.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD60>: 100%|██████████| 7/7 [00:00<00:00, 92.30 Samples/s]          \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58910>: 100%|██████████| 7/7 [00:00<00:00, 116.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53550>: 100%|██████████| 7/7 [00:00<00:00, 98.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B970>:  43%|████▎     | 3/7 [00:00<00:00, 46.08 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006454_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006628_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1580>: 100%|██████████| 7/7 [00:00<00:00, 91.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C616A0>: 100%|██████████| 7/7 [00:00<00:00, 112.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D90>: 100%|██████████| 7/7 [00:00<00:00, 73.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD6D0>: 100%|██████████| 7/7 [00:00<00:00, 99.91 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004004_male_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004269_male_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA90>: 100%|██████████| 7/7 [00:00<00:00, 79.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDAF0>: 100%|██████████| 7/7 [00:00<00:00, 108.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB10100>: 100%|██████████| 7/7 [00:00<00:00, 106.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD130>: 100%|██████████| 7/7 [00:00<00:00, 109.83 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B1C0>: 100%|██████████| 7/7 [00:00<00:00, 114.35 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006385_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004201_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F33A0>: 100%|██████████| 7/7 [00:00<00:00, 104.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD460>: 100%|██████████| 7/7 [00:00<00:00, 81.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABD8910>: 100%|██████████| 7/7 [00:00<00:00, 99.11 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003789_male_Asian_41.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001180_female_Asian_48."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B940>: 100%|██████████| 7/7 [00:00<00:00, 102.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F34F0>: 100%|██████████| 7/7 [00:00<00:00, 116.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1100>: 100%|██████████| 7/7 [00:00<00:00, 87.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A00>: 100%|██████████| 7/7 [00:00<00:00, 105.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61730>:  43%|████▎     | 3/7 [00:00<00:00, 71.82 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001576_female_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001328_male_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31F10>: 100%|██████████| 7/7 [00:00<00:00, 118.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A90>: 100%|██████████| 7/7 [00:00<00:00, 88.65 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FC23A1B50>: 100%|██████████| 7/7 [00:00<00:00, 107.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61400>: 100%|██████████| 7/7 [00:00<00:00, 102.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C616A0>:  43%|████▎     | 3/7 [00:00<00:00, 48.57 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006606_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001922_male_Asian_42."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D90>: 100%|██████████| 7/7 [00:00<00:00, 94.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61970>: 100%|██████████| 7/7 [00:00<00:00, 99.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1310>: 100%|██████████| 7/7 [00:00<00:00, 95.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3880>: 100%|██████████| 7/7 [00:00<00:00, 82.61 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006500_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003600_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901760>: 100%|██████████| 7/7 [00:00<00:00, 72.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691B20>: 100%|██████████| 7/7 [00:00<00:00, 82.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68F40>: 100%|██████████| 7/7 [00:00<00:00, 106.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F40>: 100%|██████████| 7/7 [00:00<00:00, 88.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1CD0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003307_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001577_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D589D0>: 100%|██████████| 7/7 [00:00<00:00, 98.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E80>: 100%|██████████| 7/7 [00:00<00:00, 67.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D00>: 100%|██████████| 7/7 [00:00<00:00, 99.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D586D0>: 100%|██████████| 7/7 [00:00<00:00, 98.54 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006494_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001062_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A30>: 100%|██████████| 7/7 [00:00<00:00, 65.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1760>: 100%|██████████| 7/7 [00:00<00:00, 56.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD4C0>: 100%|██████████| 7/7 [00:00<00:00, 115.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3F70>: 100%|██████████| 7/7 [00:00<00:00, 86.93 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7D53220>:  57%|█████▋    | 4/7 [00:00<00:00, 77.83 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001186_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000071_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A30>: 100%|██████████| 7/7 [00:00<00:00, 83.15 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EE0>: 100%|██████████| 7/7 [00:00<00:00, 122.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3970>: 100%|██████████| 7/7 [00:00<00:00, 85.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53280>: 100%|██████████| 7/7 [00:00<00:00, 75.66 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003754_male_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004248_female_Asian_38."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD700>: 100%|██████████| 7/7 [00:00<00:00, 121.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD940>: 100%|██████████| 7/7 [00:00<00:00, 67.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA60>: 100%|██████████| 7/7 [00:00<00:00, 75.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A60>: 100%|██████████| 7/7 [00:00<00:00, 122.57 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000229_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000037_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D538B0>: 100%|██████████| 7/7 [00:00<00:00, 88.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F40>: 100%|██████████| 7/7 [00:00<00:00, 79.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9012E0>: 100%|██████████| 7/7 [00:00<00:00, 98.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9019D0>: 100%|██████████| 7/7 [00:00<00:00, 99.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53FA0>:  43%|████▎     | 3/7 [00:00<00:00, 55.65 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003445_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006210_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDDC0>: 100%|██████████| 7/7 [00:00<00:00, 95.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58A30>: 100%|██████████| 7/7 [00:00<00:00, 88.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7B20>: 100%|██████████| 7/7 [00:00<00:00, 83.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD4F0>: 100%|██████████| 7/7 [00:00<00:00, 72.48 Samples/s]                  \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005246_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003421_female_Asian_38."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD9D0>: 100%|██████████| 7/7 [00:00<00:00, 117.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53FA0>: 100%|██████████| 7/7 [00:00<00:00, 90.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53580>: 100%|██████████| 7/7 [00:00<00:00, 88.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D539A0>: 100%|██████████| 7/7 [00:00<00:00, 76.45 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003814_male_Asian_27.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001632_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F10>: 100%|██████████| 7/7 [00:00<00:00, 92.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53250>: 100%|██████████| 7/7 [00:00<00:00, 56.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68FA0>: 100%|██████████| 7/7 [00:00<00:00, 82.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD820>: 100%|██████████| 7/7 [00:00<00:00, 107.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D00>:  43%|████▎     | 3/7 [00:00<00:00, 67.82 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006617_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001803_female_Asian_27."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537C0>: 100%|██████████| 7/7 [00:00<00:00, 139.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68040>: 100%|██████████| 7/7 [00:00<00:00, 96.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C40>: 100%|██████████| 7/7 [00:00<00:00, 82.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5B0>: 100%|██████████| 7/7 [00:00<00:00, 75.58 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003333_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003193_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D30>: 100%|██████████| 7/7 [00:00<00:00, 94.41 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FC23A19A0>: 100%|██████████| 7/7 [00:00<00:00, 89.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68340>: 100%|██████████| 7/7 [00:00<00:00, 95.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B20>: 100%|██████████| 7/7 [00:00<00:00, 115.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F35B0>:  43%|████▎     | 3/7 [00:00<00:00, 50.54 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001623_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000256_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B670>: 100%|██████████| 7/7 [00:00<00:00, 86.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BAC0>: 100%|██████████| 7/7 [00:00<00:00, 83.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1280>: 100%|██████████| 7/7 [00:00<00:00, 78.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A12B0>: 100%|██████████| 7/7 [00:00<00:00, 104.60 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001366_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006707_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3E20>: 100%|██████████| 7/7 [00:00<00:00, 84.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3550>: 100%|██████████| 7/7 [00:00<00:00, 109.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11C0>: 100%|██████████| 7/7 [00:00<00:00, 88.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61880>: 100%|██████████| 7/7 [00:00<00:00, 107.17 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D681C0>:  57%|█████▋    | 4/7 [00:00<00:00, 80.31 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001806_female_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001042_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61730>: 100%|██████████| 7/7 [00:00<00:00, 103.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3910>: 100%|██████████| 7/7 [00:00<00:00, 122.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E80>: 100%|██████████| 7/7 [00:00<00:00, 114.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3F10>: 100%|██████████| 7/7 [00:00<00:00, 76.12 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005032_female_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003173_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A30>: 100%|██████████| 7/7 [00:00<00:00, 85.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58940>: 100%|██████████| 7/7 [00:00<00:00, 75.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D587F0>: 100%|██████████| 7/7 [00:00<00:00, 111.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7160>: 100%|██████████| 7/7 [00:00<00:00, 87.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C613D0>:  43%|████▎     | 3/7 [00:00<00:00, 67.67 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006083_male_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004077_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61910>: 100%|██████████| 7/7 [00:00<00:00, 106.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901940>: 100%|██████████| 7/7 [00:00<00:00, 90.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58AC0>: 100%|██████████| 7/7 [00:00<00:00, 109.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A17C0>: 100%|██████████| 7/7 [00:00<00:00, 84.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B20>:  43%|████▎     | 3/7 [00:00<00:00, 62.18 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001334_female_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003123_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3820>: 100%|██████████| 7/7 [00:00<00:00, 124.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58730>: 100%|██████████| 7/7 [00:00<00:00, 89.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C40>: 100%|██████████| 7/7 [00:00<00:00, 94.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3310>: 100%|██████████| 7/7 [00:00<00:00, 117.82 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003435_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006242_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD90>: 100%|██████████| 7/7 [00:00<00:00, 42.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE50>: 100%|██████████| 7/7 [00:00<00:00, 41.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53610>: 100%|██████████| 7/7 [00:00<00:00, 80.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B50>: 100%|██████████| 7/7 [00:00<00:00, 84.93 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001791_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001566_female_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A00>: 100%|██████████| 7/7 [00:00<00:00, 124.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD9D0>: 100%|██████████| 7/7 [00:00<00:00, 106.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F31F0>: 100%|██████████| 7/7 [00:00<00:00, 77.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919160>: 100%|██████████| 7/7 [00:00<00:00, 83.99 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004278_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005442_female_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDBB0>: 100%|██████████| 7/7 [00:00<00:00, 105.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD310>: 100%|██████████| 7/7 [00:00<00:00, 84.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F10>: 100%|██████████| 7/7 [00:00<00:00, 112.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C310>: 100%|██████████| 7/7 [00:00<00:00, 107.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD6D0>:  29%|██▊       | 2/7 [00:00<00:00, 37.76 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001919_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004429_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDDF0>: 100%|██████████| 7/7 [00:00<00:00, 69.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58970>: 100%|██████████| 7/7 [00:00<00:00, 100.47 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A30>: 100%|██████████| 7/7 [00:00<00:00, 110.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A00>: 100%|██████████| 7/7 [00:00<00:00, 89.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D534F0>:  43%|████▎     | 3/7 [00:00<00:00, 62.75 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001612_female_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000611_male_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDB50>: 100%|██████████| 7/7 [00:00<00:00, 80.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A22E0>: 100%|██████████| 7/7 [00:00<00:00, 82.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61550>: 100%|██████████| 7/7 [00:00<00:00, 94.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58B20>: 100%|██████████| 7/7 [00:00<00:00, 89.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58970>:  29%|██▊       | 2/7 [00:00<00:00, 48.76 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001667_female_Asian_45.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004371_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B80>: 100%|██████████| 7/7 [00:00<00:00, 107.67 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7D53E50>: 100%|██████████| 7/7 [00:00<00:00, 119.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61850>: 100%|██████████| 7/7 [00:00<00:00, 105.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDFD0>: 100%|██████████| 7/7 [00:00<00:00, 83.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BE20>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003680_male_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003598_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614F0>: 100%|██████████| 7/7 [00:00<00:00, 81.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BE20>: 100%|██████████| 7/7 [00:00<00:00, 104.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A14F0>: 100%|██████████| 7/7 [00:00<00:00, 90.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11F0>: 100%|██████████| 7/7 [00:00<00:00, 83.18 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003682_male_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003947_male_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE80>: 100%|██████████| 7/7 [00:00<00:00, 91.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1400>: 100%|██████████| 7/7 [00:00<00:00, 122.07 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38B0>: 100%|██████████| 7/7 [00:00<00:00, 102.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1880>: 100%|██████████| 7/7 [00:00<00:00, 107.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53400>:  14%|█▍        | 1/7 [00:00<00:00, 23.82 Samples/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001761_male_Asian_44.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001310_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61490>: 100%|██████████| 7/7 [00:00<00:00, 101.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C616A0>: 100%|██████████| 7/7 [00:00<00:00, 90.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38E0>: 100%|██████████| 7/7 [00:00<00:00, 88.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61670>: 100%|██████████| 7/7 [00:00<00:00, 118.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F70>:  29%|██▊       | 2/7 [00:00<00:00, 35.41 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005555_male_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003819_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3BB0>: 100%|██████████| 7/7 [00:00<00:00, 99.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1FD0>: 100%|██████████| 7/7 [00:00<00:00, 102.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919BE0>: 100%|██████████| 7/7 [00:00<00:00, 94.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3E20>: 100%|██████████| 7/7 [00:00<00:00, 125.09 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7C61490>:  71%|███████▏  | 5/7 [00:00<00:00, 78.16 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006365_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006488_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3BB0>: 100%|██████████| 7/7 [00:00<00:00, 101.04 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D589D0>: 100%|██████████| 7/7 [00:00<00:00, 95.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D90>: 100%|██████████| 7/7 [00:00<00:00, 120.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3D60>: 100%|██████████| 7/7 [00:00<00:00, 133.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9193D0>: 100%|██████████| 7/7 [00:00<00:00, 92.47 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001644_male_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001971_male_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C40>: 100%|██████████| 7/7 [00:00<00:00, 66.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61820>: 100%|██████████| 7/7 [00:00<00:00, 97.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68130>: 100%|██████████| 7/7 [00:00<00:00, 100.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58A30>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001770_female_Asian_47.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003942_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919820>: 100%|██████████| 7/7 [00:00<00:00, 82.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68040>: 100%|██████████| 7/7 [00:00<00:00, 86.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68F40>: 100%|██████████| 7/7 [00:00<00:00, 94.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7E66850>: 100%|██████████| 7/7 [00:00<00:00, 103.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C70>:  43%|████▎     | 3/7 [00:00<00:00, 72.52 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003705_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001029_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D680A0>: 100%|██████████| 7/7 [00:00<00:00, 107.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1670>: 100%|██████████| 7/7 [00:00<00:00, 111.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B100>: 100%|██████████| 7/7 [00:00<00:00, 88.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D30>: 100%|██████████| 7/7 [00:00<00:00, 108.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11C0>:  43%|████▎     | 3/7 [00:00<00:00, 62.83 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001535_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001741_female_Asian_44."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D30>: 100%|██████████| 7/7 [00:00<00:00, 76.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A17C0>: 100%|██████████| 7/7 [00:00<00:00, 102.08 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E80>: 100%|██████████| 7/7 [00:00<00:00, 100.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919790>: 100%|██████████| 7/7 [00:00<00:00, 100.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A16A0>:  14%|█▍        | 1/7 [00:00<00:00, 22.22 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001227_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000304_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D90>: 100%|██████████| 7/7 [00:00<00:00, 88.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1CA0>: 100%|██████████| 7/7 [00:00<00:00, 86.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D586A0>: 100%|██████████| 7/7 [00:00<00:00, 87.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901640>: 100%|██████████| 7/7 [00:00<00:00, 111.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDB50>:  14%|█▍        | 1/7 [00:00<00:00, 19.18 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004381_male_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006543_female_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53730>: 100%|██████████| 7/7 [00:00<00:00, 76.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536D0>: 100%|██████████| 7/7 [00:00<00:00, 95.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDC40>: 100%|██████████| 7/7 [00:00<00:00, 112.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1430>: 100%|██████████| 7/7 [00:00<00:00, 57.98 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006616_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003349_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1B50>: 100%|██████████| 7/7 [00:00<00:00, 106.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53040>: 100%|██████████| 7/7 [00:00<00:00, 83.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901340>: 100%|██████████| 7/7 [00:00<00:00, 95.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1610>: 100%|██████████| 7/7 [00:00<00:00, 101.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53250>:  29%|██▊       | 2/7 [00:00<00:00, 47.25 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003847_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000248_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD160>: 100%|██████████| 7/7 [00:00<00:00, 87.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D586A0>: 100%|██████████| 7/7 [00:00<00:00, 105.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE80>: 100%|██████████| 7/7 [00:00<00:00, 107.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1640>: 100%|██████████| 7/7 [00:00<00:00, 80.53 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000692_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006163_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBC3D0>: 100%|██████████| 7/7 [00:00<00:00, 33.08 Samples/s]        \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58DC0>: 100%|██████████| 7/7 [00:00<00:00, 41.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58BB0>: 100%|██████████| 7/7 [00:00<00:00, 83.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1490>: 100%|██████████| 7/7 [00:00<00:00, 94.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD310>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001107_male_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001145_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31520>: 100%|██████████| 7/7 [00:00<00:00, 89.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDAC0>: 100%|██████████| 7/7 [00:00<00:00, 82.07 Samples/s]          \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53FD0>: 100%|██████████| 7/7 [00:00<00:00, 87.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1BB0>: 100%|██████████| 7/7 [00:00<00:00, 90.62 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003147_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001825_female_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53160>: 100%|██████████| 7/7 [00:00<00:00, 91.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD820>: 100%|██████████| 7/7 [00:00<00:00, 120.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1B50>: 100%|██████████| 7/7 [00:00<00:00, 102.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA90>: 100%|██████████| 7/7 [00:00<00:00, 114.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61850>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004412_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006264_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61430>: 100%|██████████| 7/7 [00:00<00:00, 95.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD2E0>: 100%|██████████| 7/7 [00:00<00:00, 97.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD100>: 100%|██████████| 7/7 [00:00<00:00, 98.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61DF0>: 100%|██████████| 7/7 [00:00<00:00, 83.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537F0>:  14%|█▍        | 1/7 [00:00<00:00, 25.62 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003792_male_Asian_30.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006215_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8F3BB0>: 100%|██████████| 7/7 [00:00<00:00, 82.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDF40>: 100%|██████████| 7/7 [00:00<00:00, 82.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3AC0>: 100%|██████████| 7/7 [00:00<00:00, 107.50 Samples/s]         \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F34F0>: 100%|██████████| 7/7 [00:00<00:00, 82.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919760>:  14%|█▍        | 1/7 [00:00<00:00, 24.24 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006526_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001988_male_Asian_35."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B940>: 100%|██████████| 7/7 [00:00<00:00, 87.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D30>: 100%|██████████| 7/7 [00:00<00:00, 99.70 Samples/s]          \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3400>: 100%|██████████| 7/7 [00:00<00:00, 79.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A30>: 100%|██████████| 7/7 [00:00<00:00, 95.67 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006603_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005519_female_Asian_49."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535B0>: 100%|██████████| 7/7 [00:00<00:00, 116.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B50>: 100%|██████████| 7/7 [00:00<00:00, 80.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535B0>: 100%|██████████| 7/7 [00:00<00:00, 109.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3910>: 100%|██████████| 7/7 [00:00<00:00, 65.66 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004426_female_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000652_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919670>: 100%|██████████| 7/7 [00:00<00:00, 78.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61970>: 100%|██████████| 7/7 [00:00<00:00, 87.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31E50>: 100%|██████████| 7/7 [00:00<00:00, 99.86 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61490>: 100%|██████████| 7/7 [00:00<00:00, 82.34 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D90>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003097_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001461_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919790>: 100%|██████████| 7/7 [00:00<00:00, 114.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919400>: 100%|██████████| 7/7 [00:00<00:00, 77.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D30>: 100%|██████████| 7/7 [00:00<00:00, 75.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D00>: 100%|██████████| 7/7 [00:00<00:00, 88.94 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005126_female_Asian_46.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006096_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A30>: 100%|██████████| 7/7 [00:00<00:00, 91.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECCA5E20>: 100%|██████████| 7/7 [00:00<00:00, 99.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D60>: 100%|██████████| 7/7 [00:00<00:00, 98.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3760>: 100%|██████████| 7/7 [00:00<00:00, 101.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53970>:  14%|█▍        | 1/7 [00:00<00:00, 30.38 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000616_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001842_male_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3490>: 100%|██████████| 7/7 [00:00<00:00, 86.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD490>: 100%|██████████| 7/7 [00:00<00:00, 78.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919310>: 100%|██████████| 7/7 [00:00<00:00, 93.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9199D0>: 100%|██████████| 7/7 [00:00<00:00, 96.92 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001133_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001904_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3250>: 100%|██████████| 7/7 [00:00<00:00, 84.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDF10>: 100%|██████████| 7/7 [00:00<00:00, 118.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3610>: 100%|██████████| 7/7 [00:00<00:00, 98.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53970>: 100%|██████████| 7/7 [00:00<00:00, 105.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A16A0>: 100%|██████████| 7/7 [00:00<00:00, 121.85 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006075_male_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001280_female_Asian_27."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD7F0>: 100%|██████████| 7/7 [00:00<00:00, 109.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EB0>: 100%|██████████| 7/7 [00:00<00:00, 123.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533D0>: 100%|██████████| 7/7 [00:00<00:00, 91.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11F0>: 100%|██████████| 7/7 [00:00<00:00, 113.46 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005238_male_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006222_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D588E0>: 100%|██████████| 7/7 [00:00<00:00, 103.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58880>: 100%|██████████| 7/7 [00:00<00:00, 103.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9014C0>: 100%|██████████| 7/7 [00:00<00:00, 82.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D30>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004392_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000728_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE20>: 100%|██████████| 7/7 [00:00<00:00, 81.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D30>: 100%|██████████| 7/7 [00:00<00:00, 127.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1670>: 100%|██████████| 7/7 [00:00<00:00, 101.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7190>: 100%|██████████| 7/7 [00:00<00:00, 124.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D589A0>: 100%|██████████| 7/7 [00:00<00:00, 121.04 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003294_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005526_male_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD310>: 100%|██████████| 7/7 [00:00<00:00, 98.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58B20>: 100%|██████████| 7/7 [00:00<00:00, 92.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3430>: 100%|██████████| 7/7 [00:00<00:00, 106.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1AF0>:  57%|█████▋    | 4/7 [00:00<00:00, 73.45 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006556_male_Asian_21.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001925_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D30>: 100%|██████████| 7/7 [00:00<00:00, 94.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58940>: 100%|██████████| 7/7 [00:00<00:00, 74.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F34F0>: 100%|██████████| 7/7 [00:00<00:00, 106.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CA0>: 100%|██████████| 7/7 [00:00<00:00, 83.39 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003505_male_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001616_female_Asian_40."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8F3B80>: 100%|██████████| 7/7 [00:00<00:00, 86.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1880>: 100%|██████████| 7/7 [00:00<00:00, 81.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53760>: 100%|██████████| 7/7 [00:00<00:00, 99.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD100>: 100%|██████████| 7/7 [00:00<00:00, 86.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CD0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006422_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000543_male_Asian_35."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3430>: 100%|██████████| 7/7 [00:00<00:00, 101.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1610>: 100%|██████████| 7/7 [00:00<00:00, 96.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1610>: 100%|██████████| 7/7 [00:00<00:00, 97.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61E50>: 100%|██████████| 7/7 [00:00<00:00, 83.66 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005467_female_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000633_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD550>: 100%|██████████| 7/7 [00:00<00:00, 88.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68070>: 100%|██████████| 7/7 [00:00<00:00, 73.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61280>: 100%|██████████| 7/7 [00:00<00:00, 111.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>: 100%|██████████| 7/7 [00:00<00:00, 79.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53730>:  29%|██▊       | 2/7 [00:00<00:00, 46.31 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004336_male_Asian_35.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003049_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61820>: 100%|██████████| 7/7 [00:00<00:00, 121.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD130>: 100%|██████████| 7/7 [00:00<00:00, 91.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C616A0>: 100%|██████████| 7/7 [00:00<00:00, 81.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919400>: 100%|██████████| 7/7 [00:00<00:00, 86.16 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003737_female_Asian_40.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004023_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535B0>: 100%|██████████| 7/7 [00:00<00:00, 94.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9199D0>: 100%|██████████| 7/7 [00:00<00:00, 92.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53160>: 100%|██████████| 7/7 [00:00<00:00, 97.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F70>: 100%|██████████| 7/7 [00:00<00:00, 93.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FA0>:  14%|█▍        | 1/7 [00:00<00:00, 22.32 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000783_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005529_female_Asian_44."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533A0>: 100%|██████████| 7/7 [00:00<00:00, 92.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53FD0>: 100%|██████████| 7/7 [00:00<00:00, 92.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F10>: 100%|██████████| 7/7 [00:00<00:00, 87.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B040>: 100%|██████████| 7/7 [00:00<00:00, 80.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61820>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006727_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000292_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B700>: 100%|██████████| 7/7 [00:00<00:00, 109.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A90>: 100%|██████████| 7/7 [00:00<00:00, 88.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919CD0>: 100%|██████████| 7/7 [00:00<00:00, 108.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53AC0>: 100%|██████████| 7/7 [00:00<00:00, 86.24 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003930_male_Asian_42.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005224_male_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F35E0>: 100%|██████████| 7/7 [00:00<00:00, 61.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61850>: 100%|██████████| 7/7 [00:00<00:00, 120.25 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9190A0>: 100%|██████████| 7/7 [00:00<00:00, 75.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9191F0>: 100%|██████████| 7/7 [00:00<00:00, 105.93 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001163_male_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001323_male_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B50>: 100%|██████████| 7/7 [00:00<00:00, 128.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD130>: 100%|██████████| 7/7 [00:00<00:00, 86.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53BB0>: 100%|██████████| 7/7 [00:00<00:00, 85.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53340>: 100%|██████████| 7/7 [00:00<00:00, 77.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3760>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003120_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001709_female_Asian_46."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53520>: 100%|██████████| 7/7 [00:00<00:00, 107.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE80>: 100%|██████████| 7/7 [00:00<00:00, 65.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58FA0>: 100%|██████████| 7/7 [00:00<00:00, 89.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D60>: 100%|██████████| 7/7 [00:00<00:00, 99.46 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000039_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003324_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9012E0>: 100%|██████████| 7/7 [00:00<00:00, 89.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD4F0>: 100%|██████████| 7/7 [00:00<00:00, 80.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A00>: 100%|██████████| 7/7 [00:00<00:00, 92.58 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8FD700>: 100%|██████████| 7/7 [00:00<00:00, 108.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD280>:  86%|████████▌ | 6/7 [00:00<00:00, 116.45 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003751_male_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001114_male_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD280>: 100%|██████████| 7/7 [00:00<00:00, 124.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D588E0>: 100%|██████████| 7/7 [00:00<00:00, 136.68 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1B50>: 100%|██████████| 7/7 [00:00<00:00, 106.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD6D0>: 100%|██████████| 7/7 [00:00<00:00, 136.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1790>: 100%|██████████| 7/7 [00:00<00:00, 94.86 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004258_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001015_female_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC8E0>: 100%|██████████| 7/7 [00:00<00:00, 94.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D90>: 100%|██████████| 7/7 [00:00<00:00, 80.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1E20>: 100%|██████████| 7/7 [00:00<00:00, 91.07 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001457_male_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003926_male_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD400>: 100%|██████████| 7/7 [00:00<00:00, 82.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD60>: 100%|██████████| 7/7 [00:00<00:00, 94.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C340>: 100%|██████████| 7/7 [00:00<00:00, 81.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58BB0>: 100%|██████████| 7/7 [00:00<00:00, 87.45 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005426_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000554_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD4F0>: 100%|██████████| 7/7 [00:00<00:00, 110.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D587F0>: 100%|██████████| 7/7 [00:00<00:00, 86.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCA0>: 100%|██████████| 7/7 [00:00<00:00, 110.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61490>: 100%|██████████| 7/7 [00:00<00:00, 89.89 Samples/s] \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD520>:  29%|██▊       | 2/7 [00:00<00:00, 38.96 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004070_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003004_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D30>: 100%|██████████| 7/7 [00:00<00:00, 82.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD4F0>: 100%|██████████| 7/7 [00:00<00:00, 110.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD700>: 100%|██████████| 7/7 [00:00<00:00, 91.23 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A90>: 100%|██████████| 7/7 [00:00<00:00, 79.24 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003517_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003489_male_Asian_48."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68070>: 100%|██████████| 7/7 [00:00<00:00, 110.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1F0>: 100%|██████████| 7/7 [00:00<00:00, 112.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919910>: 100%|██████████| 7/7 [00:00<00:00, 82.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1160>: 100%|██████████| 7/7 [00:00<00:00, 104.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A30>:  14%|█▍        | 1/7 [00:00<00:00, 23.26 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003531_male_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001339_female_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A2100>: 100%|██████████| 7/7 [00:00<00:00, 111.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68FA0>: 100%|██████████| 7/7 [00:00<00:00, 77.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68D00>: 100%|██████████| 7/7 [00:00<00:00, 109.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF14C0>: 100%|██████████| 7/7 [00:00<00:00, 110.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A00>:  29%|██▊       | 2/7 [00:00<00:00, 38.93 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001309_male_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006744_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3700>: 100%|██████████| 7/7 [00:00<00:00, 82.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3BB0>: 100%|██████████| 7/7 [00:00<00:00, 86.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3400>: 100%|██████████| 7/7 [00:00<00:00, 94.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919040>: 100%|██████████| 7/7 [00:00<00:00, 92.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FA0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005487_female_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000549_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3AC0>: 100%|██████████| 7/7 [00:00<00:00, 119.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919100>: 100%|██████████| 7/7 [00:00<00:00, 124.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FD0>: 100%|██████████| 7/7 [00:00<00:00, 84.43 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53E80>: 100%|██████████| 7/7 [00:00<00:00, 113.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC0A0>:  43%|████▎     | 3/7 [00:00<00:00, 73.73 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001360_male_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003345_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53670>: 100%|██████████| 7/7 [00:00<00:00, 97.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3F40>: 100%|██████████| 7/7 [00:00<00:00, 104.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A90>: 100%|██████████| 7/7 [00:00<00:00, 63.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A22E0>: 100%|██████████| 7/7 [00:00<00:00, 81.88 Samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006433_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3BB0>: 100%|██████████| 7/7 [00:00<00:00, 85.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA60>: 100%|██████████| 7/7 [00:00<00:00, 89.39 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006262_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006503_female_Asian_28."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C70>: 100%|██████████| 7/7 [00:00<00:00, 75.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C40>: 100%|██████████| 7/7 [00:00<00:00, 107.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F31C0>: 100%|██████████| 7/7 [00:00<00:00, 132.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3E80>: 100%|██████████| 7/7 [00:00<00:00, 101.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3460>: 100%|██████████| 7/7 [00:00<00:00, 119.52 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000723_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003530_male_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDAC0>: 100%|██████████| 7/7 [00:00<00:00, 90.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919BB0>: 100%|██████████| 7/7 [00:00<00:00, 103.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919820>: 100%|██████████| 7/7 [00:00<00:00, 95.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61550>:  14%|█▍        | 1/7 [00:00<00:00, 24.29 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006225_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003277_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901CA0>: 100%|██████████| 7/7 [00:00<00:00, 96.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901E50>: 100%|██████████| 7/7 [00:00<00:00, 92.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3F10>: 100%|██████████| 7/7 [00:00<00:00, 102.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53220>: 100%|██████████| 7/7 [00:00<00:00, 99.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53340>:  29%|██▊       | 2/7 [00:00<00:00, 44.93 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006529_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000809_male_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58BB0>: 100%|██████████| 7/7 [00:00<00:00, 90.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53520>: 100%|██████████| 7/7 [00:00<00:00, 108.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53850>: 100%|██████████| 7/7 [00:00<00:00, 101.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D90>: 100%|██████████| 7/7 [00:00<00:00, 117.22 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7D58F70>: 100%|██████████| 7/7 [00:00<00:00, 121.67 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001985_female_Asian_34.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005494_female_Asian_47."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C160>: 100%|██████████| 7/7 [00:00<00:00, 123.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A17C0>: 100%|██████████| 7/7 [00:00<00:00, 107.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C40>: 100%|██████████| 7/7 [00:00<00:00, 88.05 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001615_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000564_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58790>: 100%|██████████| 7/7 [00:00<00:00, 100.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C40>: 100%|██████████| 7/7 [00:00<00:00, 87.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53400>: 100%|██████████| 7/7 [00:00<00:00, 97.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1E20>: 100%|██████████| 7/7 [00:00<00:00, 98.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58940>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000043_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005085_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58FA0>: 100%|██████████| 7/7 [00:00<00:00, 106.57 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7E668E0>: 100%|██████████| 7/7 [00:00<00:00, 73.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9016D0>: 100%|██████████| 7/7 [00:00<00:00, 90.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61E50>: 100%|██████████| 7/7 [00:00<00:00, 82.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53250>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006531_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005243_male_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53280>: 100%|██████████| 7/7 [00:00<00:00, 78.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D588E0>: 100%|██████████| 7/7 [00:00<00:00, 119.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9190D0>: 100%|██████████| 7/7 [00:00<00:00, 98.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A9340>: 100%|██████████| 7/7 [00:00<00:00, 95.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C70>:  57%|█████▋    | 4/7 [00:00<00:00, 86.35 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001381_male_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003997_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CA0>: 100%|██████████| 7/7 [00:00<00:00, 94.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD90>: 100%|██████████| 7/7 [00:00<00:00, 105.00 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D539A0>: 100%|██████████| 7/7 [00:00<00:00, 111.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919250>: 100%|██████████| 7/7 [00:00<00:00, 105.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B700>:  29%|██▊       | 2/7 [00:00<00:00, 37.60 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001542_female_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003022_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A00>: 100%|██████████| 7/7 [00:00<00:00, 85.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53670>: 100%|██████████| 7/7 [00:00<00:00, 112.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919490>: 100%|██████████| 7/7 [00:00<00:00, 101.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1640>: 100%|██████████| 7/7 [00:00<00:00, 94.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68EE0>:  29%|██▊       | 2/7 [00:00<00:00, 40.16 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005480_female_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003188_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D90>: 100%|██████████| 7/7 [00:00<00:00, 120.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9199D0>: 100%|██████████| 7/7 [00:00<00:00, 107.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11F0>: 100%|██████████| 7/7 [00:00<00:00, 106.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3550>: 100%|██████████| 7/7 [00:00<00:00, 128.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D688B0>: 100%|██████████| 7/7 [00:00<00:00, 104.79 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005499_male_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004388_female_Asian_45."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A30>: 100%|██████████| 7/7 [00:00<00:00, 82.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1520>: 100%|██████████| 7/7 [00:00<00:00, 101.64 Samples/s]         \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A90>: 100%|██████████| 7/7 [00:00<00:00, 97.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD2E0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006502_male_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001839_male_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD490>: 100%|██████████| 7/7 [00:00<00:00, 83.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C10>: 100%|██████████| 7/7 [00:00<00:00, 103.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1F0>: 100%|██████████| 7/7 [00:00<00:00, 86.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C40>: 100%|██████████| 7/7 [00:00<00:00, 88.34 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006711_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000044_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3AC0>: 100%|██████████| 7/7 [00:00<00:00, 63.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3BB0>: 100%|██████████| 7/7 [00:00<00:00, 63.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F31C0>: 100%|██████████| 7/7 [00:00<00:00, 84.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCCD0>: 100%|██████████| 7/7 [00:00<00:00, 91.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC7F0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000685_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001289_female_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF12E0>: 100%|██████████| 7/7 [00:00<00:00, 84.12 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC6919D0>: 100%|██████████| 7/7 [00:00<00:00, 130.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A90>: 100%|██████████| 7/7 [00:00<00:00, 107.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BB20>: 100%|██████████| 7/7 [00:00<00:00, 94.85 Samples/s]                  \n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FECDF7160>:  29%|██▊       | 2/7 [00:00<00:00, 50.65 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001244_male_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006956_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC2E0>: 100%|██████████| 7/7 [00:00<00:00, 105.93 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>: 100%|██████████| 7/7 [00:00<00:00, 123.86 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7190>: 100%|██████████| 7/7 [00:00<00:00, 101.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B670>: 100%|██████████| 7/7 [00:00<00:00, 80.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198E0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001503_male_Asian_27.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001059_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FFC1A2100>: 100%|██████████| 7/7 [00:00<00:00, 102.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC2B0>: 100%|██████████| 7/7 [00:00<00:00, 109.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F35B0>: 100%|██████████| 7/7 [00:00<00:00, 92.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53670>: 100%|██████████| 7/7 [00:00<00:00, 141.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919C40>:  71%|███████▏  | 5/7 [00:00<00:00, 74.31 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000722_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001119_female_Asian_27."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3460>: 100%|██████████| 7/7 [00:00<00:00, 80.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC640>: 100%|██████████| 7/7 [00:00<00:00, 85.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC490>: 100%|██████████| 7/7 [00:00<00:00, 106.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6D0>: 100%|██████████| 7/7 [00:00<00:00, 112.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61490>: 100%|██████████| 7/7 [00:00<00:00, 104.58 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001700_male_Asian_33.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000206_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53FA0>: 100%|██████████| 7/7 [00:00<00:00, 101.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC130>: 100%|██████████| 7/7 [00:00<00:00, 117.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A90>: 100%|██████████| 7/7 [00:00<00:00, 101.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DC0>:  57%|█████▋    | 4/7 [00:00<00:00, 68.25 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003019_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001787_female_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61A90>: 100%|██████████| 7/7 [00:00<00:00, 89.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61970>: 100%|██████████| 7/7 [00:00<00:00, 118.91 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3E20>: 100%|██████████| 7/7 [00:00<00:00, 76.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A90>: 100%|██████████| 7/7 [00:00<00:00, 78.22 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001058_female_Asian_28.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006395_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC0A0>: 100%|██████████| 7/7 [00:00<00:00, 82.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901400>: 100%|██████████| 7/7 [00:00<00:00, 73.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A00>: 100%|██████████| 7/7 [00:00<00:00, 76.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9018E0>: 100%|██████████| 7/7 [00:00<00:00, 84.00 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003514-1_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001769_male_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901B80>: 100%|██████████| 7/7 [00:00<00:00, 85.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53310>: 100%|██████████| 7/7 [00:00<00:00, 60.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F10>: 100%|██████████| 7/7 [00:00<00:00, 108.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A10A0>: 100%|██████████| 7/7 [00:00<00:00, 104.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61BB0>:  71%|███████▏  | 5/7 [00:00<00:00, 90.01 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001744_female_Asian_46.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000221_female_Asian_40."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1670>: 100%|██████████| 7/7 [00:00<00:00, 93.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53E50>: 100%|██████████| 7/7 [00:00<00:00, 130.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FA0>: 100%|██████████| 7/7 [00:00<00:00, 51.11 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006141_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1190>: 100%|██████████| 7/7 [00:00<00:00, 37.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A60>: 100%|██████████| 7/7 [00:00<00:00, 96.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3400>: 100%|██████████| 7/7 [00:00<00:00, 91.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FD0>:  14%|█▍        | 1/7 [00:00<00:00, 25.18 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001771_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003121_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3100>: 100%|██████████| 7/7 [00:00<00:00, 108.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53CD0>: 100%|██████████| 7/7 [00:00<00:00, 103.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919610>: 100%|██████████| 7/7 [00:00<00:00, 41.10 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006135_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919CD0>: 100%|██████████| 7/7 [00:00<00:00, 41.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CD0>: 100%|██████████| 7/7 [00:00<00:00, 104.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919160>: 100%|██████████| 7/7 [00:00<00:00, 128.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D90>: 100%|██████████| 7/7 [00:00<00:00, 95.26 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004485_male_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000714_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61910>: 100%|██████████| 7/7 [00:00<00:00, 81.05 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61E50>: 100%|██████████| 7/7 [00:00<00:00, 61.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533A0>: 100%|██████████| 7/7 [00:00<00:00, 105.72 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001718_male_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004273_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B940>: 100%|██████████| 7/7 [00:00<00:00, 78.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3520>: 100%|██████████| 7/7 [00:00<00:00, 91.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53130>: 100%|██████████| 7/7 [00:00<00:00, 87.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA60>: 100%|██████████| 7/7 [00:00<00:00, 75.97 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006200_male_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006364_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA312E0>: 100%|██████████| 7/7 [00:00<00:00, 77.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F10>: 100%|██████████| 7/7 [00:00<00:00, 89.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68E20>: 100%|██████████| 7/7 [00:00<00:00, 89.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F34F0>: 100%|██████████| 7/7 [00:00<00:00, 88.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919460>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000696_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005512_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F33A0>: 100%|██████████| 7/7 [00:00<00:00, 95.04 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8F3CA0>: 100%|██████████| 7/7 [00:00<00:00, 100.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3880>: 100%|██████████| 7/7 [00:00<00:00, 108.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9195E0>: 100%|██████████| 7/7 [00:00<00:00, 91.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919130>:  29%|██▊       | 2/7 [00:00<00:00, 43.60 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005463_female_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003064_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE20>: 100%|██████████| 7/7 [00:00<00:00, 89.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919310>: 100%|██████████| 7/7 [00:00<00:00, 84.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68E20>: 100%|██████████| 7/7 [00:00<00:00, 85.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B550>: 100%|██████████| 7/7 [00:00<00:00, 98.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC5E0>:  14%|█▍        | 1/7 [00:00<00:00, 24.63 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004391_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001174_male_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31E80>: 100%|██████████| 7/7 [00:00<00:00, 92.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68040>: 100%|██████████| 7/7 [00:00<00:00, 111.03 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF1AF0>: 100%|██████████| 7/7 [00:00<00:00, 96.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B6A0>: 100%|██████████| 7/7 [00:00<00:00, 104.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC70>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003881_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005547_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F10>: 100%|██████████| 7/7 [00:00<00:00, 90.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919310>: 100%|██████████| 7/7 [00:00<00:00, 100.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3160>: 100%|██████████| 7/7 [00:00<00:00, 90.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA90>: 100%|██████████| 7/7 [00:00<00:00, 88.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC0A0>:  29%|██▊       | 2/7 [00:00<00:00, 51.61 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003739_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003695_male_Asian_49."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9190A0>: 100%|██████████| 7/7 [00:00<00:00, 106.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>: 100%|██████████| 7/7 [00:00<00:00, 112.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919BE0>: 100%|██████████| 7/7 [00:00<00:00, 102.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC4F0>: 100%|██████████| 7/7 [00:00<00:00, 91.29 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001635_male_Asian_45.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003745_male_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC640>: 100%|██████████| 7/7 [00:00<00:00, 98.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D90>: 100%|██████████| 7/7 [00:00<00:00, 78.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>: 100%|██████████| 7/7 [00:00<00:00, 108.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>: 100%|██████████| 7/7 [00:00<00:00, 93.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61880>:  14%|█▍        | 1/7 [00:00<00:00, 18.79 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005460_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006627_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919070>: 100%|██████████| 7/7 [00:00<00:00, 83.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1670>: 100%|██████████| 7/7 [00:00<00:00, 87.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC3D0>: 100%|██████████| 7/7 [00:00<00:00, 95.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53850>: 100%|██████████| 7/7 [00:00<00:00, 102.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F70>:  57%|█████▋    | 4/7 [00:00<00:00, 83.25 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001277_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006751_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C618E0>: 100%|██████████| 7/7 [00:00<00:00, 96.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1B80>: 100%|██████████| 7/7 [00:00<00:00, 108.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9A0>: 100%|██████████| 7/7 [00:00<00:00, 107.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC160>: 100%|██████████| 7/7 [00:00<00:00, 111.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6D0>: 100%|██████████| 7/7 [00:00<00:00, 113.37 Samples/s]                 \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006400_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006535_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536A0>: 100%|██████████| 7/7 [00:00<00:00, 124.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53790>: 100%|██████████| 7/7 [00:00<00:00, 99.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58EE0>: 100%|██████████| 7/7 [00:00<00:00, 113.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D00>:  71%|███████▏  | 5/7 [00:00<00:00, 100.30 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004483_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005068_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901CA0>: 100%|██████████| 7/7 [00:00<00:00, 98.94 Samples/s] \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901190>: 100%|██████████| 7/7 [00:00<00:00, 80.94 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7D53670>: 100%|██████████| 7/7 [00:00<00:00, 99.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61910>: 100%|██████████| 7/7 [00:00<00:00, 99.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58FA0>:  43%|████▎     | 3/7 [00:00<00:00, 61.84 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005255_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001496-1_male_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D30>: 100%|██████████| 7/7 [00:00<00:00, 105.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61850>: 100%|██████████| 7/7 [00:00<00:00, 82.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612E0>: 100%|██████████| 7/7 [00:00<00:00, 103.26 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61790>: 100%|██████████| 7/7 [00:00<00:00, 91.90 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001637_female_Asian_27.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000733_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D30>: 100%|██████████| 7/7 [00:00<00:00, 75.75 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C619A0>: 100%|██████████| 7/7 [00:00<00:00, 70.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533D0>: 100%|██████████| 7/7 [00:00<00:00, 115.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D90>: 100%|██████████| 7/7 [00:00<00:00, 123.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C10>:  71%|███████▏  | 5/7 [00:00<00:00, 75.27 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003658_male_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003170_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1BB0>: 100%|██████████| 7/7 [00:00<00:00, 84.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53130>: 100%|██████████| 7/7 [00:00<00:00, 76.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3E20>: 100%|██████████| 7/7 [00:00<00:00, 95.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A19D0>: 100%|██████████| 7/7 [00:00<00:00, 110.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F33A0>: 100%|██████████| 7/7 [00:00<00:00, 131.70 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001082_female_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006708_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A30>: 100%|██████████| 7/7 [00:00<00:00, 102.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537C0>: 100%|██████████| 7/7 [00:00<00:00, 115.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53730>: 100%|██████████| 7/7 [00:00<00:00, 93.12 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9191F0>:  14%|█▍        | 1/7 [00:00<00:00, 22.94 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000814_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000067_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3460>: 100%|██████████| 7/7 [00:00<00:00, 100.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B80>: 100%|██████████| 7/7 [00:00<00:00, 94.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1BC6A0>: 100%|██████████| 7/7 [00:00<00:00, 85.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919A30>: 100%|██████████| 7/7 [00:00<00:00, 87.05 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000663_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003412_female_Asian_48."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9190A0>: 100%|██████████| 7/7 [00:00<00:00, 91.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A2100>: 100%|██████████| 7/7 [00:00<00:00, 82.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3E80>: 100%|██████████| 7/7 [00:00<00:00, 108.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBC730>: 100%|██████████| 7/7 [00:00<00:00, 67.04 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000216_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006360_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53160>: 100%|██████████| 7/7 [00:00<00:00, 95.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68FA0>: 100%|██████████| 7/7 [00:00<00:00, 94.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C190>: 100%|██████████| 7/7 [00:00<00:00, 82.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7190>: 100%|██████████| 7/7 [00:00<00:00, 77.86 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003559_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005522_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31E80>: 100%|██████████| 7/7 [00:00<00:00, 87.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC850>: 100%|██████████| 7/7 [00:00<00:00, 108.85 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA30>: 100%|██████████| 7/7 [00:00<00:00, 103.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3100>: 100%|██████████| 7/7 [00:00<00:00, 96.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA90>: 100%|██████████| 7/7 [00:00<00:00, 128.31 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001485_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001522_female_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC4C0>: 100%|██████████| 7/7 [00:00<00:00, 79.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9195E0>: 100%|██████████| 7/7 [00:00<00:00, 81.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919970>: 100%|██████████| 7/7 [00:00<00:00, 102.71 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005016_female_Asian_46.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003532_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EB0>: 100%|██████████| 7/7 [00:00<00:00, 77.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612B0>: 100%|██████████| 7/7 [00:00<00:00, 75.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537F0>: 100%|██████████| 7/7 [00:00<00:00, 117.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61490>: 100%|██████████| 7/7 [00:00<00:00, 102.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D530D0>:  57%|█████▋    | 4/7 [00:00<00:00, 68.47 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000498_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001788_male_Asian_28."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC220>: 100%|██████████| 7/7 [00:00<00:00, 94.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC610>: 100%|██████████| 7/7 [00:00<00:00, 113.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53460>: 100%|██████████| 7/7 [00:00<00:00, 90.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC670>: 100%|██████████| 7/7 [00:00<00:00, 108.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D539D0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006927_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001389_male_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6D0>: 100%|██████████| 7/7 [00:00<00:00, 86.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C618E0>: 100%|██████████| 7/7 [00:00<00:00, 80.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61430>: 100%|██████████| 7/7 [00:00<00:00, 117.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC2E0>: 100%|██████████| 7/7 [00:00<00:00, 81.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9014C0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006350_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003009_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F70>: 100%|██████████| 7/7 [00:00<00:00, 87.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCFA0>: 100%|██████████| 7/7 [00:00<00:00, 98.89 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E50>: 100%|██████████| 7/7 [00:00<00:00, 103.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C10>: 100%|██████████| 7/7 [00:00<00:00, 111.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1CD0>:  57%|█████▋    | 4/7 [00:00<00:00, 68.43 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001403_male_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001790_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9018E0>: 100%|██████████| 7/7 [00:00<00:00, 93.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A60>: 100%|██████████| 7/7 [00:00<00:00, 93.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C10>: 100%|██████████| 7/7 [00:00<00:00, 75.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53AC0>: 100%|██████████| 7/7 [00:00<00:00, 83.90 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001648_male_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005232_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901940>: 100%|██████████| 7/7 [00:00<00:00, 96.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCA0>: 100%|██████████| 7/7 [00:00<00:00, 76.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901520>: 100%|██████████| 7/7 [00:00<00:00, 86.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A13D0>: 100%|██████████| 7/7 [00:00<00:00, 91.46 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003317_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006690_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D587C0>: 100%|██████████| 7/7 [00:00<00:00, 97.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F70>: 100%|██████████| 7/7 [00:00<00:00, 134.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CD0>: 100%|██████████| 7/7 [00:00<00:00, 97.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61910>: 100%|██████████| 7/7 [00:00<00:00, 90.07 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53940>:  29%|██▊       | 2/7 [00:00<00:00, 47.34 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004484_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006639_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C619A0>: 100%|██████████| 7/7 [00:00<00:00, 117.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A30>: 100%|██████████| 7/7 [00:00<00:00, 78.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D00>: 100%|██████████| 7/7 [00:00<00:00, 81.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3400>: 100%|██████████| 7/7 [00:00<00:00, 101.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901340>:  14%|█▍        | 1/7 [00:00<00:00, 25.64 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000283_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001311_female_Asian_34."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537F0>: 100%|██████████| 7/7 [00:00<00:00, 110.50 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EB0>: 100%|██████████| 7/7 [00:00<00:00, 111.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C40>: 100%|██████████| 7/7 [00:00<00:00, 104.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919CA0>: 100%|██████████| 7/7 [00:00<00:00, 94.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B220>:  14%|█▍        | 1/7 [00:00<00:00, 22.52 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005404_female_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000014_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D539A0>: 100%|██████████| 7/7 [00:00<00:00, 90.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>: 100%|██████████| 7/7 [00:00<00:00, 103.49 Samples/s]         \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A93D0>: 100%|██████████| 7/7 [00:00<00:00, 80.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9193D0>: 100%|██████████| 7/7 [00:00<00:00, 103.86 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006563_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006476_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9199A0>: 100%|██████████| 7/7 [00:00<00:00, 89.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B1C0>: 100%|██████████| 7/7 [00:00<00:00, 80.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3220>: 100%|██████████| 7/7 [00:00<00:00, 87.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68FD0>: 100%|██████████| 7/7 [00:00<00:00, 98.03 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005043_female_Asian_43.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006233_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BE20>: 100%|██████████| 7/7 [00:00<00:00, 32.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD90>: 100%|██████████| 7/7 [00:00<00:00, 43.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9197F0>: 100%|██████████| 7/7 [00:00<00:00, 124.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE50>: 100%|██████████| 7/7 [00:00<00:00, 104.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D90>:  57%|█████▋    | 4/7 [00:00<00:00, 62.88 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001987_female_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005093_female_Asian_49."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53400>: 100%|██████████| 7/7 [00:00<00:00, 90.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F32B0>: 100%|██████████| 7/7 [00:00<00:00, 81.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCA0>: 100%|██████████| 7/7 [00:00<00:00, 132.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A00>: 100%|██████████| 7/7 [00:00<00:00, 82.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD30>:  29%|██▊       | 2/7 [00:00<00:00, 49.33 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005041_female_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005554_female_Asian_40."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B1C0>: 100%|██████████| 7/7 [00:00<00:00, 91.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF1AF0>: 100%|██████████| 7/7 [00:00<00:00, 106.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31CA0>: 100%|██████████| 7/7 [00:00<00:00, 108.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A90>: 100%|██████████| 7/7 [00:00<00:00, 81.64 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005502_female_Asian_49.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003380_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CD0>: 100%|██████████| 7/7 [00:00<00:00, 100.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919670>: 100%|██████████| 7/7 [00:00<00:00, 96.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919910>: 100%|██████████| 7/7 [00:00<00:00, 90.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC070>: 100%|██████████| 7/7 [00:00<00:00, 94.74 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003521_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001488_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FA0>: 100%|██████████| 7/7 [00:00<00:00, 73.73 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919130>: 100%|██████████| 7/7 [00:00<00:00, 104.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31F10>: 100%|██████████| 7/7 [00:00<00:00, 109.54 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3EE0>: 100%|██████████| 7/7 [00:00<00:00, 88.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919B50>:  29%|██▊       | 2/7 [00:00<00:00, 44.66 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003510_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006438_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53040>: 100%|██████████| 7/7 [00:00<00:00, 94.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198B0>: 100%|██████████| 7/7 [00:00<00:00, 123.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533A0>: 100%|██████████| 7/7 [00:00<00:00, 92.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9190D0>: 100%|██████████| 7/7 [00:00<00:00, 80.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF40>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001843_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001813_male_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53400>: 100%|██████████| 7/7 [00:00<00:00, 112.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53310>: 100%|██████████| 7/7 [00:00<00:00, 73.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612E0>: 100%|██████████| 7/7 [00:00<00:00, 108.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D90>: 100%|██████████| 7/7 [00:00<00:00, 104.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCEB0>:  14%|█▍        | 1/7 [00:00<00:00, 19.53 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003332_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003676_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D589A0>: 100%|██████████| 7/7 [00:00<00:00, 84.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C10>: 100%|██████████| 7/7 [00:00<00:00, 61.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F70>: 100%|██████████| 7/7 [00:00<00:00, 107.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC2B0>: 100%|██████████| 7/7 [00:00<00:00, 111.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C40>:  71%|███████▏  | 5/7 [00:00<00:00, 73.98 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006709_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006954_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1100>: 100%|██████████| 7/7 [00:00<00:00, 87.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A00>: 100%|██████████| 7/7 [00:00<00:00, 87.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC640>: 100%|██████████| 7/7 [00:00<00:00, 50.87 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006137_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDF10>: 100%|██████████| 7/7 [00:00<00:00, 44.69 Samples/s]                \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD2E0>: 100%|██████████| 7/7 [00:00<00:00, 128.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1DC0>: 100%|██████████| 7/7 [00:00<00:00, 87.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9018E0>:  29%|██▊       | 2/7 [00:00<00:00, 33.04 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000764_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000348_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A00>: 100%|██████████| 7/7 [00:00<00:00, 87.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1B80>: 100%|██████████| 7/7 [00:00<00:00, 85.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D60>: 100%|██████████| 7/7 [00:00<00:00, 108.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61580>: 100%|██████████| 7/7 [00:00<00:00, 118.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533D0>:  71%|███████▏  | 5/7 [00:00<00:00, 77.65 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001575_female_Asian_30.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005409_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A90>: 100%|██████████| 7/7 [00:00<00:00, 91.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C613A0>: 100%|██████████| 7/7 [00:00<00:00, 115.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1820>: 100%|██████████| 7/7 [00:00<00:00, 105.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A30>: 100%|██████████| 7/7 [00:00<00:00, 94.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>:  86%|████████▌ | 6/7 [00:00<00:00, 109.66 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001064_female_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001600_male_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>: 100%|██████████| 7/7 [00:00<00:00, 124.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1070>: 100%|██████████| 7/7 [00:00<00:00, 131.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C40>: 100%|██████████| 7/7 [00:00<00:00, 107.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B80>: 100%|██████████| 7/7 [00:00<00:00, 105.85 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198B0>:  71%|███████▏  | 5/7 [00:00<00:00, 78.85 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005286_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003416_male_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F40>: 100%|██████████| 7/7 [00:00<00:00, 107.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A00>: 100%|██████████| 7/7 [00:00<00:00, 117.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECCA5B50>: 100%|██████████| 7/7 [00:00<00:00, 88.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A90>: 100%|██████████| 7/7 [00:00<00:00, 113.76 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3490>:  29%|██▊       | 2/7 [00:00<00:00, 36.53 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004326_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003535_male_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D60>: 100%|██████████| 7/7 [00:00<00:00, 96.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7F70>: 100%|██████████| 7/7 [00:00<00:00, 75.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C40>: 100%|██████████| 7/7 [00:00<00:00, 97.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C3D0>: 100%|██████████| 7/7 [00:00<00:00, 95.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53130>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006580_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001456_male_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919250>: 100%|██████████| 7/7 [00:00<00:00, 98.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B6A0>: 100%|██████████| 7/7 [00:00<00:00, 91.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9197F0>: 100%|██████████| 7/7 [00:00<00:00, 127.37 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919760>: 100%|██████████| 7/7 [00:00<00:00, 101.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7E668E0>:  71%|███████▏  | 5/7 [00:00<00:00, 92.47 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000344_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005436_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53310>: 100%|██████████| 7/7 [00:00<00:00, 94.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F40>: 100%|██████████| 7/7 [00:00<00:00, 109.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD910>: 100%|██████████| 7/7 [00:00<00:00, 120.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCAC0>: 100%|██████████| 7/7 [00:00<00:00, 94.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919460>: 100%|██████████| 7/7 [00:00<00:00, 113.08 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006473_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001407_male_Asian_43."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53BB0>: 100%|██████████| 7/7 [00:00<00:00, 82.37 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FAABCCF70>: 100%|██████████| 7/7 [00:00<00:00, 91.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198E0>: 100%|██████████| 7/7 [00:00<00:00, 107.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA00>:  29%|██▊       | 2/7 [00:00<00:00, 49.24 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006615_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001786_male_Asian_28."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68FA0>: 100%|██████████| 7/7 [00:00<00:00, 83.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9191F0>: 100%|██████████| 7/7 [00:00<00:00, 102.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C2E0>: 100%|██████████| 7/7 [00:00<00:00, 115.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7F70>: 100%|██████████| 7/7 [00:00<00:00, 88.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC640>:  57%|█████▋    | 4/7 [00:00<00:00, 78.12 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000267_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001049_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9199D0>: 100%|██████████| 7/7 [00:00<00:00, 111.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537F0>: 100%|██████████| 7/7 [00:00<00:00, 105.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A90>: 100%|██████████| 7/7 [00:00<00:00, 100.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC0A0>: 100%|██████████| 7/7 [00:00<00:00, 80.78 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001908_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006167_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53160>: 100%|██████████| 7/7 [00:00<00:00, 51.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F70>: 100%|██████████| 7/7 [00:00<00:00, 47.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919220>: 100%|██████████| 7/7 [00:00<00:00, 106.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53CA0>: 100%|██████████| 7/7 [00:00<00:00, 89.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3430>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000748-1_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001012_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535E0>: 100%|██████████| 7/7 [00:00<00:00, 63.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3880>: 100%|██████████| 7/7 [00:00<00:00, 102.11 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61430>: 100%|██████████| 7/7 [00:00<00:00, 120.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC0A0>: 100%|██████████| 7/7 [00:00<00:00, 68.89 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001659_male_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001074_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901040>: 100%|██████████| 7/7 [00:00<00:00, 132.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58790>: 100%|██████████| 7/7 [00:00<00:00, 66.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC070>: 100%|██████████| 7/7 [00:00<00:00, 103.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901CA0>: 100%|██████████| 7/7 [00:00<00:00, 106.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61880>: 100%|██████████| 7/7 [00:00<00:00, 115.90 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006749_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000576_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1310>: 100%|██████████| 7/7 [00:00<00:00, 136.65 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC340>: 100%|██████████| 7/7 [00:00<00:00, 96.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535B0>: 100%|██████████| 7/7 [00:00<00:00, 115.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53670>:  57%|█████▋    | 4/7 [00:00<00:00, 82.33 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003816_male_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004389_female_Asian_36."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1F10>: 100%|██████████| 7/7 [00:00<00:00, 101.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA00>: 100%|██████████| 7/7 [00:00<00:00, 95.15 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536A0>: 100%|██████████| 7/7 [00:00<00:00, 64.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A60>: 100%|██████████| 7/7 [00:00<00:00, 101.30 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001387_female_Asian_21.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003524_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A13D0>: 100%|██████████| 7/7 [00:00<00:00, 110.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D00>: 100%|██████████| 7/7 [00:00<00:00, 128.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C10>: 100%|██████████| 7/7 [00:00<00:00, 107.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDBB0>: 100%|██████████| 7/7 [00:00<00:00, 91.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A17C0>:  43%|████▎     | 3/7 [00:00<00:00, 57.01 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000643_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000228_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58940>: 100%|██████████| 7/7 [00:00<00:00, 100.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58940>: 100%|██████████| 7/7 [00:00<00:00, 65.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EB0>: 100%|██████████| 7/7 [00:00<00:00, 95.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61430>: 100%|██████████| 7/7 [00:00<00:00, 106.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58910>:  29%|██▊       | 2/7 [00:00<00:00, 36.34 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001004_female_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003136_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C613D0>: 100%|██████████| 7/7 [00:00<00:00, 86.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61820>: 100%|██████████| 7/7 [00:00<00:00, 105.01 Samples/s]         \n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7D53820>: 100%|██████████| 7/7 [00:00<00:00, 117.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D534F0>: 100%|██████████| 7/7 [00:00<00:00, 147.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD580>: 100%|██████████| 7/7 [00:00<00:00, 98.44 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005421_female_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003068_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD940>: 100%|██████████| 7/7 [00:00<00:00, 96.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53AC0>: 100%|██████████| 7/7 [00:00<00:00, 96.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD250>: 100%|██████████| 7/7 [00:00<00:00, 98.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53160>: 100%|██████████| 7/7 [00:00<00:00, 134.20 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006686_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005278_male_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533D0>: 100%|██████████| 7/7 [00:00<00:00, 118.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A00>: 100%|██████████| 7/7 [00:00<00:00, 95.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF14C0>: 100%|██████████| 7/7 [00:00<00:00, 104.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDDF0>:  29%|██▊       | 2/7 [00:00<00:00, 36.82 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003084_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000080_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF1EE0>: 100%|██████████| 7/7 [00:00<00:00, 94.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD820>: 100%|██████████| 7/7 [00:00<00:00, 93.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53970>: 100%|██████████| 7/7 [00:00<00:00, 89.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF12E0>: 100%|██████████| 7/7 [00:00<00:00, 95.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3520>:  14%|█▍        | 1/7 [00:00<00:00, 23.11 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001221_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006359_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDB50>: 100%|██████████| 7/7 [00:00<00:00, 93.44 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC400>: 100%|██████████| 7/7 [00:00<00:00, 80.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53FD0>: 100%|██████████| 7/7 [00:00<00:00, 101.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC070>: 100%|██████████| 7/7 [00:00<00:00, 137.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A90>: 100%|██████████| 7/7 [00:00<00:00, 94.34 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003176_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001717_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC40>: 100%|██████████| 7/7 [00:00<00:00, 97.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA90>: 100%|██████████| 7/7 [00:00<00:00, 91.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC400>: 100%|██████████| 7/7 [00:00<00:00, 83.58 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001304_male_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001409_male_Asian_41."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB14250>: 100%|██████████| 7/7 [00:00<00:00, 126.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31BE0>: 100%|██████████| 7/7 [00:00<00:00, 101.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31F70>: 100%|██████████| 7/7 [00:00<00:00, 112.54 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68D60>: 100%|██████████| 7/7 [00:00<00:00, 83.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A00>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001990_male_Asian_35.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000662_female_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECCA59A0>: 100%|██████████| 7/7 [00:00<00:00, 94.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53AF0>: 100%|██████████| 7/7 [00:00<00:00, 82.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC430>: 100%|██████████| 7/7 [00:00<00:00, 95.30 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919670>: 100%|██████████| 7/7 [00:00<00:00, 73.02 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001100_female_Asian_43.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006070_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533A0>: 100%|██████████| 7/7 [00:00<00:00, 35.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F10>: 100%|██████████| 7/7 [00:00<00:00, 37.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919400>: 100%|██████████| 7/7 [00:00<00:00, 88.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC520>: 100%|██████████| 7/7 [00:00<00:00, 69.65 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001740_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003589_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EB0>: 100%|██████████| 7/7 [00:00<00:00, 85.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53670>: 100%|██████████| 7/7 [00:00<00:00, 89.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919790>: 100%|██████████| 7/7 [00:00<00:00, 95.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901280>: 100%|██████████| 7/7 [00:00<00:00, 97.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C40>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006684_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003118_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF10>: 100%|██████████| 7/7 [00:00<00:00, 95.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53460>: 100%|██████████| 7/7 [00:00<00:00, 95.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61AF0>: 100%|██████████| 7/7 [00:00<00:00, 103.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53E50>: 100%|██████████| 7/7 [00:00<00:00, 119.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC3D0>:  86%|████████▌ | 6/7 [00:00<00:00, 86.21 Samples/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001267_female_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003087_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC3D0>: 100%|██████████| 7/7 [00:00<00:00, 98.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901B80>: 100%|██████████| 7/7 [00:00<00:00, 117.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58BB0>: 100%|██████████| 7/7 [00:00<00:00, 74.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D530D0>: 100%|██████████| 7/7 [00:00<00:00, 99.41 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003839_male_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004206_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCAF0>: 100%|██████████| 7/7 [00:00<00:00, 105.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901940>: 100%|██████████| 7/7 [00:00<00:00, 102.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D532B0>: 100%|██████████| 7/7 [00:00<00:00, 85.43 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1190>: 100%|██████████| 7/7 [00:00<00:00, 109.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A14F0>:  43%|████▎     | 3/7 [00:00<00:00, 66.98 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005495_female_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000750_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A60>: 100%|██████████| 7/7 [00:00<00:00, 92.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A14F0>: 100%|██████████| 7/7 [00:00<00:00, 68.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58B80>: 100%|██████████| 7/7 [00:00<00:00, 98.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D30>: 100%|██████████| 7/7 [00:00<00:00, 107.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901340>:  43%|████▎     | 3/7 [00:00<00:00, 50.57 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005556_male_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001090_male_Asian_34."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58A00>: 100%|██████████| 7/7 [00:00<00:00, 111.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58AC0>: 100%|██████████| 7/7 [00:00<00:00, 119.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1CA0>: 100%|██████████| 7/7 [00:00<00:00, 113.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901190>: 100%|██████████| 7/7 [00:00<00:00, 123.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD610>:  71%|███████▏  | 5/7 [00:00<00:00, 70.27 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000012_male_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003880_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1FD0>: 100%|██████████| 7/7 [00:00<00:00, 77.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDDF0>: 100%|██████████| 7/7 [00:00<00:00, 98.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A14F0>: 100%|██████████| 7/7 [00:00<00:00, 82.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1CA0>: 100%|██████████| 7/7 [00:00<00:00, 72.57 Samples/s]                  \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001009_female_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003463_male_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919310>: 100%|██████████| 7/7 [00:00<00:00, 125.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A30>: 100%|██████████| 7/7 [00:00<00:00, 104.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53550>: 100%|██████████| 7/7 [00:00<00:00, 85.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919550>: 100%|██████████| 7/7 [00:00<00:00, 116.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECCA5CD0>:  14%|█▍        | 1/7 [00:00<00:00, 24.44 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003389_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001326_male_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3A0>: 100%|██████████| 7/7 [00:00<00:00, 82.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F10>: 100%|██████████| 7/7 [00:00<00:00, 80.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3520>: 100%|██████████| 7/7 [00:00<00:00, 130.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF1EE0>: 100%|██████████| 7/7 [00:00<00:00, 74.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EB0>:  14%|█▍        | 1/7 [00:00<00:00, 21.97 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006444_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006269_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B220>: 100%|██████████| 7/7 [00:00<00:00, 98.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7E66820>: 100%|██████████| 7/7 [00:00<00:00, 101.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B100>: 100%|██████████| 7/7 [00:00<00:00, 120.39 Samples/s]         \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B940>: 100%|██████████| 7/7 [00:00<00:00, 77.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B50>:  43%|████▎     | 3/7 [00:00<00:00, 65.50 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005092_male_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006731_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B670>: 100%|██████████| 7/7 [00:00<00:00, 105.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7F70>: 100%|██████████| 7/7 [00:00<00:00, 107.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD550>: 100%|██████████| 7/7 [00:00<00:00, 128.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC3D0>: 100%|██████████| 7/7 [00:00<00:00, 97.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533D0>:  71%|███████▏  | 5/7 [00:00<00:00, 80.63 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006677_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001712_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D534F0>: 100%|██████████| 7/7 [00:00<00:00, 82.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D90>: 100%|██████████| 7/7 [00:00<00:00, 94.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD550>: 100%|██████████| 7/7 [00:00<00:00, 74.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7940>: 100%|██████████| 7/7 [00:00<00:00, 88.32 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001248_female_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003285_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECCA5B50>: 100%|██████████| 7/7 [00:00<00:00, 73.41 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD310>: 100%|██████████| 7/7 [00:00<00:00, 74.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD280>: 100%|██████████| 7/7 [00:00<00:00, 103.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61850>: 100%|██████████| 7/7 [00:00<00:00, 99.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDFA0>:  29%|██▊       | 2/7 [00:00<00:00, 36.14 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000070_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001755_male_Asian_38."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCA0>: 100%|██████████| 7/7 [00:00<00:00, 83.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61430>: 100%|██████████| 7/7 [00:00<00:00, 92.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53790>: 100%|██████████| 7/7 [00:00<00:00, 87.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF1BB0>: 100%|██████████| 7/7 [00:00<00:00, 79.85 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006656_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003863_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D588E0>: 100%|██████████| 7/7 [00:00<00:00, 126.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53EB0>: 100%|██████████| 7/7 [00:00<00:00, 109.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD00>: 100%|██████████| 7/7 [00:00<00:00, 106.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901940>: 100%|██████████| 7/7 [00:00<00:00, 122.76 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD0A0>:  29%|██▊       | 2/7 [00:00<00:00, 29.30 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006700_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001756_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901E50>: 100%|██████████| 7/7 [00:00<00:00, 61.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901CA0>: 100%|██████████| 7/7 [00:00<00:00, 88.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD100>: 100%|██████████| 7/7 [00:00<00:00, 94.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C40>: 100%|██████████| 7/7 [00:00<00:00, 86.30 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3DF0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006612_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001115_female_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68FA0>: 100%|██████████| 7/7 [00:00<00:00, 92.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58B80>: 100%|██████████| 7/7 [00:00<00:00, 91.43 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3400>: 100%|██████████| 7/7 [00:00<00:00, 91.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE50>: 100%|██████████| 7/7 [00:00<00:00, 109.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533D0>:  43%|████▎     | 3/7 [00:00<00:00, 60.77 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001433_male_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004072_male_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F37C0>: 100%|██████████| 7/7 [00:00<00:00, 94.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E80>: 100%|██████████| 7/7 [00:00<00:00, 74.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53580>: 100%|██████████| 7/7 [00:00<00:00, 93.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58C40>: 100%|██████████| 7/7 [00:00<00:00, 88.74 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001464-1_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001585_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919490>: 100%|██████████| 7/7 [00:00<00:00, 86.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919040>: 100%|██████████| 7/7 [00:00<00:00, 95.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3610>: 100%|██████████| 7/7 [00:00<00:00, 93.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919100>: 100%|██████████| 7/7 [00:00<00:00, 94.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53130>:  14%|█▍        | 1/7 [00:00<00:00, 25.16 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003074_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000566_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536D0>: 100%|██████████| 7/7 [00:00<00:00, 92.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1370>: 100%|██████████| 7/7 [00:00<00:00, 80.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901760>: 100%|██████████| 7/7 [00:00<00:00, 110.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A90>: 100%|██████████| 7/7 [00:00<00:00, 75.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1100>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000676_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003424_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919E50>: 100%|██████████| 7/7 [00:00<00:00, 101.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901490>: 100%|██████████| 7/7 [00:00<00:00, 100.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68EE0>: 100%|██████████| 7/7 [00:00<00:00, 95.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919100>: 100%|██████████| 7/7 [00:00<00:00, 115.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CD0>:  29%|██▊       | 2/7 [00:00<00:00, 42.86 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003448_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000641_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58940>: 100%|██████████| 7/7 [00:00<00:00, 96.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D589A0>: 100%|██████████| 7/7 [00:00<00:00, 98.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A17C0>: 100%|██████████| 7/7 [00:00<00:00, 121.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F32B0>: 100%|██████████| 7/7 [00:00<00:00, 78.51 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003182_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006065_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D530D0>: 100%|██████████| 7/7 [00:00<00:00, 39.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D60>: 100%|██████████| 7/7 [00:00<00:00, 42.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1B50>: 100%|██████████| 7/7 [00:00<00:00, 81.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D30>: 100%|██████████| 7/7 [00:00<00:00, 96.18 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000028_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001606_female_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A19D0>: 100%|██████████| 7/7 [00:00<00:00, 67.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D586A0>: 100%|██████████| 7/7 [00:00<00:00, 82.38 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7D58FA0>: 100%|██████████| 7/7 [00:00<00:00, 88.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B80>: 100%|██████████| 7/7 [00:00<00:00, 121.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53280>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005108_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001760_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7D53A30>: 100%|██████████| 7/7 [00:00<00:00, 89.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919760>: 100%|██████████| 7/7 [00:00<00:00, 64.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A90>: 100%|██████████| 7/7 [00:00<00:00, 94.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919220>: 100%|██████████| 7/7 [00:00<00:00, 80.35 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001820_female_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003400_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919160>: 100%|██████████| 7/7 [00:00<00:00, 71.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7E66820>: 100%|██████████| 7/7 [00:00<00:00, 93.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C619A0>: 100%|██████████| 7/7 [00:00<00:00, 118.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53610>: 100%|██████████| 7/7 [00:00<00:00, 106.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDDF0>:  43%|████▎     | 3/7 [00:00<00:00, 43.94 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001413_male_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003408_male_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61610>: 100%|██████████| 7/7 [00:00<00:00, 85.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61970>: 100%|██████████| 7/7 [00:00<00:00, 66.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B970>: 100%|██████████| 7/7 [00:00<00:00, 101.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31FD0>: 100%|██████████| 7/7 [00:00<00:00, 109.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31FD0>:  43%|████▎     | 3/7 [00:00<00:00, 52.70 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005259_male_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005472_female_Asian_45."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7E66850>: 100%|██████████| 7/7 [00:00<00:00, 75.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>: 100%|██████████| 7/7 [00:00<00:00, 105.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B8B0>: 100%|██████████| 7/7 [00:00<00:00, 96.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D530D0>: 100%|██████████| 7/7 [00:00<00:00, 143.16 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF1AC0>: 100%|██████████| 7/7 [00:00<00:00, 97.24 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000548_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003780_male_Asian_48."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C613A0>: 100%|██████████| 7/7 [00:00<00:00, 102.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD940>: 100%|██████████| 7/7 [00:00<00:00, 97.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDB50>: 100%|██████████| 7/7 [00:00<00:00, 98.09 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003403_male_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006173_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.PngImagePlugin.PngImageFile image mode=RGB size=384x512 at 0x7F8FD7D58820>: 100%|██████████| 7/7 [00:00<00:00, 42.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901B80>: 100%|██████████| 7/7 [00:00<00:00, 47.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D90>: 100%|██████████| 7/7 [00:00<00:00, 133.89 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D588E0>: 100%|██████████| 7/7 [00:00<00:00, 99.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>: 100%|██████████| 7/7 [00:00<00:00, 100.14 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003052_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005484_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58700>: 100%|██████████| 7/7 [00:00<00:00, 109.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE20>: 100%|██████████| 7/7 [00:00<00:00, 88.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919220>: 100%|██████████| 7/7 [00:00<00:00, 82.75 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003341_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005291_male_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C40>: 100%|██████████| 7/7 [00:00<00:00, 87.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198B0>: 100%|██████████| 7/7 [00:00<00:00, 100.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919490>: 100%|██████████| 7/7 [00:00<00:00, 87.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1C0>: 100%|██████████| 7/7 [00:00<00:00, 103.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD6D0>:  29%|██▊       | 2/7 [00:00<00:00, 41.55 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004431_female_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000278_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9191F0>: 100%|██████████| 7/7 [00:00<00:00, 106.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3AF0>: 100%|██████████| 7/7 [00:00<00:00, 94.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198E0>: 100%|██████████| 7/7 [00:00<00:00, 94.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A30>: 100%|██████████| 7/7 [00:00<00:00, 115.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1AF0>: 100%|██████████| 7/7 [00:00<00:00, 135.28 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001129_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003452_female_Asian_48."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3D90>: 100%|██████████| 7/7 [00:00<00:00, 104.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919E20>: 100%|██████████| 7/7 [00:00<00:00, 106.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B20>: 100%|██████████| 7/7 [00:00<00:00, 96.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1550>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003051_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004090_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3EE0>: 100%|██████████| 7/7 [00:00<00:00, 73.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EE0>: 100%|██████████| 7/7 [00:00<00:00, 90.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1C0>: 100%|██████████| 7/7 [00:00<00:00, 102.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC370>: 100%|██████████| 7/7 [00:00<00:00, 138.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53400>:  71%|███████▏  | 5/7 [00:00<00:00, 65.89 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001187-1_male_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003426_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533A0>: 100%|██████████| 7/7 [00:00<00:00, 77.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A90>: 100%|██████████| 7/7 [00:00<00:00, 79.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A10A0>: 100%|██████████| 7/7 [00:00<00:00, 115.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919460>: 100%|██████████| 7/7 [00:00<00:00, 100.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3760>:  43%|████▎     | 3/7 [00:00<00:00, 53.21 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001777_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006582_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1850>: 100%|██████████| 7/7 [00:00<00:00, 80.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1160>: 100%|██████████| 7/7 [00:00<00:00, 73.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3AC0>: 100%|██████████| 7/7 [00:00<00:00, 95.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536A0>: 100%|██████████| 7/7 [00:00<00:00, 83.72 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003376_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006224_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3BE0>: 100%|██████████| 7/7 [00:00<00:00, 37.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A60>: 100%|██████████| 7/7 [00:00<00:00, 30.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1670>: 100%|██████████| 7/7 [00:00<00:00, 78.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1580>: 100%|██████████| 7/7 [00:00<00:00, 94.23 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006555_female_Asian_21.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006419_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D588B0>: 100%|██████████| 7/7 [00:00<00:00, 111.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1310>: 100%|██████████| 7/7 [00:00<00:00, 95.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535B0>: 100%|██████████| 7/7 [00:00<00:00, 81.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61280>: 100%|██████████| 7/7 [00:00<00:00, 84.82 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006104_male_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001520_female_Asian_47."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C613A0>: 100%|██████████| 7/7 [00:00<00:00, 101.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9192B0>: 100%|██████████| 7/7 [00:00<00:00, 98.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58FA0>: 100%|██████████| 7/7 [00:00<00:00, 116.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61580>: 100%|██████████| 7/7 [00:00<00:00, 99.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D30>:  57%|█████▋    | 4/7 [00:00<00:00, 63.11 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004251_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001170_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B940>: 100%|██████████| 7/7 [00:00<00:00, 99.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C613A0>: 100%|██████████| 7/7 [00:00<00:00, 68.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B220>: 100%|██████████| 7/7 [00:00<00:00, 81.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECCA5CD0>: 100%|██████████| 7/7 [00:00<00:00, 99.66 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001138_female_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003486_female_Asian_34."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E20>: 100%|██████████| 7/7 [00:00<00:00, 75.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D00>: 100%|██████████| 7/7 [00:00<00:00, 102.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D90>: 100%|██████████| 7/7 [00:00<00:00, 89.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61550>: 100%|██████████| 7/7 [00:00<00:00, 85.94 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004488_male_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000640_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C616D0>: 100%|██████████| 7/7 [00:00<00:00, 110.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61610>: 100%|██████████| 7/7 [00:00<00:00, 92.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5E0>: 100%|██████████| 7/7 [00:00<00:00, 85.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C615E0>: 100%|██████████| 7/7 [00:00<00:00, 85.01 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003241_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000547_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61550>: 100%|██████████| 7/7 [00:00<00:00, 90.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F40>: 100%|██████████| 7/7 [00:00<00:00, 95.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE80>: 100%|██████████| 7/7 [00:00<00:00, 90.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61580>: 100%|██████████| 7/7 [00:00<00:00, 102.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDFA0>:  29%|██▊       | 2/7 [00:00<00:00, 41.10 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003014_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004421_male_Asian_30."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A93D0>: 100%|██████████| 7/7 [00:00<00:00, 83.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58BB0>: 100%|██████████| 7/7 [00:00<00:00, 86.28 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>: 100%|██████████| 7/7 [00:00<00:00, 79.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9196A0>: 100%|██████████| 7/7 [00:00<00:00, 97.55 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003884_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001489_male_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EE0>: 100%|██████████| 7/7 [00:00<00:00, 86.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919490>: 100%|██████████| 7/7 [00:00<00:00, 119.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD910>: 100%|██████████| 7/7 [00:00<00:00, 94.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58940>: 100%|██████████| 7/7 [00:00<00:00, 79.00 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004202_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003037_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919040>: 100%|██████████| 7/7 [00:00<00:00, 114.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58940>: 100%|██████████| 7/7 [00:00<00:00, 83.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919C40>: 100%|██████████| 7/7 [00:00<00:00, 75.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD040>: 100%|██████████| 7/7 [00:00<00:00, 88.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD820>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006752_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006568_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD30>: 100%|██████████| 7/7 [00:00<00:00, 116.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1BE0>: 100%|██████████| 7/7 [00:00<00:00, 94.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D00>: 100%|██████████| 7/7 [00:00<00:00, 104.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D30>: 100%|██████████| 7/7 [00:00<00:00, 102.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C40>:  29%|██▊       | 2/7 [00:00<00:00, 39.51 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006710_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003787_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C40>: 100%|██████████| 7/7 [00:00<00:00, 81.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919BE0>: 100%|██████████| 7/7 [00:00<00:00, 111.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919130>: 100%|██████████| 7/7 [00:00<00:00, 83.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536A0>: 100%|██████████| 7/7 [00:00<00:00, 102.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53AC0>:  14%|█▍        | 1/7 [00:00<00:00, 27.69 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003755_male_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000605_male_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1130>: 100%|██████████| 7/7 [00:00<00:00, 94.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919B50>: 100%|██████████| 7/7 [00:00<00:00, 81.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1100>: 100%|██████████| 7/7 [00:00<00:00, 97.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1550>: 100%|██████████| 7/7 [00:00<00:00, 99.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533A0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001401_male_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000772_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53520>: 100%|██████████| 7/7 [00:00<00:00, 61.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53790>: 100%|██████████| 7/7 [00:00<00:00, 87.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53220>: 100%|██████████| 7/7 [00:00<00:00, 104.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBC3D0>: 100%|██████████| 7/7 [00:00<00:00, 104.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>:  14%|█▍        | 1/7 [00:00<00:00, 16.77 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001214_male_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006343_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53700>: 100%|██████████| 7/7 [00:00<00:00, 98.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68F40>: 100%|██████████| 7/7 [00:00<00:00, 92.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9019D0>: 100%|██████████| 7/7 [00:00<00:00, 84.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1550>: 100%|██████████| 7/7 [00:00<00:00, 75.37 Samples/s]                  \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004075_male_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000661_male_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919160>: 100%|██████████| 7/7 [00:00<00:00, 135.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68070>: 100%|██████████| 7/7 [00:00<00:00, 88.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58640>: 100%|██████████| 7/7 [00:00<00:00, 106.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535B0>: 100%|██████████| 7/7 [00:00<00:00, 103.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D60>:  57%|█████▋    | 4/7 [00:00<00:00, 69.41 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004365_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006945_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53AC0>: 100%|██████████| 7/7 [00:00<00:00, 95.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECCA5B50>: 100%|██████████| 7/7 [00:00<00:00, 93.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D60>: 100%|██████████| 7/7 [00:00<00:00, 96.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C310>: 100%|██████████| 7/7 [00:00<00:00, 72.49 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006466_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006566_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58910>: 100%|██████████| 7/7 [00:00<00:00, 75.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A30>: 100%|██████████| 7/7 [00:00<00:00, 104.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B820>: 100%|██████████| 7/7 [00:00<00:00, 92.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A19D0>: 100%|██████████| 7/7 [00:00<00:00, 74.59 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003289_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003073_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F40>: 100%|██████████| 7/7 [00:00<00:00, 94.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61AF0>: 100%|██████████| 7/7 [00:00<00:00, 87.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919B50>: 100%|██████████| 7/7 [00:00<00:00, 81.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD790>: 100%|██████████| 7/7 [00:00<00:00, 123.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614C0>:  71%|███████▏  | 5/7 [00:00<00:00, 96.38 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005073_female_Asian_35.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006472_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D539A0>: 100%|██████████| 7/7 [00:00<00:00, 123.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53520>: 100%|██████████| 7/7 [00:00<00:00, 101.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53CD0>: 100%|██████████| 7/7 [00:00<00:00, 99.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1C0>: 100%|██████████| 7/7 [00:00<00:00, 99.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC100>:  86%|████████▌ | 6/7 [00:00<00:00, 110.13 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001794_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003353_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC100>: 100%|██████████| 7/7 [00:00<00:00, 125.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A00>: 100%|██████████| 7/7 [00:00<00:00, 91.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D00>: 100%|██████████| 7/7 [00:00<00:00, 121.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D30>: 100%|██████████| 7/7 [00:00<00:00, 90.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDFA0>: 100%|██████████| 7/7 [00:00<00:00, 123.56 Samples/s]         \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006496_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004414_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF1AC0>: 100%|██████████| 7/7 [00:00<00:00, 138.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58940>: 100%|██████████| 7/7 [00:00<00:00, 93.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919100>: 100%|██████████| 7/7 [00:00<00:00, 103.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1F0>:  29%|██▊       | 2/7 [00:00<00:00, 40.49 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003767_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001734_male_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDC40>: 100%|██████████| 7/7 [00:00<00:00, 95.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58BB0>: 100%|██████████| 7/7 [00:00<00:00, 84.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D588E0>: 100%|██████████| 7/7 [00:00<00:00, 92.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CD0>: 100%|██████████| 7/7 [00:00<00:00, 71.47 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005051_female_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003543_male_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58820>: 100%|██████████| 7/7 [00:00<00:00, 96.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD220>: 100%|██████████| 7/7 [00:00<00:00, 79.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919A30>: 100%|██████████| 7/7 [00:00<00:00, 78.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D586D0>: 100%|██████████| 7/7 [00:00<00:00, 91.28 Samples/s]                  \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003886_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000606_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1F0>: 100%|██████████| 7/7 [00:00<00:00, 74.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBCCA0>: 100%|██████████| 7/7 [00:00<00:00, 82.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5E0>: 100%|██████████| 7/7 [00:00<00:00, 79.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F36A0>: 100%|██████████| 7/7 [00:00<00:00, 85.50 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000743_female_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003783_female_Asian_40."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D90>: 100%|██████████| 7/7 [00:00<00:00, 119.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D681C0>: 100%|██████████| 7/7 [00:00<00:00, 79.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1790>: 100%|██████████| 7/7 [00:00<00:00, 106.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDAC0>: 100%|██████████| 7/7 [00:00<00:00, 98.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD190>: 100%|██████████| 7/7 [00:00<00:00, 125.85 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003805_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001906_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1F70>: 100%|██████████| 7/7 [00:00<00:00, 59.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A90>: 100%|██████████| 7/7 [00:00<00:00, 88.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1520>: 100%|██████████| 7/7 [00:00<00:00, 119.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53850>: 100%|██████████| 7/7 [00:00<00:00, 125.60 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003397_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005002_female_Asian_28."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD460>: 100%|██████████| 7/7 [00:00<00:00, 81.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A00>: 100%|██████████| 7/7 [00:00<00:00, 79.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD2E0>: 100%|██████████| 7/7 [00:00<00:00, 86.79 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001658_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003326_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A13A0>: 100%|██████████| 7/7 [00:00<00:00, 100.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1DC0>: 100%|██████████| 7/7 [00:00<00:00, 104.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53430>: 100%|██████████| 7/7 [00:00<00:00, 85.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53280>: 100%|██████████| 7/7 [00:00<00:00, 109.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A90>:  43%|████▎     | 3/7 [00:00<00:00, 69.29 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003505-1_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004257_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68F40>: 100%|██████████| 7/7 [00:00<00:00, 108.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1AC0>: 100%|██████████| 7/7 [00:00<00:00, 108.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9019D0>: 100%|██████████| 7/7 [00:00<00:00, 101.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D531C0>: 100%|██████████| 7/7 [00:00<00:00, 97.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B1C0>:  29%|██▊       | 2/7 [00:00<00:00, 39.13 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005423_male_Asian_38.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006095_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533D0>: 100%|██████████| 7/7 [00:00<00:00, 102.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1880>: 100%|██████████| 7/7 [00:00<00:00, 115.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CA0>: 100%|██████████| 7/7 [00:00<00:00, 93.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30A0>: 100%|██████████| 7/7 [00:00<00:00, 118.33 Samples/s]                 \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000650_male_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006100_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58BB0>: 100%|██████████| 7/7 [00:00<00:00, 76.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53580>: 100%|██████████| 7/7 [00:00<00:00, 113.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1910>: 100%|██████████| 7/7 [00:00<00:00, 75.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C3D0>: 100%|██████████| 7/7 [00:00<00:00, 75.67 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005524_female_Asian_38.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006362_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FD0>: 100%|██████████| 7/7 [00:00<00:00, 118.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D588E0>: 100%|██████████| 7/7 [00:00<00:00, 90.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A30>: 100%|██████████| 7/7 [00:00<00:00, 90.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CD0>: 100%|██████████| 7/7 [00:00<00:00, 131.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3610>: 100%|██████████| 7/7 [00:00<00:00, 112.04 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003330_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001144_male_Asian_28."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53310>: 100%|██████████| 7/7 [00:00<00:00, 71.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1910>: 100%|██████████| 7/7 [00:00<00:00, 89.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D90>: 100%|██████████| 7/7 [00:00<00:00, 81.43 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006392_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000064_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61790>: 100%|██████████| 7/7 [00:00<00:00, 77.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>: 100%|██████████| 7/7 [00:00<00:00, 75.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1130>: 100%|██████████| 7/7 [00:00<00:00, 94.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C10>: 100%|██████████| 7/7 [00:00<00:00, 99.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD490>:  29%|██▊       | 2/7 [00:00<00:00, 52.31 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006090_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003929_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53AC0>: 100%|██████████| 7/7 [00:00<00:00, 123.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDC40>: 100%|██████████| 7/7 [00:00<00:00, 76.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C615E0>: 100%|██████████| 7/7 [00:00<00:00, 106.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD730>: 100%|██████████| 7/7 [00:00<00:00, 99.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6D0>:  57%|█████▋    | 4/7 [00:00<00:00, 85.99 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005500_female_Asian_49.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001258_female_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD4F0>: 100%|██████████| 7/7 [00:00<00:00, 101.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61400>: 100%|██████████| 7/7 [00:00<00:00, 86.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61DC0>: 100%|██████████| 7/7 [00:00<00:00, 95.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919400>: 100%|██████████| 7/7 [00:00<00:00, 105.87 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA90>:  29%|██▊       | 2/7 [00:00<00:00, 45.42 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001665_male_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001441_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61490>: 100%|██████████| 7/7 [00:00<00:00, 83.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA60>: 100%|██████████| 7/7 [00:00<00:00, 77.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D586D0>: 100%|██████████| 7/7 [00:00<00:00, 96.33 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EB0>: 100%|██████████| 7/7 [00:00<00:00, 104.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD520>:  43%|████▎     | 3/7 [00:00<00:00, 69.39 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000724_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000523_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3880>: 100%|██████████| 7/7 [00:00<00:00, 114.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9196A0>: 100%|██████████| 7/7 [00:00<00:00, 94.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3BB0>: 100%|██████████| 7/7 [00:00<00:00, 87.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919A30>: 100%|██████████| 7/7 [00:00<00:00, 84.46 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000294_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003266_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919A30>: 100%|██████████| 7/7 [00:00<00:00, 85.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3760>: 100%|██████████| 7/7 [00:00<00:00, 100.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A90>: 100%|██████████| 7/7 [00:00<00:00, 134.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD4F0>: 100%|██████████| 7/7 [00:00<00:00, 139.26 Samples/s]         \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C40>:  43%|████▎     | 3/7 [00:00<00:00, 41.45 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000625_male_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005488_male_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD90>: 100%|██████████| 7/7 [00:00<00:00, 78.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EE0>: 100%|██████████| 7/7 [00:00<00:00, 126.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9016D0>: 100%|██████████| 7/7 [00:00<00:00, 89.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A00>: 100%|██████████| 7/7 [00:00<00:00, 72.96 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004211_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000552_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDEE0>: 100%|██████████| 7/7 [00:00<00:00, 83.04 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD490>: 100%|██████████| 7/7 [00:00<00:00, 82.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919610>: 100%|██████████| 7/7 [00:00<00:00, 84.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A30>: 100%|██████████| 7/7 [00:00<00:00, 88.96 Samples/s]                  \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005088_female_Asian_29.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001354_male_Asian_27."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1B50>: 100%|██████████| 7/7 [00:00<00:00, 88.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A10A0>: 100%|██████████| 7/7 [00:00<00:00, 96.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCD0>: 100%|██████████| 7/7 [00:00<00:00, 101.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919250>: 100%|██████████| 7/7 [00:00<00:00, 92.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>:  57%|█████▋    | 4/7 [00:00<00:00, 85.17 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000770_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003462_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD190>: 100%|██████████| 7/7 [00:00<00:00, 84.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC700>: 100%|██████████| 7/7 [00:00<00:00, 119.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A30>: 100%|██████████| 7/7 [00:00<00:00, 102.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53340>: 100%|██████████| 7/7 [00:00<00:00, 80.30 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001367_male_Asian_21.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000210_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D532B0>: 100%|██████████| 7/7 [00:00<00:00, 102.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1CA0>: 100%|██████████| 7/7 [00:00<00:00, 88.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9018E0>: 100%|██████████| 7/7 [00:00<00:00, 103.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919640>: 100%|██████████| 7/7 [00:00<00:00, 86.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B20>:  14%|█▍        | 1/7 [00:00<00:00, 35.66 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001281_female_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003339_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68070>: 100%|██████████| 7/7 [00:00<00:00, 105.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68340>: 100%|██████████| 7/7 [00:00<00:00, 92.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1F70>: 100%|██████████| 7/7 [00:00<00:00, 82.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68E20>: 100%|██████████| 7/7 [00:00<00:00, 120.72 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD340>:  43%|████▎     | 3/7 [00:00<00:00, 59.81 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000773_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001032_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D90>: 100%|██████████| 7/7 [00:00<00:00, 106.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>: 100%|██████████| 7/7 [00:00<00:00, 84.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691B20>: 100%|██████████| 7/7 [00:00<00:00, 82.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDEE0>: 100%|██████████| 7/7 [00:00<00:00, 85.28 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003414_male_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004461_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3460>: 100%|██████████| 7/7 [00:00<00:00, 95.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919310>: 100%|██████████| 7/7 [00:00<00:00, 88.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919760>: 100%|██████████| 7/7 [00:00<00:00, 121.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B1C0>: 100%|██████████| 7/7 [00:00<00:00, 80.56 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001057_female_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001603_male_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F70>: 100%|██████████| 7/7 [00:00<00:00, 79.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53340>: 100%|██████████| 7/7 [00:00<00:00, 109.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDC40>: 100%|██████████| 7/7 [00:00<00:00, 78.52 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A00>: 100%|██████████| 7/7 [00:00<00:00, 86.54 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003764_female_Asian_49.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001034_male_Asian_27."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE50>: 100%|██████████| 7/7 [00:00<00:00, 93.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533D0>: 100%|██████████| 7/7 [00:00<00:00, 113.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF1AC0>: 100%|██████████| 7/7 [00:00<00:00, 116.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC430>: 100%|██████████| 7/7 [00:00<00:00, 122.23 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003796_female_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006170_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC520>: 100%|██████████| 7/7 [00:00<00:00, 48.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D588B0>: 100%|██████████| 7/7 [00:00<00:00, 34.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCAF0>: 100%|██████████| 7/7 [00:00<00:00, 125.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61DF0>: 100%|██████████| 7/7 [00:00<00:00, 79.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD90>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001664_female_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001095_male_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535E0>: 100%|██████████| 7/7 [00:00<00:00, 67.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCB80>: 100%|██████████| 7/7 [00:00<00:00, 74.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC370>: 100%|██████████| 7/7 [00:00<00:00, 132.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC310>: 100%|██████████| 7/7 [00:00<00:00, 68.74 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006493_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001747_male_Asian_49."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D30>: 100%|██████████| 7/7 [00:00<00:00, 111.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7E66820>: 100%|██████████| 7/7 [00:00<00:00, 69.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53E50>: 100%|██████████| 7/7 [00:00<00:00, 91.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF10>:  57%|█████▋    | 4/7 [00:00<00:00, 46.33 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004228_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53CA0>: 100%|██████████| 7/7 [00:00<00:00, 54.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E50>: 100%|██████████| 7/7 [00:00<00:00, 84.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A90>: 100%|██████████| 7/7 [00:00<00:00, 120.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53430>:  86%|████████▌ | 6/7 [00:00<00:00, 111.30 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001776_male_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006403_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53430>: 100%|██████████| 7/7 [00:00<00:00, 127.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614C0>: 100%|██████████| 7/7 [00:00<00:00, 94.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31FD0>: 100%|██████████| 7/7 [00:00<00:00, 129.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B100>: 100%|██████████| 7/7 [00:00<00:00, 85.10 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC250>:  43%|████▎     | 3/7 [00:00<00:00, 51.45 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006542_female_Asian_21.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005010_female_Asian_27."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58910>: 100%|██████████| 7/7 [00:00<00:00, 91.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1C0>: 100%|██████████| 7/7 [00:00<00:00, 87.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53940>: 100%|██████████| 7/7 [00:00<00:00, 123.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53040>: 100%|██████████| 7/7 [00:00<00:00, 93.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A90>: 100%|██████████| 7/7 [00:00<00:00, 113.97 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006214_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006745_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FD0>: 100%|██████████| 7/7 [00:00<00:00, 114.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECC98E80>: 100%|██████████| 7/7 [00:00<00:00, 96.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3880>: 100%|██████████| 7/7 [00:00<00:00, 77.77 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000636_female_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003166_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3700>: 100%|██████████| 7/7 [00:00<00:00, 114.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3610>: 100%|██████████| 7/7 [00:00<00:00, 82.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53280>: 100%|██████████| 7/7 [00:00<00:00, 73.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5B0>: 100%|██████████| 7/7 [00:00<00:00, 111.06 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000810_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003617_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD460>: 100%|██████████| 7/7 [00:00<00:00, 120.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F70>: 100%|██████████| 7/7 [00:00<00:00, 114.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D681C0>: 100%|██████████| 7/7 [00:00<00:00, 85.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD310>: 100%|██████████| 7/7 [00:00<00:00, 90.47 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004309_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006133_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D30>: 100%|██████████| 7/7 [00:00<00:00, 51.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABF20D0>: 100%|██████████| 7/7 [00:00<00:00, 43.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68160>: 100%|██████████| 7/7 [00:00<00:00, 82.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F70>: 100%|██████████| 7/7 [00:00<00:00, 105.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1610>:  14%|█▍        | 1/7 [00:00<00:00, 24.02 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000511_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005496_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC4C0>: 100%|██████████| 7/7 [00:00<00:00, 101.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD100>: 100%|██████████| 7/7 [00:00<00:00, 128.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68FA0>: 100%|██████████| 7/7 [00:00<00:00, 93.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D60>: 100%|██████████| 7/7 [00:00<00:00, 82.48 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004342_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000642_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901C70>: 100%|██████████| 7/7 [00:00<00:00, 86.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A20A0>: 100%|██████████| 7/7 [00:00<00:00, 107.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9016D0>: 100%|██████████| 7/7 [00:00<00:00, 99.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3700>: 100%|██████████| 7/7 [00:00<00:00, 99.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A90>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001539_female_Asian_28.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003628_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A22E0>: 100%|██████████| 7/7 [00:00<00:00, 110.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3160>: 100%|██████████| 7/7 [00:00<00:00, 89.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDF70>: 100%|██████████| 7/7 [00:00<00:00, 101.16 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30A0>: 100%|██████████| 7/7 [00:00<00:00, 91.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD00>:  14%|█▍        | 1/7 [00:00<00:00, 20.16 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003316_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001516_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDC40>: 100%|██████████| 7/7 [00:00<00:00, 98.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1B80>: 100%|██████████| 7/7 [00:00<00:00, 99.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3160>: 100%|██████████| 7/7 [00:00<00:00, 100.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1790>: 100%|██████████| 7/7 [00:00<00:00, 81.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD90>:  29%|██▊       | 2/7 [00:00<00:00, 54.74 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004469_male_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001493-1_male_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5E0>: 100%|██████████| 7/7 [00:00<00:00, 94.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1160>: 100%|██████████| 7/7 [00:00<00:00, 77.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58700>: 100%|██████████| 7/7 [00:00<00:00, 77.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF1AC0>: 100%|██████████| 7/7 [00:00<00:00, 102.38 Samples/s]         \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004097_female_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003079_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1280>: 100%|██████████| 7/7 [00:00<00:00, 85.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCD0>: 100%|██████████| 7/7 [00:00<00:00, 104.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E20>: 100%|██████████| 7/7 [00:00<00:00, 109.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD9A0>: 100%|██████████| 7/7 [00:00<00:00, 100.17 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003124_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006486_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614C0>: 100%|██████████| 7/7 [00:00<00:00, 78.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D531C0>: 100%|██████████| 7/7 [00:00<00:00, 73.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D30>: 100%|██████████| 7/7 [00:00<00:00, 73.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE20>: 100%|██████████| 7/7 [00:00<00:00, 137.44 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001562_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006236_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.PngImagePlugin.PngImageFile image mode=RGB size=384x512 at 0x7F8FC23A1760>: 100%|██████████| 7/7 [00:00<00:00, 40.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABD0280>: 100%|██████████| 7/7 [00:00<00:00, 41.49 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FAABD80D0>: 100%|██████████| 7/7 [00:00<00:00, 124.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC4F0>: 100%|██████████| 7/7 [00:00<00:00, 87.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A9340>:  57%|█████▋    | 4/7 [00:00<00:00, 88.35 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003786_female_Asian_45.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001315_female_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF1EE0>: 100%|██████████| 7/7 [00:00<00:00, 90.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901E50>: 100%|██████████| 7/7 [00:00<00:00, 133.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B1C0>: 100%|██████████| 7/7 [00:00<00:00, 110.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCB80>: 100%|██████████| 7/7 [00:00<00:00, 78.53 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003370_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003516_male_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC7F0>: 100%|██████████| 7/7 [00:00<00:00, 101.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901190>: 100%|██████████| 7/7 [00:00<00:00, 100.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68E20>: 100%|██████████| 7/7 [00:00<00:00, 93.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D90>: 100%|██████████| 7/7 [00:00<00:00, 135.64 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCAC0>:  57%|█████▋    | 4/7 [00:00<00:00, 61.64 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005119_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006651_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901190>: 100%|██████████| 7/7 [00:00<00:00, 85.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC5E0>: 100%|██████████| 7/7 [00:00<00:00, 83.74 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537C0>: 100%|██████████| 7/7 [00:00<00:00, 108.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC2E0>: 100%|██████████| 7/7 [00:00<00:00, 78.48 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000747_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001072_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D539A0>: 100%|██████████| 7/7 [00:00<00:00, 101.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536A0>: 100%|██████████| 7/7 [00:00<00:00, 87.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC190>: 100%|██████████| 7/7 [00:00<00:00, 86.50 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8FD160>: 100%|██████████| 7/7 [00:00<00:00, 133.28 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003441_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006059_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDDF0>: 100%|██████████| 7/7 [00:00<00:00, 40.83 Samples/s]\n",
      "Processing <PIL.PngImagePlugin.PngImageFile image mode=RGB size=384x512 at 0x7F8FEC8FDFA0>: 100%|██████████| 7/7 [00:00<00:00, 50.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61790>: 100%|██████████| 7/7 [00:00<00:00, 98.97 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61940>: 100%|██████████| 7/7 [00:00<00:00, 116.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC910>:  29%|██▊       | 2/7 [00:00<00:00, 45.04 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003798_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003192_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD070>: 100%|██████████| 7/7 [00:00<00:00, 87.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1BB0>: 100%|██████████| 7/7 [00:00<00:00, 87.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCB50>: 100%|██████████| 7/7 [00:00<00:00, 75.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9A0>: 100%|██████████| 7/7 [00:00<00:00, 78.64 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001703_male_Asian_49.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001510_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C618E0>: 100%|██████████| 7/7 [00:00<00:00, 112.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1F70>: 100%|██████████| 7/7 [00:00<00:00, 98.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC520>: 100%|██████████| 7/7 [00:00<00:00, 85.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC610>: 100%|██████████| 7/7 [00:00<00:00, 110.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCBB0>:  43%|████▎     | 3/7 [00:00<00:00, 61.13 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005256_male_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005213_male_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE50>: 100%|██████████| 7/7 [00:00<00:00, 65.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919130>: 100%|██████████| 7/7 [00:00<00:00, 105.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919340>: 100%|██████████| 7/7 [00:00<00:00, 102.07 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F70>: 100%|██████████| 7/7 [00:00<00:00, 91.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61580>:  29%|██▊       | 2/7 [00:00<00:00, 45.37 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003993_male_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001054_female_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11C0>: 100%|██████████| 7/7 [00:00<00:00, 81.41 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8FD6D0>: 100%|██████████| 7/7 [00:00<00:00, 100.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919E20>: 100%|██████████| 7/7 [00:00<00:00, 96.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3D0>: 100%|██████████| 7/7 [00:00<00:00, 75.57 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003821_male_Asian_38.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003938_male_Asian_43."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53AF0>: 100%|██████████| 7/7 [00:00<00:00, 77.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1C0>: 100%|██████████| 7/7 [00:00<00:00, 82.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1310>: 100%|██████████| 7/7 [00:00<00:00, 99.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53520>: 100%|██████████| 7/7 [00:00<00:00, 121.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3A0>:  43%|████▎     | 3/7 [00:00<00:00, 44.19 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003197_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001359-1_female_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDB80>: 100%|██████████| 7/7 [00:00<00:00, 89.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C619A0>: 100%|██████████| 7/7 [00:00<00:00, 77.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B20>: 100%|██████████| 7/7 [00:00<00:00, 87.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614F0>: 100%|██████████| 7/7 [00:00<00:00, 105.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D30>:  14%|█▍        | 1/7 [00:00<00:00, 23.97 Samples/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006354_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003801_female_Asian_49."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614F0>: 100%|██████████| 7/7 [00:00<00:00, 105.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A90>: 100%|██████████| 7/7 [00:00<00:00, 102.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD340>: 100%|██████████| 7/7 [00:00<00:00, 81.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53910>: 100%|██████████| 7/7 [00:00<00:00, 97.38 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006478_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006105_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53CD0>: 100%|██████████| 7/7 [00:00<00:00, 90.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901E50>: 100%|██████████| 7/7 [00:00<00:00, 64.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919610>: 100%|██████████| 7/7 [00:00<00:00, 113.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD90>: 100%|██████████| 7/7 [00:00<00:00, 104.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53820>:  57%|█████▋    | 4/7 [00:00<00:00, 62.39 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001533_male_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006093_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68EB0>: 100%|██████████| 7/7 [00:00<00:00, 73.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68FA0>: 100%|██████████| 7/7 [00:00<00:00, 81.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC790>: 100%|██████████| 7/7 [00:00<00:00, 40.39 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006216_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53220>: 100%|██████████| 7/7 [00:00<00:00, 46.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B700>: 100%|██████████| 7/7 [00:00<00:00, 103.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A30>: 100%|██████████| 7/7 [00:00<00:00, 87.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53910>:  29%|██▊       | 2/7 [00:00<00:00, 44.15 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005014_female_Asian_35.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000729_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53610>: 100%|██████████| 7/7 [00:00<00:00, 113.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC760>: 100%|██████████| 7/7 [00:00<00:00, 76.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCB80>: 100%|██████████| 7/7 [00:00<00:00, 84.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C310>: 100%|██████████| 7/7 [00:00<00:00, 111.15 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC490>:  14%|█▍        | 1/7 [00:00<00:00, 25.48 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000236_male_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006589_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A2340>: 100%|██████████| 7/7 [00:00<00:00, 93.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBC730>: 100%|██████████| 7/7 [00:00<00:00, 98.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCCA0>: 100%|██████████| 7/7 [00:00<00:00, 118.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68FD0>: 100%|██████████| 7/7 [00:00<00:00, 95.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68070>: 100%|██████████| 7/7 [00:00<00:00, 112.35 Samples/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001362_female_Asian_28.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001608_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCEB0>: 100%|██████████| 7/7 [00:00<00:00, 123.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68340>: 100%|██████████| 7/7 [00:00<00:00, 83.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901940>: 100%|██████████| 7/7 [00:00<00:00, 85.41 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005019_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001636_male_Asian_28."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D534F0>: 100%|██████████| 7/7 [00:00<00:00, 107.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9012E0>: 100%|██████████| 7/7 [00:00<00:00, 79.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD7F0>: 100%|██████████| 7/7 [00:00<00:00, 100.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1F0>: 100%|██████████| 7/7 [00:00<00:00, 112.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D90>: 100%|██████████| 7/7 [00:00<00:00, 120.47 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003791_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001092_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE80>: 100%|██████████| 7/7 [00:00<00:00, 108.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC70>: 100%|██████████| 7/7 [00:00<00:00, 107.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC5E0>: 100%|██████████| 7/7 [00:00<00:00, 116.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9012E0>: 100%|██████████| 7/7 [00:00<00:00, 119.58 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001726_male_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001142_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D30>: 100%|██████████| 7/7 [00:00<00:00, 103.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C613A0>: 100%|██████████| 7/7 [00:00<00:00, 77.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31E50>: 100%|██████████| 7/7 [00:00<00:00, 87.48 Samples/s]                  \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003364_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003857_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1070>: 100%|██████████| 7/7 [00:00<00:00, 83.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE80>: 100%|██████████| 7/7 [00:00<00:00, 99.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA30>: 100%|██████████| 7/7 [00:00<00:00, 76.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31BE0>: 100%|██████████| 7/7 [00:00<00:00, 80.32 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003237_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006218_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC580>: 100%|██████████| 7/7 [00:00<00:00, 35.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD160>: 100%|██████████| 7/7 [00:00<00:00, 40.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1CA0>: 100%|██████████| 7/7 [00:00<00:00, 76.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD730>: 100%|██████████| 7/7 [00:00<00:00, 68.82 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006513_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003047_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9199A0>: 100%|██████████| 7/7 [00:00<00:00, 73.57 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC919D90>: 100%|██████████| 7/7 [00:00<00:00, 107.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11C0>: 100%|██████████| 7/7 [00:00<00:00, 102.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC95D790>: 100%|██████████| 7/7 [00:00<00:00, 95.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A10A0>:  14%|█▍        | 1/7 [00:00<00:00, 19.57 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001136_male_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001809_male_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61550>: 100%|██████████| 7/7 [00:00<00:00, 96.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61A60>: 100%|██████████| 7/7 [00:00<00:00, 73.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919910>: 100%|██████████| 7/7 [00:00<00:00, 132.76 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61910>: 100%|██████████| 7/7 [00:00<00:00, 99.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F10>:  57%|█████▋    | 4/7 [00:00<00:00, 55.05 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006368_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003129_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58DC0>: 100%|██████████| 7/7 [00:00<00:00, 89.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58FA0>: 100%|██████████| 7/7 [00:00<00:00, 131.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614C0>: 100%|██████████| 7/7 [00:00<00:00, 102.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD490>: 100%|██████████| 7/7 [00:00<00:00, 83.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A30>:  29%|██▊       | 2/7 [00:00<00:00, 46.35 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000297_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000266_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61790>: 100%|██████████| 7/7 [00:00<00:00, 100.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537C0>: 100%|██████████| 7/7 [00:00<00:00, 83.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9019D0>: 100%|██████████| 7/7 [00:00<00:00, 47.85 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006234_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D30>: 100%|██████████| 7/7 [00:00<00:00, 42.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A19D0>: 100%|██████████| 7/7 [00:00<00:00, 92.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53FA0>: 100%|██████████| 7/7 [00:00<00:00, 99.73 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A00>:  14%|█▍        | 1/7 [00:00<00:00, 23.22 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001451_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001892_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD310>: 100%|██████████| 7/7 [00:00<00:00, 83.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1610>: 100%|██████████| 7/7 [00:00<00:00, 109.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1400>: 100%|██████████| 7/7 [00:00<00:00, 127.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1190>: 100%|██████████| 7/7 [00:00<00:00, 90.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1B50>:  71%|███████▏  | 5/7 [00:00<00:00, 79.38 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000818_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004205_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF40>: 100%|██████████| 7/7 [00:00<00:00, 108.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD700>: 100%|██████████| 7/7 [00:00<00:00, 86.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C310>: 100%|██████████| 7/7 [00:00<00:00, 107.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D539A0>: 100%|██████████| 7/7 [00:00<00:00, 101.38 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000026_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006139_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA30>: 100%|██████████| 7/7 [00:00<00:00, 47.22 Samples/s]\n",
      "Processing <PIL.PngImagePlugin.PngImageFile image mode=RGB size=384x512 at 0x7F8FD7D688B0>: 100%|██████████| 7/7 [00:00<00:00, 38.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A2340>: 100%|██████████| 7/7 [00:00<00:00, 84.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691850>: 100%|██████████| 7/7 [00:00<00:00, 90.25 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001070_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004250_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD100>: 100%|██████████| 7/7 [00:00<00:00, 70.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53FD0>: 100%|██████████| 7/7 [00:00<00:00, 91.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691AF0>: 100%|██████████| 7/7 [00:00<00:00, 75.89 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FAABCC1F0>: 100%|██████████| 7/7 [00:00<00:00, 116.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCB20>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000759_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006674_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D680A0>: 100%|██████████| 7/7 [00:00<00:00, 92.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA00>: 100%|██████████| 7/7 [00:00<00:00, 117.60 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9016D0>: 100%|██████████| 7/7 [00:00<00:00, 76.24 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8FD070>: 100%|██████████| 7/7 [00:00<00:00, 102.44 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001713_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003818_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD970>: 100%|██████████| 7/7 [00:00<00:00, 96.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE50>: 100%|██████████| 7/7 [00:00<00:00, 98.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5B0>: 100%|██████████| 7/7 [00:00<00:00, 101.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCD0>: 100%|██████████| 7/7 [00:00<00:00, 106.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC220>:  57%|█████▋    | 4/7 [00:00<00:00, 69.99 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000522_female_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003321_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC700>: 100%|██████████| 7/7 [00:00<00:00, 83.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C615E0>: 100%|██████████| 7/7 [00:00<00:00, 83.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5E0>: 100%|██████████| 7/7 [00:00<00:00, 130.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC5E0>: 100%|██████████| 7/7 [00:00<00:00, 79.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE50>:  43%|████▎     | 3/7 [00:00<00:00, 56.87 Samples/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000560_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006571_female_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D588B0>: 100%|██████████| 7/7 [00:00<00:00, 91.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD160>: 100%|██████████| 7/7 [00:00<00:00, 107.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDEE0>: 100%|██████████| 7/7 [00:00<00:00, 114.10 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FC23A1C10>: 100%|██████████| 7/7 [00:00<00:00, 86.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD9A0>:  29%|██▊       | 2/7 [00:00<00:00, 47.85 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004214_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001006_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1160>: 100%|██████████| 7/7 [00:00<00:00, 105.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDC40>: 100%|██████████| 7/7 [00:00<00:00, 102.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61820>: 100%|██████████| 7/7 [00:00<00:00, 91.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE50>: 100%|██████████| 7/7 [00:00<00:00, 84.79 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005047_female_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006487_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDFA0>: 100%|██████████| 7/7 [00:00<00:00, 103.97 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1730>: 100%|██████████| 7/7 [00:00<00:00, 67.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1610>: 100%|██████████| 7/7 [00:00<00:00, 136.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919820>: 100%|██████████| 7/7 [00:00<00:00, 118.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919160>: 100%|██████████| 7/7 [00:00<00:00, 111.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9197F0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001192_male_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005240_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919760>: 100%|██████████| 7/7 [00:00<00:00, 122.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A16A0>: 100%|██████████| 7/7 [00:00<00:00, 93.11 Samples/s]          \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9192E0>: 100%|██████████| 7/7 [00:00<00:00, 67.33 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003810_female_Asian_49.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000286_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CA0>: 100%|██████████| 7/7 [00:00<00:00, 91.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58970>: 100%|██████████| 7/7 [00:00<00:00, 109.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61A60>: 100%|██████████| 7/7 [00:00<00:00, 91.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919A90>: 100%|██████████| 7/7 [00:00<00:00, 102.56 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537C0>:  29%|██▊       | 2/7 [00:00<00:00, 39.41 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003824_female_Asian_36.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004222_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58FA0>: 100%|██████████| 7/7 [00:00<00:00, 95.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF1AC0>: 100%|██████████| 7/7 [00:00<00:00, 80.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C10>: 100%|██████████| 7/7 [00:00<00:00, 78.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58760>: 100%|██████████| 7/7 [00:00<00:00, 80.54 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005285_male_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004246_female_Asian_38."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61850>: 100%|██████████| 7/7 [00:00<00:00, 107.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B20>: 100%|██████████| 7/7 [00:00<00:00, 117.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53310>: 100%|██████████| 7/7 [00:00<00:00, 93.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD160>: 100%|██████████| 7/7 [00:00<00:00, 109.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B100>:  71%|███████▏  | 5/7 [00:00<00:00, 93.47 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000277_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003359_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C616A0>: 100%|██████████| 7/7 [00:00<00:00, 114.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C40>: 100%|██████████| 7/7 [00:00<00:00, 81.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D530D0>: 100%|██████████| 7/7 [00:00<00:00, 104.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD700>: 100%|██████████| 7/7 [00:00<00:00, 84.56 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003716_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006423_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D00>: 100%|██████████| 7/7 [00:00<00:00, 96.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCD0>: 100%|██████████| 7/7 [00:00<00:00, 111.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A2340>: 100%|██████████| 7/7 [00:00<00:00, 87.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE20>: 100%|██████████| 7/7 [00:00<00:00, 81.69 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001023_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003513_male_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B50>: 100%|██████████| 7/7 [00:00<00:00, 106.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD100>: 100%|██████████| 7/7 [00:00<00:00, 89.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD130>: 100%|██████████| 7/7 [00:00<00:00, 101.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD130>: 100%|██████████| 7/7 [00:00<00:00, 100.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC880>:  43%|████▎     | 3/7 [00:00<00:00, 53.33 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003012_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003388_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDFA0>: 100%|██████████| 7/7 [00:00<00:00, 88.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53850>: 100%|██████████| 7/7 [00:00<00:00, 92.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5B0>: 100%|██████████| 7/7 [00:00<00:00, 116.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68CA0>: 100%|██████████| 7/7 [00:00<00:00, 149.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBC730>: 100%|██████████| 7/7 [00:00<00:00, 110.84 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000712_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003574_male_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7D60>: 100%|██████████| 7/7 [00:00<00:00, 82.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCFA0>: 100%|██████████| 7/7 [00:00<00:00, 96.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC250>: 100%|██████████| 7/7 [00:00<00:00, 96.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD730>:  29%|██▊       | 2/7 [00:00<00:00, 51.41 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001666_female_Asian_27.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005403_female_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B670>: 100%|██████████| 7/7 [00:00<00:00, 84.35 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7C61400>: 100%|██████████| 7/7 [00:00<00:00, 99.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61BB0>: 100%|██████████| 7/7 [00:00<00:00, 113.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE50>: 100%|██████████| 7/7 [00:00<00:00, 103.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC0A0>: 100%|██████████| 7/7 [00:00<00:00, 109.27 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000237_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004079_male_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD340>: 100%|██████████| 7/7 [00:00<00:00, 98.58 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61400>: 100%|██████████| 7/7 [00:00<00:00, 76.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A00>: 100%|██████████| 7/7 [00:00<00:00, 92.18 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006102_male_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003119_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53400>: 100%|██████████| 7/7 [00:00<00:00, 89.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61580>: 100%|██████████| 7/7 [00:00<00:00, 87.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD490>: 100%|██████████| 7/7 [00:00<00:00, 96.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612B0>: 100%|██████████| 7/7 [00:00<00:00, 100.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC70>:  14%|█▍        | 1/7 [00:00<00:00, 20.08 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001376_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001668_female_Asian_48."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53730>: 100%|██████████| 7/7 [00:00<00:00, 91.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC550>: 100%|██████████| 7/7 [00:00<00:00, 101.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1190>: 100%|██████████| 7/7 [00:00<00:00, 91.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D00>: 100%|██████████| 7/7 [00:00<00:00, 85.56 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001723_female_Asian_35.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005272_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD30>: 100%|██████████| 7/7 [00:00<00:00, 113.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A19D0>: 100%|██████████| 7/7 [00:00<00:00, 129.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53AC0>: 100%|██████████| 7/7 [00:00<00:00, 87.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58B20>: 100%|██████████| 7/7 [00:00<00:00, 104.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919640>:  29%|██▊       | 2/7 [00:00<00:00, 44.50 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004490_male_Asian_21.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001186-1_male_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9D0>: 100%|██████████| 7/7 [00:00<00:00, 93.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D90>: 100%|██████████| 7/7 [00:00<00:00, 84.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE20>: 100%|██████████| 7/7 [00:00<00:00, 107.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FA0>: 100%|██████████| 7/7 [00:00<00:00, 107.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198B0>:  71%|███████▏  | 5/7 [00:00<00:00, 88.08 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003092_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001270_male_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC10>: 100%|██████████| 7/7 [00:00<00:00, 93.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58940>: 100%|██████████| 7/7 [00:00<00:00, 79.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919A30>: 100%|██████████| 7/7 [00:00<00:00, 118.99 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7C61610>: 100%|██████████| 7/7 [00:00<00:00, 111.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919130>: 100%|██████████| 7/7 [00:00<00:00, 98.36 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003878_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001583_female_Asian_27."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61DC0>: 100%|██████████| 7/7 [00:00<00:00, 106.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1400>: 100%|██████████| 7/7 [00:00<00:00, 87.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EE0>: 100%|██████████| 7/7 [00:00<00:00, 79.14 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005506_male_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006434_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7C614F0>: 100%|██████████| 7/7 [00:00<00:00, 82.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECC98E80>: 100%|██████████| 7/7 [00:00<00:00, 120.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7B20>: 100%|██████████| 7/7 [00:00<00:00, 99.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD280>: 100%|██████████| 7/7 [00:00<00:00, 88.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D30>:  43%|████▎     | 3/7 [00:00<00:00, 72.11 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001168_male_Asian_28.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004479_male_Asian_38."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919E50>: 100%|██████████| 7/7 [00:00<00:00, 105.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901040>: 100%|██████████| 7/7 [00:00<00:00, 74.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE80>: 100%|██████████| 7/7 [00:00<00:00, 108.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CD0>: 100%|██████████| 7/7 [00:00<00:00, 88.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC190>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001452_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003259_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1BE0>: 100%|██████████| 7/7 [00:00<00:00, 82.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58850>: 100%|██████████| 7/7 [00:00<00:00, 108.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1AF0>: 100%|██████████| 7/7 [00:00<00:00, 103.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F40>: 100%|██████████| 7/7 [00:00<00:00, 85.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC7C0>:  14%|█▍        | 1/7 [00:00<00:00, 32.06 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001554_female_Asian_27.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004320_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919970>: 100%|██████████| 7/7 [00:00<00:00, 97.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5E0>: 100%|██████████| 7/7 [00:00<00:00, 61.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C370>: 100%|██████████| 7/7 [00:00<00:00, 78.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD040>: 100%|██████████| 7/7 [00:00<00:00, 91.38 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003156_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001738_female_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD820>: 100%|██████████| 7/7 [00:00<00:00, 96.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD9A0>: 100%|██████████| 7/7 [00:00<00:00, 73.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3160>: 100%|██████████| 7/7 [00:00<00:00, 106.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6A0>: 100%|██████████| 7/7 [00:00<00:00, 90.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC940>:  14%|█▍        | 1/7 [00:00<00:00, 22.17 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006673_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003150_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCDF0>: 100%|██████████| 7/7 [00:00<00:00, 94.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC640>: 100%|██████████| 7/7 [00:00<00:00, 109.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53520>: 100%|██████████| 7/7 [00:00<00:00, 100.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53670>: 100%|██████████| 7/7 [00:00<00:00, 125.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC580>:  57%|█████▋    | 4/7 [00:00<00:00, 67.19 Samples/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001150_male_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001284_male_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C40>: 100%|██████████| 7/7 [00:00<00:00, 85.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA30>: 100%|██████████| 7/7 [00:00<00:00, 94.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF70>: 100%|██████████| 7/7 [00:00<00:00, 91.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3550>: 100%|██████████| 7/7 [00:00<00:00, 90.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F70>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003825_female_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001179-1_female_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBCCA0>: 100%|██████████| 7/7 [00:00<00:00, 116.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC550>: 100%|██████████| 7/7 [00:00<00:00, 104.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F37C0>: 100%|██████████| 7/7 [00:00<00:00, 82.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3670>: 100%|██████████| 7/7 [00:00<00:00, 112.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901640>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000602_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000532_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901400>: 100%|██████████| 7/7 [00:00<00:00, 88.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC880>: 100%|██████████| 7/7 [00:00<00:00, 118.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68340>: 100%|██████████| 7/7 [00:00<00:00, 100.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53EB0>: 100%|██████████| 7/7 [00:00<00:00, 89.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58700>:  43%|████▎     | 3/7 [00:00<00:00, 64.56 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003469_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001515_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D587C0>: 100%|██████████| 7/7 [00:00<00:00, 95.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58760>: 100%|██████████| 7/7 [00:00<00:00, 77.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC3A0>: 100%|██████████| 7/7 [00:00<00:00, 99.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901970>: 100%|██████████| 7/7 [00:00<00:00, 91.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537C0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005174_male_Asian_31.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000659_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53550>: 100%|██████████| 7/7 [00:00<00:00, 132.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F70>: 100%|██████████| 7/7 [00:00<00:00, 109.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDFD0>: 100%|██████████| 7/7 [00:00<00:00, 81.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC340>: 100%|██████████| 7/7 [00:00<00:00, 115.29 Samples/s]                 \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000668_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003483_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53E50>: 100%|██████████| 7/7 [00:00<00:00, 92.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D30>: 100%|██████████| 7/7 [00:00<00:00, 109.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53670>: 100%|██████████| 7/7 [00:00<00:00, 100.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1BC6A0>: 100%|██████████| 7/7 [00:00<00:00, 97.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53520>:  43%|████▎     | 3/7 [00:00<00:00, 73.94 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001715_male_Asian_43.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001116_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31FD0>: 100%|██████████| 7/7 [00:00<00:00, 106.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61A60>: 100%|██████████| 7/7 [00:00<00:00, 99.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1BE0>: 100%|██████████| 7/7 [00:00<00:00, 70.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1B50>: 100%|██████████| 7/7 [00:00<00:00, 91.82 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001663_male_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003431_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA30>: 100%|██████████| 7/7 [00:00<00:00, 77.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C615B0>: 100%|██████████| 7/7 [00:00<00:00, 108.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919A30>: 100%|██████████| 7/7 [00:00<00:00, 101.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1E20>: 100%|██████████| 7/7 [00:00<00:00, 87.07 Samples/s]          \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919610>:  29%|██▊       | 2/7 [00:00<00:00, 46.08 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000575_male_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000299_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53130>: 100%|██████████| 7/7 [00:00<00:00, 106.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9190A0>: 100%|██████████| 7/7 [00:00<00:00, 80.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919040>: 100%|██████████| 7/7 [00:00<00:00, 95.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7E66820>: 100%|██████████| 7/7 [00:00<00:00, 86.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61400>:  14%|█▍        | 1/7 [00:00<00:00, 27.00 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003093_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004098_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68C70>: 100%|██████████| 7/7 [00:00<00:00, 107.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A19D0>: 100%|██████████| 7/7 [00:00<00:00, 104.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58760>: 100%|██████████| 7/7 [00:00<00:00, 70.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BAC0>: 100%|██████████| 7/7 [00:00<00:00, 72.14 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001973_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006168_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9D0>: 100%|██████████| 7/7 [00:00<00:00, 40.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C370>: 100%|██████████| 7/7 [00:00<00:00, 49.12 Samples/s]                \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D60>: 100%|██████████| 7/7 [00:00<00:00, 96.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C10>: 100%|██████████| 7/7 [00:00<00:00, 109.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C619A0>:  86%|████████▌ | 6/7 [00:00<00:00, 103.78 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000241_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000009_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C619A0>: 100%|██████████| 7/7 [00:00<00:00, 118.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF1AC0>: 100%|██████████| 7/7 [00:00<00:00, 81.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9016D0>: 100%|██████████| 7/7 [00:00<00:00, 91.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691850>: 100%|██████████| 7/7 [00:00<00:00, 104.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC10>:  29%|██▊       | 2/7 [00:00<00:00, 40.07 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001647_male_Asian_46.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001852_male_Asian_27."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1CD0>: 100%|██████████| 7/7 [00:00<00:00, 76.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C619A0>: 100%|██████████| 7/7 [00:00<00:00, 86.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61880>: 100%|██████████| 7/7 [00:00<00:00, 105.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC190>: 100%|██████████| 7/7 [00:00<00:00, 83.29 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006667_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003434_male_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A00>: 100%|██████████| 7/7 [00:00<00:00, 81.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC8E0>: 100%|██████████| 7/7 [00:00<00:00, 97.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC670>: 100%|██████████| 7/7 [00:00<00:00, 84.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3880>: 100%|██████████| 7/7 [00:00<00:00, 79.35 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001528_female_Asian_34.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001338_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC670>: 100%|██████████| 7/7 [00:00<00:00, 97.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53730>: 100%|██████████| 7/7 [00:00<00:00, 104.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D90>: 100%|██████████| 7/7 [00:00<00:00, 99.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA00>: 100%|██████████| 7/7 [00:00<00:00, 85.42 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003502_male_Asian_41.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003381_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901190>: 100%|██████████| 7/7 [00:00<00:00, 92.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD490>: 100%|██████████| 7/7 [00:00<00:00, 90.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA30>: 100%|██████████| 7/7 [00:00<00:00, 100.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3460>: 100%|██████████| 7/7 [00:00<00:00, 119.42 Samples/s]         \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F35B0>:  29%|██▊       | 2/7 [00:00<00:00, 33.71 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006213_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004450_male_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC940>: 100%|██████████| 7/7 [00:00<00:00, 80.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53040>: 100%|██████████| 7/7 [00:00<00:00, 79.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30D0>: 100%|██████████| 7/7 [00:00<00:00, 72.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9018E0>: 100%|██████████| 7/7 [00:00<00:00, 99.52 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003760_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001113_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901E50>: 100%|██████████| 7/7 [00:00<00:00, 108.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9018E0>: 100%|██████████| 7/7 [00:00<00:00, 106.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B20>: 100%|██████████| 7/7 [00:00<00:00, 90.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61970>: 100%|██████████| 7/7 [00:00<00:00, 84.75 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003187_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001767_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61670>: 100%|██████████| 7/7 [00:00<00:00, 73.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C616A0>: 100%|██████████| 7/7 [00:00<00:00, 90.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61BB0>: 100%|██████████| 7/7 [00:00<00:00, 102.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53430>: 100%|██████████| 7/7 [00:00<00:00, 125.30 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9A0>:  57%|█████▋    | 4/7 [00:00<00:00, 56.85 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003110_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001775_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F10>: 100%|██████████| 7/7 [00:00<00:00, 84.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C618E0>: 100%|██████████| 7/7 [00:00<00:00, 85.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31FD0>: 100%|██████████| 7/7 [00:00<00:00, 68.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68070>: 100%|██████████| 7/7 [00:00<00:00, 79.86 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006900_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006366_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1280>: 100%|██████████| 7/7 [00:00<00:00, 106.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53AC0>: 100%|██████████| 7/7 [00:00<00:00, 103.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A93A0>: 100%|██████████| 7/7 [00:00<00:00, 107.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC550>: 100%|██████████| 7/7 [00:00<00:00, 105.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A00>:  29%|██▊       | 2/7 [00:00<00:00, 38.29 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006947_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001069_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58B20>: 100%|██████████| 7/7 [00:00<00:00, 95.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B1C0>: 100%|██████████| 7/7 [00:00<00:00, 83.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61580>: 100%|██████████| 7/7 [00:00<00:00, 101.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919040>: 100%|██████████| 7/7 [00:00<00:00, 83.65 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003832_male_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001591_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A17C0>: 100%|██████████| 7/7 [00:00<00:00, 96.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>: 100%|██████████| 7/7 [00:00<00:00, 115.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1BE0>: 100%|██████████| 7/7 [00:00<00:00, 137.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1190>: 100%|██████████| 7/7 [00:00<00:00, 69.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9192E0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003474_female_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000737_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919E50>: 100%|██████████| 7/7 [00:00<00:00, 98.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BE20>: 100%|██████████| 7/7 [00:00<00:00, 77.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31E20>: 100%|██████████| 7/7 [00:00<00:00, 95.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58BB0>: 100%|██████████| 7/7 [00:00<00:00, 97.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC190>:  14%|█▍        | 1/7 [00:00<00:00, 24.17 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006460_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003684_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D90>: 100%|██████████| 7/7 [00:00<00:00, 114.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58880>: 100%|██████████| 7/7 [00:00<00:00, 86.92 Samples/s]          \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A93D0>: 100%|██████████| 7/7 [00:00<00:00, 99.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC8E0>: 100%|██████████| 7/7 [00:00<00:00, 79.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006261_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001359_male_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919250>: 100%|██████████| 7/7 [00:00<00:00, 108.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61AF0>: 100%|██████████| 7/7 [00:00<00:00, 104.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919460>: 100%|██████████| 7/7 [00:00<00:00, 82.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61490>: 100%|██████████| 7/7 [00:00<00:00, 80.48 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003401_female_Asian_49.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000528_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61DF0>: 100%|██████████| 7/7 [00:00<00:00, 88.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919A90>: 100%|██████████| 7/7 [00:00<00:00, 109.81 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FD0>: 100%|██████████| 7/7 [00:00<00:00, 93.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53760>: 100%|██████████| 7/7 [00:00<00:00, 123.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1AF0>:  43%|████▎     | 3/7 [00:00<00:00, 47.87 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003181_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006716_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>: 100%|██████████| 7/7 [00:00<00:00, 75.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58A30>: 100%|██████████| 7/7 [00:00<00:00, 122.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53CD0>: 100%|██████████| 7/7 [00:00<00:00, 104.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533D0>: 100%|██████████| 7/7 [00:00<00:00, 81.22 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001104_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006241_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD520>: 100%|██████████| 7/7 [00:00<00:00, 44.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD2B0>: 100%|██████████| 7/7 [00:00<00:00, 37.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3D90>: 100%|██████████| 7/7 [00:00<00:00, 94.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC3A0>: 100%|██████████| 7/7 [00:00<00:00, 95.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D530D0>:  14%|█▍        | 1/7 [00:00<00:00, 25.80 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001652_female_Asian_35.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001321_female_Asian_27."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE80>: 100%|██████████| 7/7 [00:00<00:00, 96.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A90>: 100%|██████████| 7/7 [00:00<00:00, 87.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53400>: 100%|██████████| 7/7 [00:00<00:00, 95.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53310>: 100%|██████████| 7/7 [00:00<00:00, 101.49 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003506_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006164_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F32B0>: 100%|██████████| 7/7 [00:00<00:00, 40.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F10>: 100%|██████████| 7/7 [00:00<00:00, 38.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61580>: 100%|██████████| 7/7 [00:00<00:00, 68.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901940>: 100%|██████████| 7/7 [00:00<00:00, 105.83 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003599_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005532_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C613A0>: 100%|██████████| 7/7 [00:00<00:00, 94.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C10>: 100%|██████████| 7/7 [00:00<00:00, 122.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C616A0>: 100%|██████████| 7/7 [00:00<00:00, 91.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61610>: 100%|██████████| 7/7 [00:00<00:00, 96.01 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003386_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003295_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D30>: 100%|██████████| 7/7 [00:00<00:00, 82.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58730>: 100%|██████████| 7/7 [00:00<00:00, 92.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3190>: 100%|██████████| 7/7 [00:00<00:00, 79.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C40>: 100%|██████████| 7/7 [00:00<00:00, 96.07 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000601_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006648_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68FA0>: 100%|██████████| 7/7 [00:00<00:00, 90.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC5E0>: 100%|██████████| 7/7 [00:00<00:00, 96.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7940>: 100%|██████████| 7/7 [00:00<00:00, 111.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D587C0>: 100%|██████████| 7/7 [00:00<00:00, 97.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6D0>:  14%|█▍        | 1/7 [00:00<00:00, 22.02 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006623_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004465_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDFD0>: 100%|██████████| 7/7 [00:00<00:00, 81.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD730>: 100%|██████████| 7/7 [00:00<00:00, 74.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD7F0>: 100%|██████████| 7/7 [00:00<00:00, 87.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC700>: 100%|██████████| 7/7 [00:00<00:00, 121.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC040>:  14%|█▍        | 1/7 [00:00<00:00, 20.32 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001156_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006717_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC6919D0>: 100%|██████████| 7/7 [00:00<00:00, 82.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53E50>: 100%|██████████| 7/7 [00:00<00:00, 111.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCDF0>: 100%|██████████| 7/7 [00:00<00:00, 89.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCEB0>: 100%|██████████| 7/7 [00:00<00:00, 96.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1C0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006477_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001662_female_Asian_30."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B20>: 100%|██████████| 7/7 [00:00<00:00, 123.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD2B0>: 100%|██████████| 7/7 [00:00<00:00, 90.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE50>: 100%|██████████| 7/7 [00:00<00:00, 83.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B820>: 100%|██████████| 7/7 [00:00<00:00, 95.49 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001171_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003021_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD310>: 100%|██████████| 7/7 [00:00<00:00, 81.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA90>: 100%|██████████| 7/7 [00:00<00:00, 85.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD30>: 100%|██████████| 7/7 [00:00<00:00, 83.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE80>: 100%|██████████| 7/7 [00:00<00:00, 76.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC970>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003276_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005509_female_Asian_46."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53AF0>: 100%|██████████| 7/7 [00:00<00:00, 95.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDF70>: 100%|██████████| 7/7 [00:00<00:00, 119.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDDF0>: 100%|██████████| 7/7 [00:00<00:00, 85.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53040>: 100%|██████████| 7/7 [00:00<00:00, 81.46 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001436_male_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005003_female_Asian_45."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC910>: 100%|██████████| 7/7 [00:00<00:00, 98.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A2340>: 100%|██████████| 7/7 [00:00<00:00, 76.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58760>: 100%|██████████| 7/7 [00:00<00:00, 80.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA90>: 100%|██████████| 7/7 [00:00<00:00, 84.26 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003653_male_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000226_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD00>: 100%|██████████| 7/7 [00:00<00:00, 97.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53AC0>: 100%|██████████| 7/7 [00:00<00:00, 102.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53E80>: 100%|██████████| 7/7 [00:00<00:00, 80.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58AF0>: 100%|██████████| 7/7 [00:00<00:00, 81.42 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001313_female_Asian_45.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006669_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901280>: 100%|██████████| 7/7 [00:00<00:00, 96.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901190>: 100%|██████████| 7/7 [00:00<00:00, 112.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F40>: 100%|██████████| 7/7 [00:00<00:00, 93.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CA0>: 100%|██████████| 7/7 [00:00<00:00, 90.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901970>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000034_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006718_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53040>: 100%|██████████| 7/7 [00:00<00:00, 102.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D90>: 100%|██████████| 7/7 [00:00<00:00, 84.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCBE0>: 100%|██████████| 7/7 [00:00<00:00, 77.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCB50>: 100%|██████████| 7/7 [00:00<00:00, 92.22 Samples/s]                  \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001065_male_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004394_male_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C615E0>: 100%|██████████| 7/7 [00:00<00:00, 106.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCAC0>: 100%|██████████| 7/7 [00:00<00:00, 95.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3490>: 100%|██████████| 7/7 [00:00<00:00, 79.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61DC0>: 100%|██████████| 7/7 [00:00<00:00, 69.78 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001162_male_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006629_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC190>: 100%|██████████| 7/7 [00:00<00:00, 78.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D30>: 100%|██████████| 7/7 [00:00<00:00, 91.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB14250>: 100%|██████████| 7/7 [00:00<00:00, 72.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C613A0>: 100%|██████████| 7/7 [00:00<00:00, 104.65 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001089_female_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006474_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C2E0>: 100%|██████████| 7/7 [00:00<00:00, 89.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901490>: 100%|██████████| 7/7 [00:00<00:00, 90.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901640>: 100%|██████████| 7/7 [00:00<00:00, 99.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901400>: 100%|██████████| 7/7 [00:00<00:00, 98.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3490>:  14%|█▍        | 1/7 [00:00<00:00, 22.16 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003103_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003480_female_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A90>: 100%|██████████| 7/7 [00:00<00:00, 120.55 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1CA0>: 100%|██████████| 7/7 [00:00<00:00, 88.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901970>: 100%|██████████| 7/7 [00:00<00:00, 98.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC040>: 100%|██████████| 7/7 [00:00<00:00, 81.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3100>:  14%|█▍        | 1/7 [00:00<00:00, 26.83 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000006_female_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005457_female_Asian_36."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1130>: 100%|██████████| 7/7 [00:00<00:00, 100.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCBE0>: 100%|██████████| 7/7 [00:00<00:00, 82.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3190>: 100%|██████████| 7/7 [00:00<00:00, 73.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58B20>: 100%|██████████| 7/7 [00:00<00:00, 86.42 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005420_female_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003094_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68130>: 100%|██████████| 7/7 [00:00<00:00, 100.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68EE0>: 100%|██████████| 7/7 [00:00<00:00, 94.22 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F37C0>: 100%|██████████| 7/7 [00:00<00:00, 66.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC580>: 100%|██████████| 7/7 [00:00<00:00, 88.95 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001499_female_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000038_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3460>: 100%|██████████| 7/7 [00:00<00:00, 100.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD30>: 100%|██████████| 7/7 [00:00<00:00, 107.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC040>: 100%|██████████| 7/7 [00:00<00:00, 81.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC5B0>: 100%|██████████| 7/7 [00:00<00:00, 75.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD130>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003024_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005226_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC340>: 100%|██████████| 7/7 [00:00<00:00, 113.26 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA60>: 100%|██████████| 7/7 [00:00<00:00, 99.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD820>: 100%|██████████| 7/7 [00:00<00:00, 80.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3520>: 100%|██████████| 7/7 [00:00<00:00, 111.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C40>:  14%|█▍        | 1/7 [00:00<00:00, 24.43 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003274_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006608_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3D90>: 100%|██████████| 7/7 [00:00<00:00, 132.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3EE0>: 100%|██████████| 7/7 [00:00<00:00, 112.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535B0>: 100%|██████████| 7/7 [00:00<00:00, 68.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58AC0>: 100%|██████████| 7/7 [00:00<00:00, 85.49 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004247_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000725_male_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D00>: 100%|██████████| 7/7 [00:00<00:00, 104.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD4F0>: 100%|██████████| 7/7 [00:00<00:00, 109.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD730>: 100%|██████████| 7/7 [00:00<00:00, 122.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58850>: 100%|██████████| 7/7 [00:00<00:00, 117.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D534F0>:  71%|███████▏  | 5/7 [00:00<00:00, 66.06 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000746_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006593_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D00>: 100%|██████████| 7/7 [00:00<00:00, 76.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3190>: 100%|██████████| 7/7 [00:00<00:00, 98.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD160>: 100%|██████████| 7/7 [00:00<00:00, 109.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD310>: 100%|██████████| 7/7 [00:00<00:00, 115.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD2E0>: 100%|██████████| 7/7 [00:00<00:00, 100.81 Samples/s]                 \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003069_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000824_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD730>: 100%|██████████| 7/7 [00:00<00:00, 72.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3220>: 100%|██████████| 7/7 [00:00<00:00, 84.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53400>: 100%|██████████| 7/7 [00:00<00:00, 96.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF40>:  14%|█▍        | 1/7 [00:00<00:00, 25.23 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003793_female_Asian_44.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000716_male_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD970>: 100%|██████████| 7/7 [00:00<00:00, 102.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535E0>: 100%|██████████| 7/7 [00:00<00:00, 130.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3D0>: 100%|██████████| 7/7 [00:00<00:00, 88.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A2340>: 100%|██████████| 7/7 [00:00<00:00, 80.51 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005552_female_Asian_35.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005141_male_Asian_48."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD400>: 100%|██████████| 7/7 [00:00<00:00, 89.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537F0>: 100%|██████████| 7/7 [00:00<00:00, 80.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCEB0>: 100%|██████████| 7/7 [00:00<00:00, 81.01 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE20>: 100%|██████████| 7/7 [00:00<00:00, 88.12 Samples/s]          \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005118_female_Asian_28.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001894_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61970>: 100%|██████████| 7/7 [00:00<00:00, 89.51 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53250>: 100%|██████████| 7/7 [00:00<00:00, 83.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A60>: 100%|██████████| 7/7 [00:00<00:00, 113.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC100>: 100%|██████████| 7/7 [00:00<00:00, 101.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC160>:  71%|███████▏  | 5/7 [00:00<00:00, 77.27 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001149_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001707_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>: 100%|██████████| 7/7 [00:00<00:00, 103.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C616A0>: 100%|██████████| 7/7 [00:00<00:00, 94.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D30>: 100%|██████████| 7/7 [00:00<00:00, 101.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61400>: 100%|██████████| 7/7 [00:00<00:00, 108.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C615B0>:  43%|████▎     | 3/7 [00:00<00:00, 49.13 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001071_male_Asian_45.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001655_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61400>: 100%|██████████| 7/7 [00:00<00:00, 100.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901760>: 100%|██████████| 7/7 [00:00<00:00, 75.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCEB0>: 100%|██████████| 7/7 [00:00<00:00, 89.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D90>: 100%|██████████| 7/7 [00:00<00:00, 108.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31FD0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006905_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004321_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A19A0>: 100%|██████████| 7/7 [00:00<00:00, 83.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC460>: 100%|██████████| 7/7 [00:00<00:00, 95.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901640>: 100%|██████████| 7/7 [00:00<00:00, 84.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F36A0>: 100%|██████████| 7/7 [00:00<00:00, 95.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A13D0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003178_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003711_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A30>: 100%|██████████| 7/7 [00:00<00:00, 90.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3D60>: 100%|██████████| 7/7 [00:00<00:00, 108.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EB0>: 100%|██████████| 7/7 [00:00<00:00, 101.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CD0>: 100%|██████████| 7/7 [00:00<00:00, 77.63 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000831_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000531_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3100>: 100%|██████████| 7/7 [00:00<00:00, 89.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD60>: 100%|██████████| 7/7 [00:00<00:00, 67.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD00>: 100%|██████████| 7/7 [00:00<00:00, 68.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B80>:  57%|█████▋    | 4/7 [00:00<00:00, 41.95 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005283_male_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F37C0>: 100%|██████████| 7/7 [00:00<00:00, 67.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE20>: 100%|██████████| 7/7 [00:00<00:00, 113.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD9D0>: 100%|██████████| 7/7 [00:00<00:00, 85.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCEB0>:  57%|█████▋    | 4/7 [00:00<00:00, 81.73 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003432_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006406_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD6D0>: 100%|██████████| 7/7 [00:00<00:00, 124.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCAC0>: 100%|██████████| 7/7 [00:00<00:00, 101.47 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD7C0>: 100%|██████████| 7/7 [00:00<00:00, 98.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B6A0>: 100%|██████████| 7/7 [00:00<00:00, 82.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC070>:  14%|█▍        | 1/7 [00:00<00:00, 26.11 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001239_male_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003539_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC6919D0>: 100%|██████████| 7/7 [00:00<00:00, 102.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F37C0>: 100%|██████████| 7/7 [00:00<00:00, 88.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38B0>: 100%|██████████| 7/7 [00:00<00:00, 92.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1F0>: 100%|██████████| 7/7 [00:00<00:00, 88.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECC98E80>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001073_female_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006427_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC070>: 100%|██████████| 7/7 [00:00<00:00, 98.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535B0>: 100%|██████████| 7/7 [00:00<00:00, 121.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC790>: 100%|██████████| 7/7 [00:00<00:00, 77.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C40>: 100%|██████████| 7/7 [00:00<00:00, 86.72 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006737_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000718_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E80>: 100%|██████████| 7/7 [00:00<00:00, 81.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D30>: 100%|██████████| 7/7 [00:00<00:00, 99.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A60>: 100%|██████████| 7/7 [00:00<00:00, 87.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F10>: 100%|██████████| 7/7 [00:00<00:00, 90.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9190D0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001026-1_male_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003279_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53040>: 100%|██████████| 7/7 [00:00<00:00, 80.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919A30>: 100%|██████████| 7/7 [00:00<00:00, 85.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68F40>: 100%|██████████| 7/7 [00:00<00:00, 96.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691B20>: 100%|██████████| 7/7 [00:00<00:00, 92.08 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000808_male_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000557_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919CD0>: 100%|██████████| 7/7 [00:00<00:00, 95.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD910>: 100%|██████████| 7/7 [00:00<00:00, 122.87 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919550>: 100%|██████████| 7/7 [00:00<00:00, 80.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F39A0>: 100%|██████████| 7/7 [00:00<00:00, 102.72 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001851_male_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000700_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDDF0>: 100%|██████████| 7/7 [00:00<00:00, 83.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919BE0>: 100%|██████████| 7/7 [00:00<00:00, 88.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53400>: 100%|██████████| 7/7 [00:00<00:00, 102.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919790>: 100%|██████████| 7/7 [00:00<00:00, 118.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDC40>: 100%|██████████| 7/7 [00:00<00:00, 123.01 Samples/s]                 \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003282_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001357_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919670>: 100%|██████████| 7/7 [00:00<00:00, 94.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3D0>: 100%|██████████| 7/7 [00:00<00:00, 43.48 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006161_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC0A0>: 100%|██████████| 7/7 [00:00<00:00, 46.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD640>: 100%|██████████| 7/7 [00:00<00:00, 103.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDBE0>: 100%|██████████| 7/7 [00:00<00:00, 77.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCAC0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001352_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006463_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC7C0>: 100%|██████████| 7/7 [00:00<00:00, 122.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC3A0>: 100%|██████████| 7/7 [00:00<00:00, 94.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1F0>: 100%|██████████| 7/7 [00:00<00:00, 112.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF40>: 100%|██████████| 7/7 [00:00<00:00, 87.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCCD0>:  14%|█▍        | 1/7 [00:00<00:00, 18.83 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005471_female_Asian_38.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003044_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1070>: 100%|██████████| 7/7 [00:00<00:00, 107.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC370>: 100%|██████████| 7/7 [00:00<00:00, 123.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1730>: 100%|██████████| 7/7 [00:00<00:00, 79.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61970>: 100%|██████████| 7/7 [00:00<00:00, 120.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A20A0>:  29%|██▊       | 2/7 [00:00<00:00, 43.92 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006635_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001184_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901490>: 100%|██████████| 7/7 [00:00<00:00, 90.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC2E0>: 100%|██████████| 7/7 [00:00<00:00, 106.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38B0>: 100%|██████████| 7/7 [00:00<00:00, 112.27 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FC23A1070>: 100%|██████████| 7/7 [00:00<00:00, 130.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1640>:  71%|███████▏  | 5/7 [00:00<00:00, 70.81 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000512_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003738_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C2E0>: 100%|██████████| 7/7 [00:00<00:00, 80.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9016D0>: 100%|██████████| 7/7 [00:00<00:00, 95.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1670>: 100%|██████████| 7/7 [00:00<00:00, 96.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D00>: 100%|██████████| 7/7 [00:00<00:00, 84.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A19A0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006523_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000596_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1640>: 100%|██████████| 7/7 [00:00<00:00, 88.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A60>: 100%|██████████| 7/7 [00:00<00:00, 108.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EB0>: 100%|██████████| 7/7 [00:00<00:00, 93.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A9520>: 100%|██████████| 7/7 [00:00<00:00, 87.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA30>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001445_male_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006414_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD2E0>: 100%|██████████| 7/7 [00:00<00:00, 92.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68EB0>: 100%|██████████| 7/7 [00:00<00:00, 102.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD400>: 100%|██████████| 7/7 [00:00<00:00, 109.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD7C0>: 100%|██████████| 7/7 [00:00<00:00, 103.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC4C0>: 100%|██████████| 7/7 [00:00<00:00, 115.48 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004333_male_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003802_female_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919790>: 100%|██████████| 7/7 [00:00<00:00, 82.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCFA0>: 100%|██████████| 7/7 [00:00<00:00, 95.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA00>: 100%|██████████| 7/7 [00:00<00:00, 105.21 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006941_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006132_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC400>: 100%|██████████| 7/7 [00:00<00:00, 40.41 Samples/s]                \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC400>: 100%|██████████| 7/7 [00:00<00:00, 53.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD640>: 100%|██████████| 7/7 [00:00<00:00, 92.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B1C0>: 100%|██████████| 7/7 [00:00<00:00, 81.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC730>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003196_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003845_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919100>: 100%|██████████| 7/7 [00:00<00:00, 97.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198E0>: 100%|██████████| 7/7 [00:00<00:00, 93.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53280>: 100%|██████████| 7/7 [00:00<00:00, 103.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A00>: 100%|██████████| 7/7 [00:00<00:00, 109.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919A30>: 100%|██████████| 7/7 [00:00<00:00, 112.10 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003402_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001560_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD730>: 100%|██████████| 7/7 [00:00<00:00, 118.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919BB0>: 100%|██████████| 7/7 [00:00<00:00, 112.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CD0>: 100%|██████████| 7/7 [00:00<00:00, 92.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B8B0>:  29%|██▊       | 2/7 [00:00<00:00, 37.02 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003325_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005498_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A00>: 100%|██████████| 7/7 [00:00<00:00, 91.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BB20>: 100%|██████████| 7/7 [00:00<00:00, 78.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9191F0>: 100%|██████████| 7/7 [00:00<00:00, 134.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D60>: 100%|██████████| 7/7 [00:00<00:00, 85.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D539D0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006089_male_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000073_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DC0>: 100%|██████████| 7/7 [00:00<00:00, 101.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919220>: 100%|██████████| 7/7 [00:00<00:00, 91.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC490>: 100%|██████████| 7/7 [00:00<00:00, 109.59 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B6A0>: 100%|██████████| 7/7 [00:00<00:00, 81.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53850>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000214_female_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001783_female_Asian_42."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCEE0>: 100%|██████████| 7/7 [00:00<00:00, 106.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF70>: 100%|██████████| 7/7 [00:00<00:00, 102.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68C70>: 100%|██████████| 7/7 [00:00<00:00, 80.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535E0>: 100%|██████████| 7/7 [00:00<00:00, 84.85 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006665_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000514_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC3D0>: 100%|██████████| 7/7 [00:00<00:00, 81.42 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8FD820>: 100%|██████████| 7/7 [00:00<00:00, 92.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE80>: 100%|██████████| 7/7 [00:00<00:00, 63.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC730>:  57%|█████▋    | 4/7 [00:00<00:00, 44.97 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004319-1_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD30>: 100%|██████████| 7/7 [00:00<00:00, 75.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C40>: 100%|██████████| 7/7 [00:00<00:00, 36.10 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006127_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F32B0>: 100%|██████████| 7/7 [00:00<00:00, 49.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD130>: 100%|██████████| 7/7 [00:00<00:00, 91.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC3A0>: 100%|██████████| 7/7 [00:00<00:00, 121.53 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001003_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006162_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1640>: 100%|██████████| 7/7 [00:00<00:00, 42.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1730>: 100%|██████████| 7/7 [00:00<00:00, 40.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC250>: 100%|██████████| 7/7 [00:00<00:00, 94.77 Samples/s]                  \n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FECA31E80>: 100%|██████████| 7/7 [00:00<00:00, 83.72 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001347_female_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001430_male_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC910>: 100%|██████████| 7/7 [00:00<00:00, 83.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A60>: 100%|██████████| 7/7 [00:00<00:00, 117.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533A0>: 100%|██████████| 7/7 [00:00<00:00, 81.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A17C0>: 100%|██████████| 7/7 [00:00<00:00, 98.90 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003508_male_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003127_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901760>: 100%|██████████| 7/7 [00:00<00:00, 81.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBC880>: 100%|██████████| 7/7 [00:00<00:00, 66.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901C70>: 100%|██████████| 7/7 [00:00<00:00, 66.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBC880>: 100%|██████████| 7/7 [00:00<00:00, 85.82 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000717_female_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005523_male_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1520>: 100%|██████████| 7/7 [00:00<00:00, 92.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1580>: 100%|██████████| 7/7 [00:00<00:00, 101.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1640>: 100%|██████████| 7/7 [00:00<00:00, 107.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3AF0>: 100%|██████████| 7/7 [00:00<00:00, 85.85 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001388_male_Asian_21.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003511-1_male_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3DF0>: 100%|██████████| 7/7 [00:00<00:00, 80.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D90>: 100%|██████████| 7/7 [00:00<00:00, 106.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC520>: 100%|██████████| 7/7 [00:00<00:00, 99.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA00>: 100%|██████████| 7/7 [00:00<00:00, 105.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCD0>:  29%|██▊       | 2/7 [00:00<00:00, 34.02 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006471_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000721_female_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3520>: 100%|██████████| 7/7 [00:00<00:00, 93.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691B20>: 100%|██████████| 7/7 [00:00<00:00, 88.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68160>: 100%|██████████| 7/7 [00:00<00:00, 95.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD100>: 100%|██████████| 7/7 [00:00<00:00, 95.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53940>:  29%|██▊       | 2/7 [00:00<00:00, 45.26 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003468_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003384_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D90>: 100%|██████████| 7/7 [00:00<00:00, 95.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCAC0>: 100%|██████████| 7/7 [00:00<00:00, 86.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B6A0>: 100%|██████████| 7/7 [00:00<00:00, 116.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDBB0>: 100%|██████████| 7/7 [00:00<00:00, 84.25 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003875_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003226_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC610>: 100%|██████████| 7/7 [00:00<00:00, 102.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD490>: 100%|██████████| 7/7 [00:00<00:00, 98.77 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536A0>: 100%|██████████| 7/7 [00:00<00:00, 93.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDBB0>: 100%|██████████| 7/7 [00:00<00:00, 72.14 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003473_male_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006499_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D90>: 100%|██████████| 7/7 [00:00<00:00, 104.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD640>: 100%|██████████| 7/7 [00:00<00:00, 137.88 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53160>: 100%|██████████| 7/7 [00:00<00:00, 87.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC8B0>: 100%|██████████| 7/7 [00:00<00:00, 94.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FA0>:  14%|█▍        | 1/7 [00:00<00:00, 24.89 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005416_female_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005120_female_Asian_28."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3A0>: 100%|██████████| 7/7 [00:00<00:00, 103.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53310>: 100%|██████████| 7/7 [00:00<00:00, 76.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F70>: 100%|██████████| 7/7 [00:00<00:00, 84.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53EE0>: 100%|██████████| 7/7 [00:00<00:00, 112.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F40>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003867_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004305_female_Asian_48."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C613D0>: 100%|██████████| 7/7 [00:00<00:00, 85.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F70>: 100%|██████████| 7/7 [00:00<00:00, 84.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D587F0>: 100%|██████████| 7/7 [00:00<00:00, 73.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D90>: 100%|██████████| 7/7 [00:00<00:00, 94.63 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003070_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004313_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BAC0>: 100%|██████████| 7/7 [00:00<00:00, 110.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B970>: 100%|██████████| 7/7 [00:00<00:00, 95.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536D0>: 100%|██████████| 7/7 [00:00<00:00, 120.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68070>: 100%|██████████| 7/7 [00:00<00:00, 116.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7940>: 100%|██████████| 7/7 [00:00<00:00, 100.27 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000219_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006230_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC490>: 100%|██████████| 7/7 [00:00<00:00, 113.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD30>: 100%|██████████| 7/7 [00:00<00:00, 116.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919670>: 100%|██████████| 7/7 [00:00<00:00, 74.98 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005277_male_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005445_female_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD90>: 100%|██████████| 7/7 [00:00<00:00, 97.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD400>: 100%|██████████| 7/7 [00:00<00:00, 77.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA60>: 100%|██████████| 7/7 [00:00<00:00, 112.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53460>: 100%|██████████| 7/7 [00:00<00:00, 80.60 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006408_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005007_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD070>: 100%|██████████| 7/7 [00:00<00:00, 111.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38B0>: 100%|██████████| 7/7 [00:00<00:00, 78.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A00>: 100%|██████████| 7/7 [00:00<00:00, 78.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31520>: 100%|██████████| 7/7 [00:00<00:00, 96.23 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003538_male_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005449_female_Asian_48."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C340>: 100%|██████████| 7/7 [00:00<00:00, 95.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C190>: 100%|██████████| 7/7 [00:00<00:00, 90.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C40>: 100%|██████████| 7/7 [00:00<00:00, 89.57 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA90>: 100%|██████████| 7/7 [00:00<00:00, 105.36 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000819_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001905_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53760>: 100%|██████████| 7/7 [00:00<00:00, 105.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D00>: 100%|██████████| 7/7 [00:00<00:00, 68.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901760>: 100%|██████████| 7/7 [00:00<00:00, 91.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D90>: 100%|██████████| 7/7 [00:00<00:00, 119.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABD8130>:  14%|█▍        | 1/7 [00:00<00:00, 16.95 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005183_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003588_male_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCB80>: 100%|██████████| 7/7 [00:00<00:00, 82.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC880>: 100%|██████████| 7/7 [00:00<00:00, 67.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A60>: 100%|██████████| 7/7 [00:00<00:00, 72.95 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC196EB0>: 100%|██████████| 7/7 [00:00<00:00, 84.56 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005275_male_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003542_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901190>: 100%|██████████| 7/7 [00:00<00:00, 93.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC040>: 100%|██████████| 7/7 [00:00<00:00, 96.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B20>: 100%|██████████| 7/7 [00:00<00:00, 90.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F39A0>: 100%|██████████| 7/7 [00:00<00:00, 81.80 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC4C0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000045_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003125_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F35B0>: 100%|██████████| 7/7 [00:00<00:00, 109.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FA0>: 100%|██████████| 7/7 [00:00<00:00, 107.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD970>: 100%|██████████| 7/7 [00:00<00:00, 43.53 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006178_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD90>: 100%|██████████| 7/7 [00:00<00:00, 42.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53220>: 100%|██████████| 7/7 [00:00<00:00, 114.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC670>: 100%|██████████| 7/7 [00:00<00:00, 73.83 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004076_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001298_female_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF40>: 100%|██████████| 7/7 [00:00<00:00, 81.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD490>: 100%|██████████| 7/7 [00:00<00:00, 80.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53580>: 100%|██████████| 7/7 [00:00<00:00, 82.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A00>: 100%|██████████| 7/7 [00:00<00:00, 68.90 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003003_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006498_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5B0>: 100%|██████████| 7/7 [00:00<00:00, 80.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD640>: 100%|██████████| 7/7 [00:00<00:00, 86.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1C0>: 100%|██████████| 7/7 [00:00<00:00, 78.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD100>: 100%|██████████| 7/7 [00:00<00:00, 85.78 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006738_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001743_female_Asian_48."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919A30>: 100%|██████████| 7/7 [00:00<00:00, 89.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD00>: 100%|██████████| 7/7 [00:00<00:00, 103.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58760>: 100%|██████████| 7/7 [00:00<00:00, 84.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC460>: 100%|██████████| 7/7 [00:00<00:00, 74.75 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001124_male_Asian_30.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001364_male_Asian_28."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C619A0>: 100%|██████████| 7/7 [00:00<00:00, 106.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>: 100%|██████████| 7/7 [00:00<00:00, 127.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C615B0>: 100%|██████████| 7/7 [00:00<00:00, 92.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC5B0>: 100%|██████████| 7/7 [00:00<00:00, 82.65 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001275_female_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005034_male_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919700>: 100%|██████████| 7/7 [00:00<00:00, 89.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC550>: 100%|██████████| 7/7 [00:00<00:00, 94.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B820>: 100%|██████████| 7/7 [00:00<00:00, 83.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61970>: 100%|██████████| 7/7 [00:00<00:00, 109.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61DF0>:  14%|█▍        | 1/7 [00:00<00:00, 21.51 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005211_male_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001751_male_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7940>: 100%|██████████| 7/7 [00:00<00:00, 93.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9191F0>: 100%|██████████| 7/7 [00:00<00:00, 73.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C615E0>: 100%|██████████| 7/7 [00:00<00:00, 111.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D30>: 100%|██████████| 7/7 [00:00<00:00, 119.68 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6D0>:  57%|█████▋    | 4/7 [00:00<00:00, 69.53 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001044_female_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005110_female_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD310>: 100%|██████████| 7/7 [00:00<00:00, 90.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537C0>: 100%|██████████| 7/7 [00:00<00:00, 124.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD90>: 100%|██████████| 7/7 [00:00<00:00, 100.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD6D0>: 100%|██████████| 7/7 [00:00<00:00, 84.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD820>:  29%|██▊       | 2/7 [00:00<00:00, 46.54 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000224_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004242_female_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198B0>: 100%|██████████| 7/7 [00:00<00:00, 127.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCA0>: 100%|██████████| 7/7 [00:00<00:00, 74.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC460>: 100%|██████████| 7/7 [00:00<00:00, 84.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53940>: 100%|██████████| 7/7 [00:00<00:00, 110.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC3A0>:  29%|██▊       | 2/7 [00:00<00:00, 43.68 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006410_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003088_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A90>: 100%|██████████| 7/7 [00:00<00:00, 93.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535B0>: 100%|██████████| 7/7 [00:00<00:00, 114.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD970>: 100%|██████████| 7/7 [00:00<00:00, 81.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901490>: 100%|██████████| 7/7 [00:00<00:00, 99.46 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004443_male_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005419_female_Asian_38."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3220>: 100%|██████████| 7/7 [00:00<00:00, 78.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3E80>: 100%|██████████| 7/7 [00:00<00:00, 103.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC700>: 100%|██████████| 7/7 [00:00<00:00, 84.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9012E0>: 100%|██████████| 7/7 [00:00<00:00, 86.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DC0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000826_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000622_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1430>: 100%|██████████| 7/7 [00:00<00:00, 134.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C40>: 100%|██████████| 7/7 [00:00<00:00, 98.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABD04C0>: 100%|██████████| 7/7 [00:00<00:00, 40.02 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006231_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABD07F0>: 100%|██████████| 7/7 [00:00<00:00, 40.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1F0>: 100%|██████████| 7/7 [00:00<00:00, 92.98 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FAABCCCD0>: 100%|██████████| 7/7 [00:00<00:00, 88.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC670>:  14%|█▍        | 1/7 [00:00<00:00, 24.84 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003550_male_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006944_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1B50>: 100%|██████████| 7/7 [00:00<00:00, 88.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C310>: 100%|██████████| 7/7 [00:00<00:00, 104.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68E20>: 100%|██████████| 7/7 [00:00<00:00, 115.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919100>: 100%|██████████| 7/7 [00:00<00:00, 86.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1670>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005009_female_Asian_49.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003593_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1CD0>: 100%|██████████| 7/7 [00:00<00:00, 98.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68D00>: 100%|██████████| 7/7 [00:00<00:00, 113.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D688B0>: 100%|██████████| 7/7 [00:00<00:00, 97.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53760>: 100%|██████████| 7/7 [00:00<00:00, 123.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A13D0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006750_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001087_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F10>: 100%|██████████| 7/7 [00:00<00:00, 86.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53BB0>: 100%|██████████| 7/7 [00:00<00:00, 99.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919760>: 100%|██████████| 7/7 [00:00<00:00, 118.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535E0>: 100%|██████████| 7/7 [00:00<00:00, 91.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9194F0>:  71%|███████▏  | 5/7 [00:00<00:00, 86.03 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004268_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000565_female_Asian_35."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F70>: 100%|██████████| 7/7 [00:00<00:00, 111.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58640>: 100%|██████████| 7/7 [00:00<00:00, 106.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58A30>: 100%|██████████| 7/7 [00:00<00:00, 97.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B20>: 100%|██████████| 7/7 [00:00<00:00, 101.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919220>:  14%|█▍        | 1/7 [00:00<00:00, 21.45 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001218_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000288_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11C0>: 100%|██████████| 7/7 [00:00<00:00, 89.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9195E0>: 100%|██████████| 7/7 [00:00<00:00, 134.01 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F36A0>: 100%|██████████| 7/7 [00:00<00:00, 67.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919760>: 100%|██████████| 7/7 [00:00<00:00, 110.90 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001422_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003562_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61850>: 100%|██████████| 7/7 [00:00<00:00, 83.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61DC0>: 100%|██████████| 7/7 [00:00<00:00, 94.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9192B0>: 100%|██████████| 7/7 [00:00<00:00, 91.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61820>: 100%|██████████| 7/7 [00:00<00:00, 85.31 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003164_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001587_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919040>: 100%|██████████| 7/7 [00:00<00:00, 89.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3400>: 100%|██████████| 7/7 [00:00<00:00, 80.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198E0>: 100%|██████████| 7/7 [00:00<00:00, 94.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3700>: 100%|██████████| 7/7 [00:00<00:00, 77.39 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003561_male_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006357_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D60>: 100%|██████████| 7/7 [00:00<00:00, 80.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5B0>: 100%|██████████| 7/7 [00:00<00:00, 131.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC160>: 100%|██████████| 7/7 [00:00<00:00, 88.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B1C0>: 100%|██████████| 7/7 [00:00<00:00, 127.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61730>:  71%|███████▏  | 5/7 [00:00<00:00, 89.20 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006407_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006948_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3AC0>: 100%|██████████| 7/7 [00:00<00:00, 108.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C616D0>: 100%|██████████| 7/7 [00:00<00:00, 75.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61820>: 100%|██████████| 7/7 [00:00<00:00, 73.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCBB0>: 100%|██████████| 7/7 [00:00<00:00, 93.19 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005225_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000334_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC910>: 100%|██████████| 7/7 [00:00<00:00, 83.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC580>: 100%|██████████| 7/7 [00:00<00:00, 86.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC310>: 100%|██████████| 7/7 [00:00<00:00, 109.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CA0>: 100%|██████████| 7/7 [00:00<00:00, 90.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6D0>:  57%|█████▋    | 4/7 [00:00<00:00, 75.52 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003358_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000529_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919220>: 100%|██████████| 7/7 [00:00<00:00, 89.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE50>: 100%|██████████| 7/7 [00:00<00:00, 109.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9195E0>: 100%|██████████| 7/7 [00:00<00:00, 92.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D589D0>: 100%|██████████| 7/7 [00:00<00:00, 76.52 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001393_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006609_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919B50>: 100%|██████████| 7/7 [00:00<00:00, 80.05 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3F10>: 100%|██████████| 7/7 [00:00<00:00, 73.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F10>: 100%|██████████| 7/7 [00:00<00:00, 64.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1EEE0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000227_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901520>: 100%|██████████| 7/7 [00:00<00:00, 53.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919CA0>: 100%|██████████| 7/7 [00:00<00:00, 58.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC7F0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001496_male_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC070>: 100%|██████████| 7/7 [00:00<00:00, 59.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1610>: 100%|██████████| 7/7 [00:00<00:00, 68.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D30>: 100%|██████████| 7/7 [00:00<00:00, 112.88 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003890_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001024-1_female_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919070>: 100%|██████████| 7/7 [00:00<00:00, 74.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A17C0>: 100%|██████████| 7/7 [00:00<00:00, 68.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1520>: 100%|██████████| 7/7 [00:00<00:00, 90.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCB50>: 100%|██████████| 7/7 [00:00<00:00, 73.20 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006401_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000276_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919160>: 100%|██████████| 7/7 [00:00<00:00, 60.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53730>: 100%|██████████| 7/7 [00:00<00:00, 80.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DC0>: 100%|██████████| 7/7 [00:00<00:00, 72.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919640>:  57%|█████▋    | 4/7 [00:00<00:00, 39.17 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006412_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D30>: 100%|██████████| 7/7 [00:00<00:00, 66.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919790>: 100%|██████████| 7/7 [00:00<00:00, 64.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53430>: 100%|██████████| 7/7 [00:00<00:00, 91.91 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003740_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004027_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7940>: 100%|██████████| 7/7 [00:00<00:00, 74.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1880>: 100%|██████████| 7/7 [00:00<00:00, 93.21 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FECB1C2E0>: 100%|██████████| 7/7 [00:00<00:00, 97.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C3D0>: 100%|██████████| 7/7 [00:00<00:00, 80.91 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004245_female_Asian_49.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003292_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901490>: 100%|██████████| 7/7 [00:00<00:00, 64.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A00>: 100%|██████████| 7/7 [00:00<00:00, 96.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F40>: 100%|██████████| 7/7 [00:00<00:00, 102.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D538B0>: 100%|██████████| 7/7 [00:00<00:00, 92.74 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006675_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004006_male_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11F0>: 100%|██████████| 7/7 [00:00<00:00, 76.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901C70>: 100%|██████████| 7/7 [00:00<00:00, 75.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1DC0>: 100%|██████████| 7/7 [00:00<00:00, 68.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53430>:  86%|████████▌ | 6/7 [00:00<00:00, 62.80 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001405_male_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53430>: 100%|██████████| 7/7 [00:00<00:00, 72.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A00>: 100%|██████████| 7/7 [00:00<00:00, 59.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D30>:  14%|█▍        | 1/7 [00:00<00:00, 15.55 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003303_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EE0>: 100%|██████████| 7/7 [00:00<00:00, 61.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58790>: 100%|██████████| 7/7 [00:00<00:00, 87.10 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919820>: 100%|██████████| 7/7 [00:00<00:00, 73.78 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001727_male_Asian_28.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005513_female_Asian_48."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9199A0>: 100%|██████████| 7/7 [00:00<00:00, 63.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F34F0>: 100%|██████████| 7/7 [00:00<00:00, 104.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58B20>: 100%|██████████| 7/7 [00:00<00:00, 80.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>: 100%|██████████| 7/7 [00:00<00:00, 83.67 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001629_female_Asian_42.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001508_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38E0>: 100%|██████████| 7/7 [00:00<00:00, 66.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58700>: 100%|██████████| 7/7 [00:00<00:00, 67.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C618E0>: 100%|██████████| 7/7 [00:00<00:00, 89.79 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BE20>: 100%|██████████| 7/7 [00:00<00:00, 101.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3F10>:  14%|█▍        | 1/7 [00:00<00:00, 20.57 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001193_male_Asian_21.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005464_male_Asian_47."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61A60>: 100%|██████████| 7/7 [00:00<00:00, 86.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B970>: 100%|██████████| 7/7 [00:00<00:00, 95.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC8B0>: 100%|██████████| 7/7 [00:00<00:00, 35.16 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006159_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing <PIL.PngImagePlugin.PngImageFile image mode=RGB size=384x512 at 0x7F8FEC8F3190>: 100%|██████████| 7/7 [00:00<00:00, 28.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF40>: 100%|██████████| 7/7 [00:00<00:00, 62.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3E20>:  29%|██▊       | 2/7 [00:00<00:00, 25.58 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001245_female_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC070>: 100%|██████████| 7/7 [00:00<00:00, 70.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC5B0>: 100%|██████████| 7/7 [00:00<00:00, 78.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9A0>: 100%|██████████| 7/7 [00:00<00:00, 82.52 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006607_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004422_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA60>: 100%|██████████| 7/7 [00:00<00:00, 90.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC100>: 100%|██████████| 7/7 [00:00<00:00, 72.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D586D0>: 100%|██████████| 7/7 [00:00<00:00, 77.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA90>: 100%|██████████| 7/7 [00:00<00:00, 94.22 Samples/s]                  \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001231_male_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001179_male_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA60>: 100%|██████████| 7/7 [00:00<00:00, 85.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61430>: 100%|██████████| 7/7 [00:00<00:00, 94.20 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1160>: 100%|██████████| 7/7 [00:00<00:00, 84.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EB0>: 100%|██████████| 7/7 [00:00<00:00, 89.89 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003055_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006206_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53160>: 100%|██████████| 7/7 [00:00<00:00, 41.22 Samples/s]                \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1F10>: 100%|██████████| 7/7 [00:00<00:00, 49.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6A0>: 100%|██████████| 7/7 [00:00<00:00, 112.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53850>: 100%|██████████| 7/7 [00:00<00:00, 115.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F40>: 100%|██████████| 7/7 [00:00<00:00, 105.86 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003225_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003808_male_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9193D0>: 100%|██████████| 7/7 [00:00<00:00, 106.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919820>: 100%|██████████| 7/7 [00:00<00:00, 91.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D60>: 100%|██████████| 7/7 [00:00<00:00, 106.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC4C0>:  14%|█▍        | 1/7 [00:00<00:00, 23.44 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000078_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006688_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58700>: 100%|██████████| 7/7 [00:00<00:00, 89.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901100>: 100%|██████████| 7/7 [00:00<00:00, 125.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC250>: 100%|██████████| 7/7 [00:00<00:00, 116.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53400>: 100%|██████████| 7/7 [00:00<00:00, 103.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31FD0>:  57%|█████▋    | 4/7 [00:00<00:00, 79.39 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003017_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005530_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919550>: 100%|██████████| 7/7 [00:00<00:00, 93.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC400>: 100%|██████████| 7/7 [00:00<00:00, 104.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901E50>: 100%|██████████| 7/7 [00:00<00:00, 115.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7B20>: 100%|██████████| 7/7 [00:00<00:00, 73.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC4C0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000031_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006753_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901C70>: 100%|██████████| 7/7 [00:00<00:00, 126.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1BB0>: 100%|██████████| 7/7 [00:00<00:00, 87.31 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31E20>: 100%|██████████| 7/7 [00:00<00:00, 103.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7E66850>: 100%|██████████| 7/7 [00:00<00:00, 102.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D538B0>:  43%|████▎     | 3/7 [00:00<00:00, 54.96 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003643_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001735_male_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA3F0A0>: 100%|██████████| 7/7 [00:00<00:00, 98.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBC3D0>: 100%|██████████| 7/7 [00:00<00:00, 107.02 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF14C0>: 100%|██████████| 7/7 [00:00<00:00, 77.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A9520>: 100%|██████████| 7/7 [00:00<00:00, 122.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1FD0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006613_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005439_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1190>: 100%|██████████| 7/7 [00:00<00:00, 94.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919220>: 100%|██████████| 7/7 [00:00<00:00, 112.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535B0>: 100%|██████████| 7/7 [00:00<00:00, 79.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919B50>: 100%|██████████| 7/7 [00:00<00:00, 85.66 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005450_female_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000713_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D60>: 100%|██████████| 7/7 [00:00<00:00, 111.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E20>: 100%|██████████| 7/7 [00:00<00:00, 100.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EB0>: 100%|██████████| 7/7 [00:00<00:00, 93.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198B0>: 100%|██████████| 7/7 [00:00<00:00, 88.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53910>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006445_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003699_male_Asian_41."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1DC0>: 100%|██████████| 7/7 [00:00<00:00, 99.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B80>: 100%|██████████| 7/7 [00:00<00:00, 91.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D589A0>: 100%|██████████| 7/7 [00:00<00:00, 77.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3910>: 100%|██████████| 7/7 [00:00<00:00, 101.61 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006951_male_Asian_21.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001660_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D589A0>: 100%|██████████| 7/7 [00:00<00:00, 98.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38E0>: 100%|██████████| 7/7 [00:00<00:00, 83.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58880>: 100%|██████████| 7/7 [00:00<00:00, 85.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1640>: 100%|██████████| 7/7 [00:00<00:00, 86.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3490>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005215_male_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004399_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D588B0>: 100%|██████████| 7/7 [00:00<00:00, 112.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F37C0>: 100%|██████████| 7/7 [00:00<00:00, 86.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533A0>: 100%|██████████| 7/7 [00:00<00:00, 68.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A90>: 100%|██████████| 7/7 [00:00<00:00, 102.94 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001808_male_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001501_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3DF0>: 100%|██████████| 7/7 [00:00<00:00, 88.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3400>: 100%|██████████| 7/7 [00:00<00:00, 104.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCB20>: 100%|██████████| 7/7 [00:00<00:00, 132.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533A0>: 100%|██████████| 7/7 [00:00<00:00, 86.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC730>:  29%|██▊       | 2/7 [00:00<00:00, 35.50 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001795_male_Asian_27.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006643_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC190>: 100%|██████████| 7/7 [00:00<00:00, 72.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9D0>: 100%|██████████| 7/7 [00:00<00:00, 151.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC7F0>: 100%|██████████| 7/7 [00:00<00:00, 93.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF70>: 100%|██████████| 7/7 [00:00<00:00, 77.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3490>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003319_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006409_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCCD0>: 100%|██████████| 7/7 [00:00<00:00, 103.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C616A0>: 100%|██████████| 7/7 [00:00<00:00, 70.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D589A0>: 100%|██████████| 7/7 [00:00<00:00, 110.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D589A0>: 100%|██████████| 7/7 [00:00<00:00, 89.47 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001620_male_Asian_45.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006610_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC3A0>: 100%|██████████| 7/7 [00:00<00:00, 95.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA60>: 100%|██████████| 7/7 [00:00<00:00, 86.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58BB0>: 100%|██████████| 7/7 [00:00<00:00, 102.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F36A0>: 100%|██████████| 7/7 [00:00<00:00, 95.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3460>:  43%|████▎     | 3/7 [00:00<00:00, 59.21 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005130_female_Asian_29.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001198_male_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901520>: 100%|██████████| 7/7 [00:00<00:00, 87.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A00>: 100%|██████████| 7/7 [00:00<00:00, 74.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901E50>: 100%|██████████| 7/7 [00:00<00:00, 68.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D90>: 100%|██████████| 7/7 [00:00<00:00, 100.29 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001534_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003143_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F10>: 100%|██████████| 7/7 [00:00<00:00, 98.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58C40>: 100%|██████████| 7/7 [00:00<00:00, 100.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53BB0>: 100%|██████████| 7/7 [00:00<00:00, 95.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F10>: 100%|██████████| 7/7 [00:00<00:00, 131.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF14C0>:  57%|█████▋    | 4/7 [00:00<00:00, 61.10 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001025_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003144_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EE0>: 100%|██████████| 7/7 [00:00<00:00, 80.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A9520>: 100%|██████████| 7/7 [00:00<00:00, 93.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D531C0>: 100%|██████████| 7/7 [00:00<00:00, 80.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919220>: 100%|██████████| 7/7 [00:00<00:00, 91.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006377_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000592_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198E0>: 100%|██████████| 7/7 [00:00<00:00, 130.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919E20>: 100%|██████████| 7/7 [00:00<00:00, 107.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68FD0>: 100%|██████████| 7/7 [00:00<00:00, 91.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C40>: 100%|██████████| 7/7 [00:00<00:00, 73.66 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000217_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005252_male_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53280>: 100%|██████████| 7/7 [00:00<00:00, 78.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5E0>: 100%|██████████| 7/7 [00:00<00:00, 91.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9197F0>: 100%|██████████| 7/7 [00:00<00:00, 93.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3A0>: 100%|██████████| 7/7 [00:00<00:00, 80.97 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000776_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003146_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691B20>: 100%|██████████| 7/7 [00:00<00:00, 98.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53700>: 100%|██████████| 7/7 [00:00<00:00, 112.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD730>: 100%|██████████| 7/7 [00:00<00:00, 111.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53310>: 100%|██████████| 7/7 [00:00<00:00, 103.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD100>:  71%|███████▏  | 5/7 [00:00<00:00, 85.28 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005090_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006440_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11C0>: 100%|██████████| 7/7 [00:00<00:00, 91.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A2100>: 100%|██████████| 7/7 [00:00<00:00, 85.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1AC0>: 100%|██████████| 7/7 [00:00<00:00, 67.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919460>: 100%|██████████| 7/7 [00:00<00:00, 96.36 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000047_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001302_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD100>: 100%|██████████| 7/7 [00:00<00:00, 86.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901E50>: 100%|██████████| 7/7 [00:00<00:00, 110.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901940>: 100%|██████████| 7/7 [00:00<00:00, 123.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53760>: 100%|██████████| 7/7 [00:00<00:00, 101.87 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FA0>:  57%|█████▋    | 4/7 [00:00<00:00, 60.51 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004306_female_Asian_42.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001628_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901340>: 100%|██████████| 7/7 [00:00<00:00, 81.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EB0>: 100%|██████████| 7/7 [00:00<00:00, 103.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD90>: 100%|██████████| 7/7 [00:00<00:00, 100.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD790>: 100%|██████████| 7/7 [00:00<00:00, 128.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F34F0>:  43%|████▎     | 3/7 [00:00<00:00, 42.86 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000556_male_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006371_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E20>: 100%|██████████| 7/7 [00:00<00:00, 79.61 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8FDA30>: 100%|██████████| 7/7 [00:00<00:00, 105.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDEE0>: 100%|██████████| 7/7 [00:00<00:00, 36.56 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006177_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD400>: 100%|██████████| 7/7 [00:00<00:00, 47.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCBB0>: 100%|██████████| 7/7 [00:00<00:00, 84.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1F0>: 100%|██████████| 7/7 [00:00<00:00, 96.50 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001481_male_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004472_female_Asian_49."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3190>: 100%|██████████| 7/7 [00:00<00:00, 89.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61A90>: 100%|██████████| 7/7 [00:00<00:00, 99.62 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD340>: 100%|██████████| 7/7 [00:00<00:00, 89.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D538B0>: 100%|██████████| 7/7 [00:00<00:00, 115.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC970>:  29%|██▊       | 2/7 [00:00<00:00, 50.77 Samples/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001396_male_Asian_45.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006480_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30A0>: 100%|██████████| 7/7 [00:00<00:00, 105.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCBE0>: 100%|██████████| 7/7 [00:00<00:00, 78.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9A0>: 100%|██████████| 7/7 [00:00<00:00, 73.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E20>: 100%|██████████| 7/7 [00:00<00:00, 70.94 Samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004221_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001224_female_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B670>: 100%|██████████| 7/7 [00:00<00:00, 115.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A22E0>: 100%|██████████| 7/7 [00:00<00:00, 88.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCFA0>: 100%|██████████| 7/7 [00:00<00:00, 112.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3DF0>: 100%|██████████| 7/7 [00:00<00:00, 83.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58790>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001526_female_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005479_male_Asian_45."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF40>: 100%|██████████| 7/7 [00:00<00:00, 80.12 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8F3BB0>: 100%|██████████| 7/7 [00:00<00:00, 116.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53730>: 100%|██████████| 7/7 [00:00<00:00, 100.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D531C0>: 100%|██████████| 7/7 [00:00<00:00, 105.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCAF0>:  43%|████▎     | 3/7 [00:00<00:00, 63.65 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003314_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001105_male_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919CD0>: 100%|██████████| 7/7 [00:00<00:00, 108.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3760>: 100%|██████████| 7/7 [00:00<00:00, 93.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA30>: 100%|██████████| 7/7 [00:00<00:00, 89.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3220>: 100%|██████████| 7/7 [00:00<00:00, 63.20 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001200_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001139_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3880>: 100%|██████████| 7/7 [00:00<00:00, 82.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3BE0>: 100%|██████████| 7/7 [00:00<00:00, 76.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC5E0>: 100%|██████████| 7/7 [00:00<00:00, 78.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198E0>: 100%|██████████| 7/7 [00:00<00:00, 73.46 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003082_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005257_male_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7B20>: 100%|██████████| 7/7 [00:00<00:00, 125.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536D0>: 100%|██████████| 7/7 [00:00<00:00, 85.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68D00>: 100%|██████████| 7/7 [00:00<00:00, 84.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1130>: 100%|██████████| 7/7 [00:00<00:00, 90.25 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005276_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005089_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1580>: 100%|██████████| 7/7 [00:00<00:00, 90.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC430>: 100%|██████████| 7/7 [00:00<00:00, 87.08 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D531C0>: 100%|██████████| 7/7 [00:00<00:00, 83.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCBB0>: 100%|██████████| 7/7 [00:00<00:00, 98.75 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FC23A13D0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005065_female_Asian_49.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006367_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53850>: 100%|██████████| 7/7 [00:00<00:00, 112.72 Samples/s]         \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABD81F0>: 100%|██████████| 7/7 [00:00<00:00, 103.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF1AC0>: 100%|██████████| 7/7 [00:00<00:00, 111.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919550>: 100%|██████████| 7/7 [00:00<00:00, 98.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9199A0>:  43%|████▎     | 3/7 [00:00<00:00, 59.31 Samples/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003101_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004367_male_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31CA0>: 100%|██████████| 7/7 [00:00<00:00, 89.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31E50>: 100%|██████████| 7/7 [00:00<00:00, 100.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919490>: 100%|██████████| 7/7 [00:00<00:00, 90.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53E50>: 100%|██████████| 7/7 [00:00<00:00, 91.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1BB0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001774_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000231_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A19D0>: 100%|██████████| 7/7 [00:00<00:00, 87.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD2B0>: 100%|██████████| 7/7 [00:00<00:00, 93.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1550>: 100%|██████████| 7/7 [00:00<00:00, 104.58 Samples/s]         \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EB0>: 100%|██████████| 7/7 [00:00<00:00, 114.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9190A0>:  71%|███████▏  | 5/7 [00:00<00:00, 80.94 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000821_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005035_female_Asian_49."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A2100>: 100%|██████████| 7/7 [00:00<00:00, 88.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D538B0>: 100%|██████████| 7/7 [00:00<00:00, 114.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F70>: 100%|██████████| 7/7 [00:00<00:00, 92.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61DC0>: 100%|██████████| 7/7 [00:00<00:00, 108.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD430>:  43%|████▎     | 3/7 [00:00<00:00, 54.67 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000797_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006699_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3D60>: 100%|██████████| 7/7 [00:00<00:00, 88.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1430>: 100%|██████████| 7/7 [00:00<00:00, 86.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901340>: 100%|██████████| 7/7 [00:00<00:00, 81.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7E66850>: 100%|██████████| 7/7 [00:00<00:00, 107.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61940>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001745_female_Asian_47.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004346_female_Asian_45."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E50>: 100%|██████████| 7/7 [00:00<00:00, 97.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C613A0>: 100%|██████████| 7/7 [00:00<00:00, 99.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11C0>: 100%|██████████| 7/7 [00:00<00:00, 88.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1850>: 100%|██████████| 7/7 [00:00<00:00, 81.73 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004272_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006154_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDC40>: 100%|██████████| 7/7 [00:00<00:00, 46.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC3A0>: 100%|██████████| 7/7 [00:00<00:00, 47.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3610>: 100%|██████████| 7/7 [00:00<00:00, 93.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA60>: 100%|██████████| 7/7 [00:00<00:00, 110.98 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A30>: 100%|██████████| 7/7 [00:00<00:00, 137.62 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003234_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003169_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F35B0>: 100%|██████████| 7/7 [00:00<00:00, 103.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC10>: 100%|██████████| 7/7 [00:00<00:00, 105.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC310>: 100%|██████████| 7/7 [00:00<00:00, 72.11 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001631_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004345_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE80>: 100%|██████████| 7/7 [00:00<00:00, 92.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3490>: 100%|██████████| 7/7 [00:00<00:00, 73.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD100>: 100%|██████████| 7/7 [00:00<00:00, 71.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC250>: 100%|██████████| 7/7 [00:00<00:00, 83.29 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001085_male_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003312_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D589D0>: 100%|██████████| 7/7 [00:00<00:00, 98.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC280>: 100%|██████████| 7/7 [00:00<00:00, 105.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C40>: 100%|██████████| 7/7 [00:00<00:00, 87.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>: 100%|██████████| 7/7 [00:00<00:00, 92.47 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005248_male_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001051_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3490>: 100%|██████████| 7/7 [00:00<00:00, 88.86 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E20>: 100%|██████████| 7/7 [00:00<00:00, 113.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC640>: 100%|██████████| 7/7 [00:00<00:00, 102.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58BB0>: 100%|██████████| 7/7 [00:00<00:00, 77.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68CA0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000799_female_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000679_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53130>: 100%|██████████| 7/7 [00:00<00:00, 108.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C160>: 100%|██████████| 7/7 [00:00<00:00, 107.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD90>: 100%|██████████| 7/7 [00:00<00:00, 107.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58850>: 100%|██████████| 7/7 [00:00<00:00, 96.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC40>:  14%|█▍        | 1/7 [00:00<00:00, 16.87 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005067-1_female_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000789_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68CA0>: 100%|██████████| 7/7 [00:00<00:00, 87.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1CA0>: 100%|██████████| 7/7 [00:00<00:00, 122.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCFA0>: 100%|██████████| 7/7 [00:00<00:00, 86.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CA0>: 100%|██████████| 7/7 [00:00<00:00, 87.67 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001630-1_female_Asian_34.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000535_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC430>: 100%|██████████| 7/7 [00:00<00:00, 71.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53850>: 100%|██████████| 7/7 [00:00<00:00, 80.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D90>: 100%|██████████| 7/7 [00:00<00:00, 68.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D90>: 100%|██████████| 7/7 [00:00<00:00, 93.52 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000016_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005443_female_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9193D0>: 100%|██████████| 7/7 [00:00<00:00, 79.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1520>: 100%|██████████| 7/7 [00:00<00:00, 87.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1DC0>: 100%|██████████| 7/7 [00:00<00:00, 98.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53850>: 100%|██████████| 7/7 [00:00<00:00, 92.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D60>:  71%|███████▏  | 5/7 [00:00<00:00, 104.19 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003348_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006398_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53FD0>: 100%|██████████| 7/7 [00:00<00:00, 119.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDAC0>: 100%|██████████| 7/7 [00:00<00:00, 99.58 Samples/s]                   \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EB0>: 100%|██████████| 7/7 [00:00<00:00, 83.95 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE20>: 100%|██████████| 7/7 [00:00<00:00, 93.11 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003369_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000691_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDBE0>: 100%|██████████| 7/7 [00:00<00:00, 94.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D30>: 100%|██████████| 7/7 [00:00<00:00, 99.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECCA5E20>: 100%|██████████| 7/7 [00:00<00:00, 81.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D688B0>: 100%|██████████| 7/7 [00:00<00:00, 86.52 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005145_female_Asian_30.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003490_male_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D90>: 100%|██████████| 7/7 [00:00<00:00, 75.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9199D0>: 100%|██████████| 7/7 [00:00<00:00, 106.04 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68CA0>: 100%|██████████| 7/7 [00:00<00:00, 62.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD700>:  71%|███████▏  | 5/7 [00:00<00:00, 64.65 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005036_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B100>: 100%|██████████| 7/7 [00:00<00:00, 75.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68EB0>: 100%|██████████| 7/7 [00:00<00:00, 86.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDBB0>: 100%|██████████| 7/7 [00:00<00:00, 89.33 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005430_male_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003135_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EE0>: 100%|██████████| 7/7 [00:00<00:00, 108.22 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDEE0>: 100%|██████████| 7/7 [00:00<00:00, 89.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919130>: 100%|██████████| 7/7 [00:00<00:00, 91.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3D90>: 100%|██████████| 7/7 [00:00<00:00, 89.48 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003484_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001154_female_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDF70>: 100%|██████████| 7/7 [00:00<00:00, 86.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F34F0>: 100%|██████████| 7/7 [00:00<00:00, 109.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D60>: 100%|██████████| 7/7 [00:00<00:00, 84.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FA0>: 100%|██████████| 7/7 [00:00<00:00, 99.46 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCD0>:  14%|█▍        | 1/7 [00:00<00:00, 54.45 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006926_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000295_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9016D0>: 100%|██████████| 7/7 [00:00<00:00, 119.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D586D0>: 100%|██████████| 7/7 [00:00<00:00, 72.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53130>: 100%|██████████| 7/7 [00:00<00:00, 94.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58AF0>: 100%|██████████| 7/7 [00:00<00:00, 99.37 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD970>:  43%|████▎     | 3/7 [00:00<00:00, 58.92 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001460_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001013_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53EE0>: 100%|██████████| 7/7 [00:00<00:00, 80.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53730>: 100%|██████████| 7/7 [00:00<00:00, 85.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A90>: 100%|██████████| 7/7 [00:00<00:00, 103.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F36A0>: 100%|██████████| 7/7 [00:00<00:00, 99.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1C0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003397_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006229_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC10>: 100%|██████████| 7/7 [00:00<00:00, 82.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC100>: 100%|██████████| 7/7 [00:00<00:00, 67.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58700>: 100%|██████████| 7/7 [00:00<00:00, 78.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F70>: 100%|██████████| 7/7 [00:00<00:00, 66.80 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000614_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005435_female_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDEE0>: 100%|██████████| 7/7 [00:00<00:00, 83.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC760>: 100%|██████████| 7/7 [00:00<00:00, 86.51 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD60>: 100%|██████████| 7/7 [00:00<00:00, 95.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58910>: 100%|██████████| 7/7 [00:00<00:00, 75.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1F0>:  14%|█▍        | 1/7 [00:00<00:00, 56.72 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001498_female_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004378_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC7F0>: 100%|██████████| 7/7 [00:00<00:00, 123.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC7F0>: 100%|██████████| 7/7 [00:00<00:00, 111.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CA0>: 100%|██████████| 7/7 [00:00<00:00, 93.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58730>: 100%|██████████| 7/7 [00:00<00:00, 104.46 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC460>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006413_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006527_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901970>: 100%|██████████| 7/7 [00:00<00:00, 70.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536D0>: 100%|██████████| 7/7 [00:00<00:00, 131.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901280>: 100%|██████████| 7/7 [00:00<00:00, 104.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30A0>: 100%|██████████| 7/7 [00:00<00:00, 91.53 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D30>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003328_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005520_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCAC0>: 100%|██████████| 7/7 [00:00<00:00, 79.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C310>: 100%|██████████| 7/7 [00:00<00:00, 103.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C190>: 100%|██████████| 7/7 [00:00<00:00, 115.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FA0>: 100%|██████████| 7/7 [00:00<00:00, 93.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61A90>: 100%|██████████| 7/7 [00:00<00:00, 135.06 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004078_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003619_male_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1520>: 100%|██████████| 7/7 [00:00<00:00, 86.30 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61430>: 100%|██████████| 7/7 [00:00<00:00, 102.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612E0>: 100%|██████████| 7/7 [00:00<00:00, 88.60 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005527_female_Asian_40.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006349_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A30>: 100%|██████████| 7/7 [00:00<00:00, 92.82 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC40>: 100%|██████████| 7/7 [00:00<00:00, 81.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61910>: 100%|██████████| 7/7 [00:00<00:00, 76.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC220>: 100%|██████████| 7/7 [00:00<00:00, 111.92 Samples/s]                 \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005254_male_Asian_21.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001373_male_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1190>: 100%|██████████| 7/7 [00:00<00:00, 113.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919220>: 100%|██████████| 7/7 [00:00<00:00, 91.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE32B0>: 100%|██████████| 7/7 [00:00<00:00, 90.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD310>: 100%|██████████| 7/7 [00:00<00:00, 98.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1820>:  14%|█▍        | 1/7 [00:00<00:00, 21.98 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003527_male_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000766_female_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD040>: 100%|██████████| 7/7 [00:00<00:00, 91.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535B0>: 100%|██████████| 7/7 [00:00<00:00, 80.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3100>: 100%|██████████| 7/7 [00:00<00:00, 84.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1850>: 100%|██████████| 7/7 [00:00<00:00, 83.32 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001194_male_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006381_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1AC0>: 100%|██████████| 7/7 [00:00<00:00, 105.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1E20>: 100%|██████████| 7/7 [00:00<00:00, 64.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF12E0>: 100%|██████████| 7/7 [00:00<00:00, 66.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A22E0>: 100%|██████████| 7/7 [00:00<00:00, 102.84 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005551_male_Asian_43.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005549_male_Asian_34."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECCA5B50>: 100%|██████████| 7/7 [00:00<00:00, 107.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1670>: 100%|██████████| 7/7 [00:00<00:00, 81.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E20>: 100%|██████████| 7/7 [00:00<00:00, 77.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1310>: 100%|██████████| 7/7 [00:00<00:00, 98.32 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005466_female_Asian_45.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005451_male_Asian_32."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58790>: 100%|██████████| 7/7 [00:00<00:00, 89.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1490>: 100%|██████████| 7/7 [00:00<00:00, 72.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B550>: 100%|██████████| 7/7 [00:00<00:00, 75.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCA0>: 100%|██████████| 7/7 [00:00<00:00, 82.21 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005553_male_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004319_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA90>: 100%|██████████| 7/7 [00:00<00:00, 100.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B550>: 100%|██████████| 7/7 [00:00<00:00, 113.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA90>: 100%|██████████| 7/7 [00:00<00:00, 118.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDF70>: 100%|██████████| 7/7 [00:00<00:00, 111.93 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005223_female_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001815_male_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3610>: 100%|██████████| 7/7 [00:00<00:00, 88.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3670>: 100%|██████████| 7/7 [00:00<00:00, 76.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC8E0>: 100%|██████████| 7/7 [00:00<00:00, 101.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC790>: 100%|██████████| 7/7 [00:00<00:00, 90.76 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001110_male_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006482_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD430>: 100%|██████████| 7/7 [00:00<00:00, 77.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE50>: 100%|██████████| 7/7 [00:00<00:00, 112.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCAC0>: 100%|██████████| 7/7 [00:00<00:00, 83.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD2B0>: 100%|██████████| 7/7 [00:00<00:00, 100.47 Samples/s]                 \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003130_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003488_male_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901640>: 100%|██████████| 7/7 [00:00<00:00, 85.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61880>: 100%|██████████| 7/7 [00:00<00:00, 113.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCDC0>: 100%|██████████| 7/7 [00:00<00:00, 85.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3AF0>: 100%|██████████| 7/7 [00:00<00:00, 76.91 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004203_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003286_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD910>: 100%|██████████| 7/7 [00:00<00:00, 122.44 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3970>: 100%|██████████| 7/7 [00:00<00:00, 99.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9192E0>: 100%|██████████| 7/7 [00:00<00:00, 100.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919310>: 100%|██████████| 7/7 [00:00<00:00, 106.73 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919670>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003482_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003501_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EB0>: 100%|██████████| 7/7 [00:00<00:00, 98.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614F0>: 100%|██████████| 7/7 [00:00<00:00, 114.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31BE0>: 100%|██████████| 7/7 [00:00<00:00, 124.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61DF0>: 100%|██████████| 7/7 [00:00<00:00, 99.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30A0>:  71%|███████▏  | 5/7 [00:00<00:00, 73.62 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001536_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000066_female_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901B80>: 100%|██████████| 7/7 [00:00<00:00, 95.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61280>: 100%|██████████| 7/7 [00:00<00:00, 73.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B700>: 100%|██████████| 7/7 [00:00<00:00, 82.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919340>: 100%|██████████| 7/7 [00:00<00:00, 103.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD00>:  14%|█▍        | 1/7 [00:00<00:00, 25.69 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006428_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001127_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68160>: 100%|██████████| 7/7 [00:00<00:00, 108.92 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE20>: 100%|██████████| 7/7 [00:00<00:00, 90.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919130>: 100%|██████████| 7/7 [00:00<00:00, 98.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD370>: 100%|██████████| 7/7 [00:00<00:00, 63.66 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001021_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003180_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA00>: 100%|██████████| 7/7 [00:00<00:00, 67.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919BE0>: 100%|██████████| 7/7 [00:00<00:00, 90.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDBE0>: 100%|██████████| 7/7 [00:00<00:00, 75.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919CA0>: 100%|██████████| 7/7 [00:00<00:00, 109.17 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006596_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006479_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD280>: 100%|██████████| 7/7 [00:00<00:00, 86.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5B0>: 100%|██████████| 7/7 [00:00<00:00, 136.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD970>: 100%|██████████| 7/7 [00:00<00:00, 99.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D60>: 100%|██████████| 7/7 [00:00<00:00, 115.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3D90>:  57%|█████▋    | 4/7 [00:00<00:00, 93.43 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000376_female_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003347_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B80>: 100%|██████████| 7/7 [00:00<00:00, 100.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D587F0>: 100%|██████████| 7/7 [00:00<00:00, 123.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58760>: 100%|██████████| 7/7 [00:00<00:00, 113.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A00>: 100%|██████████| 7/7 [00:00<00:00, 85.27 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004374_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003038_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F32B0>: 100%|██████████| 7/7 [00:00<00:00, 75.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCBB0>: 100%|██████████| 7/7 [00:00<00:00, 78.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691B20>: 100%|██████████| 7/7 [00:00<00:00, 101.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58730>: 100%|██████████| 7/7 [00:00<00:00, 92.53 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003298_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006240_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3BE0>: 100%|██████████| 7/7 [00:00<00:00, 36.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC130>: 100%|██████████| 7/7 [00:00<00:00, 38.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A30>: 100%|██████████| 7/7 [00:00<00:00, 72.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D588B0>: 100%|██████████| 7/7 [00:00<00:00, 84.27 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001060_female_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006437_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC880>: 100%|██████████| 7/7 [00:00<00:00, 113.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58700>: 100%|██████████| 7/7 [00:00<00:00, 83.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC5E0>: 100%|██████████| 7/7 [00:00<00:00, 89.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1400>: 100%|██████████| 7/7 [00:00<00:00, 104.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58B80>:  29%|██▊       | 2/7 [00:00<00:00, 40.82 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006946_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003390_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3BE0>: 100%|██████████| 7/7 [00:00<00:00, 134.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1070>: 100%|██████████| 7/7 [00:00<00:00, 69.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1F0>: 100%|██████████| 7/7 [00:00<00:00, 102.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E80>: 100%|██████████| 7/7 [00:00<00:00, 84.70 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001492-1_female_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001970_male_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF70>: 100%|██████████| 7/7 [00:00<00:00, 79.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3460>: 100%|██████████| 7/7 [00:00<00:00, 90.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD940>: 100%|██████████| 7/7 [00:00<00:00, 100.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B160>: 100%|██████████| 7/7 [00:00<00:00, 125.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D681C0>: 100%|██████████| 7/7 [00:00<00:00, 104.55 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006728_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001355_female_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B8B0>: 100%|██████████| 7/7 [00:00<00:00, 87.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31CA0>: 100%|██████████| 7/7 [00:00<00:00, 81.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC130>: 100%|██████████| 7/7 [00:00<00:00, 105.87 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FC23A1190>:  29%|██▊       | 2/7 [00:00<00:00, 49.87 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000018_female_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005288_male_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCEE0>: 100%|██████████| 7/7 [00:00<00:00, 109.43 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD340>: 100%|██████████| 7/7 [00:00<00:00, 102.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC970>: 100%|██████████| 7/7 [00:00<00:00, 107.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C615B0>: 100%|██████████| 7/7 [00:00<00:00, 68.06 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001125_female_Asian_27.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005084_female_Asian_28."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901520>: 100%|██████████| 7/7 [00:00<00:00, 114.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3D0>: 100%|██████████| 7/7 [00:00<00:00, 77.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC190>: 100%|██████████| 7/7 [00:00<00:00, 78.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCEB0>: 100%|██████████| 7/7 [00:00<00:00, 127.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE50>:  43%|████▎     | 3/7 [00:00<00:00, 57.90 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001147_male_Asian_35.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003427_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDDF0>: 100%|██████████| 7/7 [00:00<00:00, 100.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5B0>: 100%|██████████| 7/7 [00:00<00:00, 101.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD00>: 100%|██████████| 7/7 [00:00<00:00, 113.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EB0>: 100%|██████████| 7/7 [00:00<00:00, 81.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EE0>:  14%|█▍        | 1/7 [00:00<00:00, 20.66 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001303_female_Asian_21.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001774-1_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919160>: 100%|██████████| 7/7 [00:00<00:00, 103.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612B0>: 100%|██████████| 7/7 [00:00<00:00, 85.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D30>: 100%|██████████| 7/7 [00:00<00:00, 74.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD90>: 100%|██████████| 7/7 [00:00<00:00, 105.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDAC0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003160_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001547_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614F0>: 100%|██████████| 7/7 [00:00<00:00, 115.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD2B0>: 100%|██████████| 7/7 [00:00<00:00, 79.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9012E0>: 100%|██████████| 7/7 [00:00<00:00, 89.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C616A0>: 100%|██████████| 7/7 [00:00<00:00, 115.30 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C10>:  43%|████▎     | 3/7 [00:00<00:00, 63.52 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004427_female_Asian_29.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001031_female_Asian_45."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919E20>: 100%|██████████| 7/7 [00:00<00:00, 100.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D30>: 100%|██████████| 7/7 [00:00<00:00, 99.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61280>: 100%|██████████| 7/7 [00:00<00:00, 75.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD90>: 100%|██████████| 7/7 [00:00<00:00, 107.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901040>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000786_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001008_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDFA0>: 100%|██████████| 7/7 [00:00<00:00, 97.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD310>: 100%|██████████| 7/7 [00:00<00:00, 66.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61610>: 100%|██████████| 7/7 [00:00<00:00, 113.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3220>: 100%|██████████| 7/7 [00:00<00:00, 80.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F32B0>:  43%|████▎     | 3/7 [00:00<00:00, 67.58 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006551_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003889_female_Asian_35."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD910>: 100%|██████████| 7/7 [00:00<00:00, 106.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC7F0>: 100%|██████████| 7/7 [00:00<00:00, 75.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC430>: 100%|██████████| 7/7 [00:00<00:00, 99.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC760>: 100%|██████████| 7/7 [00:00<00:00, 92.19 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003318_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001502_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1BC6A0>: 100%|██████████| 7/7 [00:00<00:00, 81.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C310>: 100%|██████████| 7/7 [00:00<00:00, 90.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F36A0>: 100%|██████████| 7/7 [00:00<00:00, 76.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D30>: 100%|██████████| 7/7 [00:00<00:00, 122.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCCD0>:  14%|█▍        | 1/7 [00:00<00:00, 26.38 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006672_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004164_female_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3460>: 100%|██████████| 7/7 [00:00<00:00, 83.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9D0>: 100%|██████████| 7/7 [00:00<00:00, 99.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD0A0>: 100%|██████████| 7/7 [00:00<00:00, 70.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE20>: 100%|██████████| 7/7 [00:00<00:00, 85.06 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003350_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003459_female_Asian_48."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC670>: 100%|██████████| 7/7 [00:00<00:00, 88.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53250>: 100%|██████████| 7/7 [00:00<00:00, 115.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58790>: 100%|██████████| 7/7 [00:00<00:00, 106.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C340>: 100%|██████████| 7/7 [00:00<00:00, 86.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC190>:  14%|█▍        | 1/7 [00:00<00:00, 26.47 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001763_female_Asian_42.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005510_female_Asian_39."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FA0>: 100%|██████████| 7/7 [00:00<00:00, 94.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3E80>: 100%|██████████| 7/7 [00:00<00:00, 80.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3DF0>: 100%|██████████| 7/7 [00:00<00:00, 113.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A20A0>: 100%|██████████| 7/7 [00:00<00:00, 107.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53940>:  29%|██▊       | 2/7 [00:00<00:00, 34.84 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003054_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001779_female_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>: 100%|██████████| 7/7 [00:00<00:00, 72.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53430>: 100%|██████████| 7/7 [00:00<00:00, 126.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC490>: 100%|██████████| 7/7 [00:00<00:00, 108.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C10>: 100%|██████████| 7/7 [00:00<00:00, 123.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3400>: 100%|██████████| 7/7 [00:00<00:00, 116.12 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001972_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004074_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53CD0>: 100%|██████████| 7/7 [00:00<00:00, 89.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11C0>: 100%|██████████| 7/7 [00:00<00:00, 75.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC880>: 100%|██████████| 7/7 [00:00<00:00, 90.57 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005528_female_Asian_40.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000771_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901520>: 100%|██████████| 7/7 [00:00<00:00, 107.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901E50>: 100%|██████████| 7/7 [00:00<00:00, 108.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1AC0>: 100%|██████████| 7/7 [00:00<00:00, 129.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3EE0>: 100%|██████████| 7/7 [00:00<00:00, 71.12 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000272_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003763_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC196EB0>: 100%|██████████| 7/7 [00:00<00:00, 96.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901940>: 100%|██████████| 7/7 [00:00<00:00, 84.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919790>: 100%|██████████| 7/7 [00:00<00:00, 116.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31F10>: 100%|██████████| 7/7 [00:00<00:00, 102.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA60>:  43%|████▎     | 3/7 [00:00<00:00, 45.40 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006666_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003724_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA60>: 100%|██████████| 7/7 [00:00<00:00, 79.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B670>: 100%|██████████| 7/7 [00:00<00:00, 111.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B820>: 100%|██████████| 7/7 [00:00<00:00, 102.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F36A0>: 100%|██████████| 7/7 [00:00<00:00, 82.86 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004440_female_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006223_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9192B0>: 100%|██████████| 7/7 [00:00<00:00, 35.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD100>: 100%|██████████| 7/7 [00:00<00:00, 45.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919670>: 100%|██████████| 7/7 [00:00<00:00, 76.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDAC0>: 100%|██████████| 7/7 [00:00<00:00, 102.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3A0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003596_female_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001181_male_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE50>: 100%|██████████| 7/7 [00:00<00:00, 101.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919790>: 100%|██████████| 7/7 [00:00<00:00, 95.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDEE0>: 100%|██████████| 7/7 [00:00<00:00, 76.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68070>: 100%|██████████| 7/7 [00:00<00:00, 67.07 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000033_male_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000243_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9196A0>: 100%|██████████| 7/7 [00:00<00:00, 92.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F39A0>: 100%|██████████| 7/7 [00:00<00:00, 103.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A00>: 100%|██████████| 7/7 [00:00<00:00, 75.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA90>: 100%|██████████| 7/7 [00:00<00:00, 82.80 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006451_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000313_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3D60>: 100%|██████████| 7/7 [00:00<00:00, 77.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61430>: 100%|██████████| 7/7 [00:00<00:00, 115.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1520>: 100%|██████████| 7/7 [00:00<00:00, 97.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901040>: 100%|██████████| 7/7 [00:00<00:00, 92.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198E0>:  57%|█████▋    | 4/7 [00:00<00:00, 82.51 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006661_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006335_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECCA5E20>: 100%|██████████| 7/7 [00:00<00:00, 114.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9018E0>: 100%|██████████| 7/7 [00:00<00:00, 86.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD130>: 100%|██████████| 7/7 [00:00<00:00, 63.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61400>: 100%|██████████| 7/7 [00:00<00:00, 109.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDFA0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000357_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004441_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCB80>: 100%|██████████| 7/7 [00:00<00:00, 125.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD040>: 100%|██████████| 7/7 [00:00<00:00, 83.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1FD0>: 100%|██████████| 7/7 [00:00<00:00, 118.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A30>: 100%|██████████| 7/7 [00:00<00:00, 98.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC730>:  57%|█████▋    | 4/7 [00:00<00:00, 66.87 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001331_female_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006443_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3190>: 100%|██████████| 7/7 [00:00<00:00, 102.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD430>: 100%|██████████| 7/7 [00:00<00:00, 70.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38B0>: 100%|██████████| 7/7 [00:00<00:00, 72.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC370>: 100%|██████████| 7/7 [00:00<00:00, 72.89 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006959_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000671_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53910>: 100%|██████████| 7/7 [00:00<00:00, 77.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7190>: 100%|██████████| 7/7 [00:00<00:00, 122.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC940>: 100%|██████████| 7/7 [00:00<00:00, 102.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1CD0>: 100%|██████████| 7/7 [00:00<00:00, 88.27 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005109_female_Asian_45.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005140_female_Asian_32."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>: 100%|██████████| 7/7 [00:00<00:00, 80.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A90>: 100%|██████████| 7/7 [00:00<00:00, 74.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F10>: 100%|██████████| 7/7 [00:00<00:00, 93.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58C40>: 100%|██████████| 7/7 [00:00<00:00, 101.55 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1070>:  14%|█▍        | 1/7 [00:00<00:00, 19.99 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000768_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003891_female_Asian_31."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58970>: 100%|██████████| 7/7 [00:00<00:00, 86.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A00>: 100%|██████████| 7/7 [00:00<00:00, 78.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1BB0>: 100%|██████████| 7/7 [00:00<00:00, 89.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC250>: 100%|██████████| 7/7 [00:00<00:00, 132.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC4C0>:  29%|██▊       | 2/7 [00:00<00:00, 38.77 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006344_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003165_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1880>: 100%|██████████| 7/7 [00:00<00:00, 82.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11C0>: 100%|██████████| 7/7 [00:00<00:00, 85.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3910>: 100%|██████████| 7/7 [00:00<00:00, 119.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A93A0>: 100%|██████████| 7/7 [00:00<00:00, 105.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F40>: 100%|██████████| 7/7 [00:00<00:00, 126.15 Samples/s]                 \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000023_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001490_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3AC0>: 100%|██████████| 7/7 [00:00<00:00, 78.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECCA5CD0>: 100%|██████████| 7/7 [00:00<00:00, 93.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B80>: 100%|██████████| 7/7 [00:00<00:00, 94.21 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001798_male_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001019_male_Asian_29."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D539D0>: 100%|██████████| 7/7 [00:00<00:00, 79.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C340>: 100%|██████████| 7/7 [00:00<00:00, 78.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53430>: 100%|██████████| 7/7 [00:00<00:00, 82.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A90>: 100%|██████████| 7/7 [00:00<00:00, 99.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53700>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003111_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000309_male_Asian_29."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A90>: 100%|██████████| 7/7 [00:00<00:00, 100.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EB0>: 100%|██████████| 7/7 [00:00<00:00, 112.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612E0>: 100%|██████████| 7/7 [00:00<00:00, 109.62 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9195E0>: 100%|██████████| 7/7 [00:00<00:00, 118.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC70>:  43%|████▎     | 3/7 [00:00<00:00, 48.38 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006554_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003361_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31AC0>: 100%|██████████| 7/7 [00:00<00:00, 78.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC760>: 100%|██████████| 7/7 [00:00<00:00, 97.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61280>: 100%|██████████| 7/7 [00:00<00:00, 99.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F40>: 100%|██████████| 7/7 [00:00<00:00, 87.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61790>:  29%|██▊       | 2/7 [00:00<00:00, 48.88 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003409_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003785_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1F0>: 100%|██████████| 7/7 [00:00<00:00, 100.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCDF0>: 100%|██████████| 7/7 [00:00<00:00, 89.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3D0>: 100%|██████████| 7/7 [00:00<00:00, 112.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD520>: 100%|██████████| 7/7 [00:00<00:00, 92.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D30>:  43%|████▎     | 3/7 [00:00<00:00, 60.09 Samples/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000036_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006729_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC8E0>: 100%|██████████| 7/7 [00:00<00:00, 102.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614C0>: 100%|██████████| 7/7 [00:00<00:00, 83.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE20>: 100%|██████████| 7/7 [00:00<00:00, 80.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B160>: 100%|██████████| 7/7 [00:00<00:00, 70.14 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006449_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000518_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919CD0>: 100%|██████████| 7/7 [00:00<00:00, 99.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD700>: 100%|██████████| 7/7 [00:00<00:00, 79.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919310>: 100%|██████████| 7/7 [00:00<00:00, 80.54 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8FD490>: 100%|██████████| 7/7 [00:00<00:00, 82.40 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006618_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006462_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCA0>: 100%|██████████| 7/7 [00:00<00:00, 77.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D00>: 100%|██████████| 7/7 [00:00<00:00, 115.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD910>: 100%|██████████| 7/7 [00:00<00:00, 90.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBC880>: 100%|██████████| 7/7 [00:00<00:00, 98.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53250>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003554_female_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001158_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919340>: 100%|██████████| 7/7 [00:00<00:00, 73.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612E0>: 100%|██████████| 7/7 [00:00<00:00, 74.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C40>: 100%|██████████| 7/7 [00:00<00:00, 67.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612E0>: 100%|██████████| 7/7 [00:00<00:00, 79.89 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001230_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003856_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53280>: 100%|██████████| 7/7 [00:00<00:00, 96.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD250>: 100%|██████████| 7/7 [00:00<00:00, 103.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D60>: 100%|██████████| 7/7 [00:00<00:00, 113.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9D0>: 100%|██████████| 7/7 [00:00<00:00, 115.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A30>: 100%|██████████| 7/7 [00:00<00:00, 95.18 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001649_female_Asian_44.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001633_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3160>: 100%|██████████| 7/7 [00:00<00:00, 70.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61A90>: 100%|██████████| 7/7 [00:00<00:00, 92.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C3D0>: 100%|██████████| 7/7 [00:00<00:00, 73.65 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FC23A1070>:  29%|██▊       | 2/7 [00:00<00:00, 130.54 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003099_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003139_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53400>: 100%|██████████| 7/7 [00:00<00:00, 123.26 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53EB0>: 100%|██████████| 7/7 [00:00<00:00, 76.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A60>: 100%|██████████| 7/7 [00:00<00:00, 98.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58FA0>: 100%|██████████| 7/7 [00:00<00:00, 135.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3100>: 100%|██████████| 7/7 [00:00<00:00, 99.71 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003320_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000041_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC0A0>: 100%|██████████| 7/7 [00:00<00:00, 107.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58DC0>: 100%|██████████| 7/7 [00:00<00:00, 83.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF14C0>: 100%|██████████| 7/7 [00:00<00:00, 85.90 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001538_male_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003512_male_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1C0>: 100%|██████████| 7/7 [00:00<00:00, 99.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C190>: 100%|██████████| 7/7 [00:00<00:00, 79.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7D60>: 100%|██████████| 7/7 [00:00<00:00, 89.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B80>: 100%|██████████| 7/7 [00:00<00:00, 103.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3490>:  43%|████▎     | 3/7 [00:00<00:00, 62.63 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003533_male_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001055_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C10>: 100%|██████████| 7/7 [00:00<00:00, 124.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D30>: 100%|██████████| 7/7 [00:00<00:00, 88.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC640>: 100%|██████████| 7/7 [00:00<00:00, 90.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901040>: 100%|██████████| 7/7 [00:00<00:00, 99.47 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001639_male_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006424_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F40>: 100%|██████████| 7/7 [00:00<00:00, 106.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A00>: 100%|██████████| 7/7 [00:00<00:00, 107.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA30>: 100%|██████████| 7/7 [00:00<00:00, 94.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53250>: 100%|██████████| 7/7 [00:00<00:00, 119.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3490>:  71%|███████▏  | 5/7 [00:00<00:00, 81.80 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001604_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003424-1_female_Asian_44."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>: 100%|██████████| 7/7 [00:00<00:00, 95.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31FD0>: 100%|██████████| 7/7 [00:00<00:00, 97.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B040>: 100%|██████████| 7/7 [00:00<00:00, 89.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC670>: 100%|██████████| 7/7 [00:00<00:00, 97.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EB0>:  57%|█████▋    | 4/7 [00:00<00:00, 90.77 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003095_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001250_male_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536A0>: 100%|██████████| 7/7 [00:00<00:00, 95.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53580>: 100%|██████████| 7/7 [00:00<00:00, 125.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919100>: 100%|██████████| 7/7 [00:00<00:00, 81.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA30>: 100%|██████████| 7/7 [00:00<00:00, 133.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE80>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005406_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006485_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61BB0>: 100%|██████████| 7/7 [00:00<00:00, 84.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F36D0>: 100%|██████████| 7/7 [00:00<00:00, 66.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919CD0>: 100%|██████████| 7/7 [00:00<00:00, 81.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38E0>: 100%|██████████| 7/7 [00:00<00:00, 118.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD070>:  29%|██▊       | 2/7 [00:00<00:00, 41.59 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001312_male_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000588_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30A0>: 100%|██████████| 7/7 [00:00<00:00, 91.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC040>: 100%|██████████| 7/7 [00:00<00:00, 96.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC040>: 100%|██████████| 7/7 [00:00<00:00, 88.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3490>: 100%|██████████| 7/7 [00:00<00:00, 81.62 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006338_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003519_male_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD220>: 100%|██████████| 7/7 [00:00<00:00, 87.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A90>: 100%|██████████| 7/7 [00:00<00:00, 86.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198B0>: 100%|██████████| 7/7 [00:00<00:00, 123.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68340>: 100%|██████████| 7/7 [00:00<00:00, 107.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198E0>:  43%|████▎     | 3/7 [00:00<00:00, 41.07 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000527_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003545_male_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61E50>: 100%|██████████| 7/7 [00:00<00:00, 87.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA30>: 100%|██████████| 7/7 [00:00<00:00, 81.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD400>: 100%|██████████| 7/7 [00:00<00:00, 104.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FD0>: 100%|██████████| 7/7 [00:00<00:00, 105.42 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD7C0>:  57%|█████▋    | 4/7 [00:00<00:00, 64.94 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005017_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003581_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919340>: 100%|██████████| 7/7 [00:00<00:00, 82.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61880>: 100%|██████████| 7/7 [00:00<00:00, 73.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901100>: 100%|██████████| 7/7 [00:00<00:00, 67.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD7C0>: 100%|██████████| 7/7 [00:00<00:00, 131.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61DF0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001899_male_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001601_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612B0>: 100%|██████████| 7/7 [00:00<00:00, 108.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61430>: 100%|██████████| 7/7 [00:00<00:00, 110.76 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7D534F0>: 100%|██████████| 7/7 [00:00<00:00, 84.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECC98E80>: 100%|██████████| 7/7 [00:00<00:00, 109.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>:  43%|████▎     | 3/7 [00:00<00:00, 73.15 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000900_female_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001161_male_Asian_40."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61790>: 100%|██████████| 7/7 [00:00<00:00, 101.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3F10>: 100%|██████████| 7/7 [00:00<00:00, 80.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1F10>: 100%|██████████| 7/7 [00:00<00:00, 90.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1FD0>: 100%|██████████| 7/7 [00:00<00:00, 93.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE50>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003846_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001586_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1670>: 100%|██████████| 7/7 [00:00<00:00, 93.46 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8F3220>: 100%|██████████| 7/7 [00:00<00:00, 97.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3DF0>: 100%|██████████| 7/7 [00:00<00:00, 106.63 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53160>: 100%|██████████| 7/7 [00:00<00:00, 116.26 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD370>:  71%|███████▏  | 5/7 [00:00<00:00, 76.60 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001453_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006562_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3700>: 100%|██████████| 7/7 [00:00<00:00, 97.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C10>: 100%|██████████| 7/7 [00:00<00:00, 94.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30D0>: 100%|██████████| 7/7 [00:00<00:00, 109.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58820>: 100%|██████████| 7/7 [00:00<00:00, 106.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B20>: 100%|██████████| 7/7 [00:00<00:00, 105.90 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006101_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001512_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD00>: 100%|██████████| 7/7 [00:00<00:00, 91.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC520>: 100%|██████████| 7/7 [00:00<00:00, 74.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC640>: 100%|██████████| 7/7 [00:00<00:00, 103.42 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004352_male_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000686_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC520>: 100%|██████████| 7/7 [00:00<00:00, 94.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7940>: 100%|██████████| 7/7 [00:00<00:00, 103.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A00>: 100%|██████████| 7/7 [00:00<00:00, 89.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533A0>: 100%|██████████| 7/7 [00:00<00:00, 85.38 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC490>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000562_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006336_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1520>: 100%|██████████| 7/7 [00:00<00:00, 98.52 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38B0>: 100%|██████████| 7/7 [00:00<00:00, 95.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58700>: 100%|██████████| 7/7 [00:00<00:00, 76.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC160>: 100%|██████████| 7/7 [00:00<00:00, 71.16 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001276_female_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003035_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F36A0>: 100%|██████████| 7/7 [00:00<00:00, 97.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A17C0>: 100%|██████████| 7/7 [00:00<00:00, 100.04 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D60>: 100%|██████████| 7/7 [00:00<00:00, 81.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612B0>: 100%|██████████| 7/7 [00:00<00:00, 89.30 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001749_female_Asian_39.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001650_female_Asian_49."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9016D0>: 100%|██████████| 7/7 [00:00<00:00, 75.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>: 100%|██████████| 7/7 [00:00<00:00, 70.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3F10>: 100%|██████████| 7/7 [00:00<00:00, 93.90 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C616D0>: 100%|██████████| 7/7 [00:00<00:00, 95.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53580>:  29%|██▊       | 2/7 [00:00<00:00, 43.90 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005559_male_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004446_male_Asian_40."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536A0>: 100%|██████████| 7/7 [00:00<00:00, 63.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61910>: 100%|██████████| 7/7 [00:00<00:00, 83.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCB50>: 100%|██████████| 7/7 [00:00<00:00, 112.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC310>: 100%|██████████| 7/7 [00:00<00:00, 99.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919CA0>:  57%|█████▋    | 4/7 [00:00<00:00, 67.04 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000024_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003439_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D00>: 100%|██████████| 7/7 [00:00<00:00, 95.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9199D0>: 100%|██████████| 7/7 [00:00<00:00, 98.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919970>: 100%|██████████| 7/7 [00:00<00:00, 144.04 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61280>: 100%|██████████| 7/7 [00:00<00:00, 102.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6040>:  43%|████▎     | 3/7 [00:00<00:00, 48.79 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001492_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001473_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68FD0>: 100%|██████████| 7/7 [00:00<00:00, 72.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D60>: 100%|██████████| 7/7 [00:00<00:00, 90.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53040>: 100%|██████████| 7/7 [00:00<00:00, 107.97 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61820>: 100%|██████████| 7/7 [00:00<00:00, 120.64 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDFA0>:  14%|█▍        | 1/7 [00:00<00:00, 16.82 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005260_male_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000020_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C613D0>: 100%|██████████| 7/7 [00:00<00:00, 56.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FA0>: 100%|██████████| 7/7 [00:00<00:00, 76.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1F0>: 100%|██████████| 7/7 [00:00<00:00, 104.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE80>: 100%|██████████| 7/7 [00:00<00:00, 75.80 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006924_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003534_male_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68CA0>: 100%|██████████| 7/7 [00:00<00:00, 118.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198B0>: 100%|██████████| 7/7 [00:00<00:00, 87.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B6A0>: 100%|██████████| 7/7 [00:00<00:00, 106.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919070>: 100%|██████████| 7/7 [00:00<00:00, 80.39 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003841_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005059_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1AF0>: 100%|██████████| 7/7 [00:00<00:00, 100.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C340>: 100%|██████████| 7/7 [00:00<00:00, 92.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901190>: 100%|██████████| 7/7 [00:00<00:00, 88.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD6D0>: 100%|██████████| 7/7 [00:00<00:00, 100.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA30>:  43%|████▎     | 3/7 [00:00<00:00, 65.75 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000520_female_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005227_male_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B160>: 100%|██████████| 7/7 [00:00<00:00, 86.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C615E0>: 100%|██████████| 7/7 [00:00<00:00, 87.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A60>: 100%|██████████| 7/7 [00:00<00:00, 121.74 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61DC0>: 100%|██████████| 7/7 [00:00<00:00, 89.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F36A0>:  57%|█████▋    | 4/7 [00:00<00:00, 68.83 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004178_male_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000765_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1490>: 100%|██████████| 7/7 [00:00<00:00, 108.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5B0>: 100%|██████████| 7/7 [00:00<00:00, 75.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61670>: 100%|██████████| 7/7 [00:00<00:00, 77.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDF70>: 100%|██████████| 7/7 [00:00<00:00, 91.08 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004362_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003270_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C10>: 100%|██████████| 7/7 [00:00<00:00, 100.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3AC0>: 100%|██████████| 7/7 [00:00<00:00, 99.37 Samples/s] \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDDF0>: 100%|██████████| 7/7 [00:00<00:00, 71.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D588E0>: 100%|██████████| 7/7 [00:00<00:00, 96.54 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000687_male_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006097_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A60>: 100%|██████████| 7/7 [00:00<00:00, 76.50 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5B0>: 100%|██████████| 7/7 [00:00<00:00, 87.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABD83A0>: 100%|██████████| 7/7 [00:00<00:00, 41.33 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006138_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABD85E0>: 100%|██████████| 7/7 [00:00<00:00, 41.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53EB0>: 100%|██████████| 7/7 [00:00<00:00, 90.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCD0>: 100%|██████████| 7/7 [00:00<00:00, 90.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE69A0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004254_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003726_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B20>: 100%|██████████| 7/7 [00:00<00:00, 118.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30D0>: 100%|██████████| 7/7 [00:00<00:00, 98.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F33A0>: 100%|██████████| 7/7 [00:00<00:00, 79.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53AC0>: 100%|██████████| 7/7 [00:00<00:00, 78.00 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003893_female_Asian_46.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001299_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCAC0>: 100%|██████████| 7/7 [00:00<00:00, 93.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7190>: 100%|██████████| 7/7 [00:00<00:00, 88.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E80>: 100%|██████████| 7/7 [00:00<00:00, 89.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BE20>: 100%|██████████| 7/7 [00:00<00:00, 103.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53700>:  29%|██▊       | 2/7 [00:00<00:00, 47.94 Samples/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003128_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000079_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D90>: 100%|██████████| 7/7 [00:00<00:00, 118.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BAC0>: 100%|██████████| 7/7 [00:00<00:00, 81.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C619A0>: 100%|██████████| 7/7 [00:00<00:00, 87.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C190>: 100%|██████████| 7/7 [00:00<00:00, 87.34 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001781_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005154_male_Asian_35."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CA0>: 100%|██████████| 7/7 [00:00<00:00, 91.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F70>: 100%|██████████| 7/7 [00:00<00:00, 75.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D586A0>: 100%|██████████| 7/7 [00:00<00:00, 122.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E80>: 100%|██████████| 7/7 [00:00<00:00, 91.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536A0>:  71%|███████▏  | 5/7 [00:00<00:00, 86.17 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006091_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003567_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58B80>: 100%|██████████| 7/7 [00:00<00:00, 92.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53340>: 100%|██████████| 7/7 [00:00<00:00, 85.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1670>: 100%|██████████| 7/7 [00:00<00:00, 76.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC2E0>:  43%|████▎     | 3/7 [00:00<00:00, 38.79 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000546_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11F0>: 100%|██████████| 7/7 [00:00<00:00, 60.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDBE0>: 100%|██████████| 7/7 [00:00<00:00, 41.18 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006147_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1C0>: 100%|██████████| 7/7 [00:00<00:00, 43.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53BB0>: 100%|██████████| 7/7 [00:00<00:00, 122.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDB50>: 100%|██████████| 7/7 [00:00<00:00, 94.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA00>: 100%|██████████| 7/7 [00:00<00:00, 118.80 Samples/s]                 \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001793_female_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001368_female_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9D0>: 100%|██████████| 7/7 [00:00<00:00, 81.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD30>: 100%|██████████| 7/7 [00:00<00:00, 99.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53FD0>: 100%|██████████| 7/7 [00:00<00:00, 92.83 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001836_female_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004262_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31E20>: 100%|██████████| 7/7 [00:00<00:00, 93.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD430>: 100%|██████████| 7/7 [00:00<00:00, 109.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>: 100%|██████████| 7/7 [00:00<00:00, 89.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901400>: 100%|██████████| 7/7 [00:00<00:00, 98.67 Samples/s]          \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919460>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001647-1_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005056_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F37C0>: 100%|██████████| 7/7 [00:00<00:00, 93.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901CA0>: 100%|██████████| 7/7 [00:00<00:00, 109.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3430>: 100%|██████████| 7/7 [00:00<00:00, 82.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31E80>: 100%|██████████| 7/7 [00:00<00:00, 109.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3AC0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000647_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000515_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901400>: 100%|██████████| 7/7 [00:00<00:00, 88.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1DC0>: 100%|██████████| 7/7 [00:00<00:00, 92.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F39A0>: 100%|██████████| 7/7 [00:00<00:00, 103.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC130>: 100%|██████████| 7/7 [00:00<00:00, 76.53 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004355_female_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003655_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3AC0>: 100%|██████████| 7/7 [00:00<00:00, 96.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3670>: 100%|██████████| 7/7 [00:00<00:00, 90.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCD0>: 100%|██████████| 7/7 [00:00<00:00, 113.30 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDBE0>: 100%|██████████| 7/7 [00:00<00:00, 92.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3A0>:  14%|█▍        | 1/7 [00:00<00:00, 26.62 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000264_female_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004423_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1BB0>: 100%|██████████| 7/7 [00:00<00:00, 95.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1CD0>: 100%|██████████| 7/7 [00:00<00:00, 95.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D30>: 100%|██████████| 7/7 [00:00<00:00, 103.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA00>: 100%|██████████| 7/7 [00:00<00:00, 88.62 Samples/s]                  \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003020_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001061_male_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1520>: 100%|██████████| 7/7 [00:00<00:00, 92.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7F70>: 100%|██████████| 7/7 [00:00<00:00, 109.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D586A0>: 100%|██████████| 7/7 [00:00<00:00, 112.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B100>: 100%|██████████| 7/7 [00:00<00:00, 96.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6D0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000690_female_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001146_male_Asian_45."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD6D0>: 100%|██████████| 7/7 [00:00<00:00, 86.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58FA0>: 100%|██████████| 7/7 [00:00<00:00, 97.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD640>: 100%|██████████| 7/7 [00:00<00:00, 87.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCAF0>: 100%|██████████| 7/7 [00:00<00:00, 122.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53910>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006405_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000732_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCD0>: 100%|██████████| 7/7 [00:00<00:00, 103.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC5E0>: 100%|██████████| 7/7 [00:00<00:00, 65.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC550>: 100%|██████████| 7/7 [00:00<00:00, 96.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD610>: 100%|██████████| 7/7 [00:00<00:00, 102.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE20>:  14%|█▍        | 1/7 [00:00<00:00, 21.01 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001610_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001022_male_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D589A0>: 100%|██████████| 7/7 [00:00<00:00, 110.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53310>: 100%|██████████| 7/7 [00:00<00:00, 88.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58A30>: 100%|██████████| 7/7 [00:00<00:00, 99.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D539A0>: 100%|██████████| 7/7 [00:00<00:00, 130.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF1EE0>: 100%|██████████| 7/7 [00:00<00:00, 99.82 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006220_male_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003191_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7940>: 100%|██████████| 7/7 [00:00<00:00, 64.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CA0>: 100%|██████████| 7/7 [00:00<00:00, 89.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B160>: 100%|██████████| 7/7 [00:00<00:00, 99.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D586A0>:  14%|█▍        | 1/7 [00:00<00:00, 21.57 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001358_female_Asian_29.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001137_male_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61670>: 100%|██████████| 7/7 [00:00<00:00, 94.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D00>: 100%|██████████| 7/7 [00:00<00:00, 89.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58AF0>: 100%|██████████| 7/7 [00:00<00:00, 66.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C70>:  43%|████▎     | 3/7 [00:00<00:00, 33.03 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000244_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC700>: 100%|██████████| 7/7 [00:00<00:00, 69.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58790>: 100%|██████████| 7/7 [00:00<00:00, 102.53 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61280>: 100%|██████████| 7/7 [00:00<00:00, 67.41 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001088_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001033_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C10>: 100%|██████████| 7/7 [00:00<00:00, 75.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53580>: 100%|██████████| 7/7 [00:00<00:00, 96.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537F0>: 100%|██████████| 7/7 [00:00<00:00, 87.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53EB0>: 100%|██████████| 7/7 [00:00<00:00, 86.48 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005441_male_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003652_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53CD0>: 100%|██████████| 7/7 [00:00<00:00, 109.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D30>: 100%|██████████| 7/7 [00:00<00:00, 91.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68FA0>: 100%|██████████| 7/7 [00:00<00:00, 82.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC5E0>: 100%|██████████| 7/7 [00:00<00:00, 91.39 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003817_male_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003778_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38B0>: 100%|██████████| 7/7 [00:00<00:00, 96.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCB20>: 100%|██████████| 7/7 [00:00<00:00, 112.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF70>: 100%|██████████| 7/7 [00:00<00:00, 98.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3550>: 100%|██████████| 7/7 [00:00<00:00, 121.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE80>:  43%|████▎     | 3/7 [00:00<00:00, 69.90 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001330_female_Asian_28.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003355_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1130>: 100%|██████████| 7/7 [00:00<00:00, 94.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3610>: 100%|██████████| 7/7 [00:00<00:00, 78.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA90>: 100%|██████████| 7/7 [00:00<00:00, 79.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD00>: 100%|██████████| 7/7 [00:00<00:00, 102.87 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000782_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005557_male_Asian_46."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8FD160>: 100%|██████████| 7/7 [00:00<00:00, 105.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919100>: 100%|██████████| 7/7 [00:00<00:00, 84.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE20>: 100%|██████████| 7/7 [00:00<00:00, 91.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA30>: 100%|██████████| 7/7 [00:00<00:00, 89.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC070>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005261_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000760_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCBE0>: 100%|██████████| 7/7 [00:00<00:00, 108.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9192B0>: 100%|██████████| 7/7 [00:00<00:00, 82.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD130>: 100%|██████████| 7/7 [00:00<00:00, 84.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31CA0>: 100%|██████████| 7/7 [00:00<00:00, 136.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD700>:  29%|██▊       | 2/7 [00:00<00:00, 42.08 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003555_female_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003642_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198E0>: 100%|██████████| 7/7 [00:00<00:00, 88.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3550>: 100%|██████████| 7/7 [00:00<00:00, 104.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919760>: 100%|██████████| 7/7 [00:00<00:00, 85.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA00>: 100%|██████████| 7/7 [00:00<00:00, 91.47 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004082_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005483_female_Asian_45."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDBB0>: 100%|██████████| 7/7 [00:00<00:00, 111.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3E80>: 100%|██████████| 7/7 [00:00<00:00, 120.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A13D0>: 100%|██████████| 7/7 [00:00<00:00, 85.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30A0>: 100%|██████████| 7/7 [00:00<00:00, 76.61 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004467_female_Asian_49.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003033_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD160>: 100%|██████████| 7/7 [00:00<00:00, 81.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCB20>: 100%|██████████| 7/7 [00:00<00:00, 107.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC910>: 100%|██████████| 7/7 [00:00<00:00, 85.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC340>: 100%|██████████| 7/7 [00:00<00:00, 77.66 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006646_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006468_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3910>: 100%|██████████| 7/7 [00:00<00:00, 99.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA90>: 100%|██████████| 7/7 [00:00<00:00, 94.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD700>: 100%|██████████| 7/7 [00:00<00:00, 102.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA30>: 100%|██████████| 7/7 [00:00<00:00, 113.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D90>: 100%|██████████| 7/7 [00:00<00:00, 110.51 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001722_male_Asian_30.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003548_male_Asian_41."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BAC0>: 100%|██████████| 7/7 [00:00<00:00, 82.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D90>: 100%|██████████| 7/7 [00:00<00:00, 76.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C40>: 100%|██████████| 7/7 [00:00<00:00, 99.43 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003753_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005244_male_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38B0>: 100%|██████████| 7/7 [00:00<00:00, 78.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F10>: 100%|██████████| 7/7 [00:00<00:00, 87.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF12E0>: 100%|██████████| 7/7 [00:00<00:00, 109.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC850>: 100%|██████████| 7/7 [00:00<00:00, 105.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58EE0>:  29%|██▊       | 2/7 [00:00<00:00, 36.08 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003078_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003058_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD520>: 100%|██████████| 7/7 [00:00<00:00, 84.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B6A0>: 100%|██████████| 7/7 [00:00<00:00, 55.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE80>: 100%|██████████| 7/7 [00:00<00:00, 75.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F70>: 100%|██████████| 7/7 [00:00<00:00, 97.05 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003806_male_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001123_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B1C0>: 100%|██████████| 7/7 [00:00<00:00, 108.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C3D0>: 100%|██████████| 7/7 [00:00<00:00, 135.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC340>: 100%|██████████| 7/7 [00:00<00:00, 115.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58A00>: 100%|██████████| 7/7 [00:00<00:00, 97.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D587C0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003137_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003790_male_Asian_46."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B8B0>: 100%|██████████| 7/7 [00:00<00:00, 80.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CD0>: 100%|██████████| 7/7 [00:00<00:00, 79.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61DC0>: 100%|██████████| 7/7 [00:00<00:00, 80.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61550>: 100%|██████████| 7/7 [00:00<00:00, 81.90 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003057_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003161_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC340>: 100%|██████████| 7/7 [00:00<00:00, 85.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCBB0>: 100%|██████████| 7/7 [00:00<00:00, 102.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC3D0>: 100%|██████████| 7/7 [00:00<00:00, 87.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC880>: 100%|██████████| 7/7 [00:00<00:00, 87.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53220>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003566_male_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005414_female_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EE0>: 100%|██████████| 7/7 [00:00<00:00, 104.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA00>: 100%|██████████| 7/7 [00:00<00:00, 82.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1070>: 100%|██████████| 7/7 [00:00<00:00, 99.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1580>: 100%|██████████| 7/7 [00:00<00:00, 106.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF70>:  14%|█▍        | 1/7 [00:00<00:00, 21.06 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000207_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004220_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53130>: 100%|██████████| 7/7 [00:00<00:00, 79.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD070>: 100%|██████████| 7/7 [00:00<00:00, 89.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61910>: 100%|██████████| 7/7 [00:00<00:00, 88.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC190>: 100%|██████████| 7/7 [00:00<00:00, 83.20 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001039_female_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004216_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3AC0>: 100%|██████████| 7/7 [00:00<00:00, 125.50 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD7C0>: 100%|██████████| 7/7 [00:00<00:00, 115.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC070>: 100%|██████████| 7/7 [00:00<00:00, 105.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901B80>: 100%|██████████| 7/7 [00:00<00:00, 104.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD7C0>:  57%|█████▋    | 4/7 [00:00<00:00, 65.81 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000312_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000282_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD040>: 100%|██████████| 7/7 [00:00<00:00, 89.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1F0>: 100%|██████████| 7/7 [00:00<00:00, 110.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD430>: 100%|██████████| 7/7 [00:00<00:00, 98.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD7F0>: 100%|██████████| 7/7 [00:00<00:00, 96.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>: 100%|██████████| 7/7 [00:00<00:00, 142.68 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001068_female_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001595_male_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE20>: 100%|██████████| 7/7 [00:00<00:00, 84.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68D00>: 100%|██████████| 7/7 [00:00<00:00, 90.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3100>: 100%|██████████| 7/7 [00:00<00:00, 83.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38E0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004454_male_Asian_32.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004311_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919340>: 100%|██████████| 7/7 [00:00<00:00, 86.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3BB0>: 100%|██████████| 7/7 [00:00<00:00, 88.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A00>: 100%|██████████| 7/7 [00:00<00:00, 87.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA00>: 100%|██████████| 7/7 [00:00<00:00, 88.64 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004448_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001041_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F34F0>: 100%|██████████| 7/7 [00:00<00:00, 84.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919820>: 100%|██████████| 7/7 [00:00<00:00, 129.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901280>: 100%|██████████| 7/7 [00:00<00:00, 97.82 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919CD0>: 100%|██████████| 7/7 [00:00<00:00, 84.49 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001155_male_Asian_28.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003601_male_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9190A0>: 100%|██████████| 7/7 [00:00<00:00, 93.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C70>: 100%|██████████| 7/7 [00:00<00:00, 103.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919790>: 100%|██████████| 7/7 [00:00<00:00, 125.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1AF0>: 100%|██████████| 7/7 [00:00<00:00, 106.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537F0>: 100%|██████████| 7/7 [00:00<00:00, 101.60 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003131_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005521_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC700>: 100%|██████████| 7/7 [00:00<00:00, 95.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537C0>: 100%|██████████| 7/7 [00:00<00:00, 80.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A2340>: 100%|██████████| 7/7 [00:00<00:00, 101.54 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001721_female_Asian_35.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003220_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC7F0>: 100%|██████████| 7/7 [00:00<00:00, 89.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECC98E80>: 100%|██████████| 7/7 [00:00<00:00, 68.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9190D0>: 100%|██████████| 7/7 [00:00<00:00, 77.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61850>: 100%|██████████| 7/7 [00:00<00:00, 100.99 Samples/s]                 \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001182-1_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000301_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612B0>: 100%|██████████| 7/7 [00:00<00:00, 68.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE80>: 100%|██████████| 7/7 [00:00<00:00, 95.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D00>: 100%|██████████| 7/7 [00:00<00:00, 82.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDAC0>: 100%|██████████| 7/7 [00:00<00:00, 89.05 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005031_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000741_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7E66820>: 100%|██████████| 7/7 [00:00<00:00, 90.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B50>: 100%|██████████| 7/7 [00:00<00:00, 85.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABD8700>: 100%|██████████| 7/7 [00:00<00:00, 113.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C3D0>: 100%|██████████| 7/7 [00:00<00:00, 85.65 Samples/s]                  \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001132-1_male_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003565_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691AF0>: 100%|██████████| 7/7 [00:00<00:00, 97.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C310>: 100%|██████████| 7/7 [00:00<00:00, 79.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F10>: 100%|██████████| 7/7 [00:00<00:00, 72.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C616A0>: 100%|██████████| 7/7 [00:00<00:00, 90.05 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000356_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005082_male_Asian_48."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58A30>: 100%|██████████| 7/7 [00:00<00:00, 111.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CD0>: 100%|██████████| 7/7 [00:00<00:00, 105.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA00>: 100%|██████████| 7/7 [00:00<00:00, 112.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61790>: 100%|██████████| 7/7 [00:00<00:00, 100.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9190A0>:  71%|███████▏  | 5/7 [00:00<00:00, 94.53 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000802_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006626_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D90>: 100%|██████████| 7/7 [00:00<00:00, 103.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61430>: 100%|██████████| 7/7 [00:00<00:00, 88.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53580>: 100%|██████████| 7/7 [00:00<00:00, 101.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC760>: 100%|██████████| 7/7 [00:00<00:00, 107.91 Samples/s]         \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1BB0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001736_female_Asian_36.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000499_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919E50>: 100%|██████████| 7/7 [00:00<00:00, 80.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F70>: 100%|██████████| 7/7 [00:00<00:00, 107.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A00>: 100%|██████████| 7/7 [00:00<00:00, 81.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC4C0>: 100%|██████████| 7/7 [00:00<00:00, 104.82 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000735_female_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006248_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537F0>: 100%|██████████| 7/7 [00:00<00:00, 37.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919970>: 100%|██████████| 7/7 [00:00<00:00, 39.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA00>: 100%|██████████| 7/7 [00:00<00:00, 96.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9195E0>: 100%|██████████| 7/7 [00:00<00:00, 114.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF10>:  43%|████▎     | 3/7 [00:00<00:00, 58.72 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003195_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006721_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919460>: 100%|██████████| 7/7 [00:00<00:00, 84.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A30>: 100%|██████████| 7/7 [00:00<00:00, 67.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6A0>: 100%|██████████| 7/7 [00:00<00:00, 98.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDC40>: 100%|██████████| 7/7 [00:00<00:00, 82.41 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003148_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003231_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC700>: 100%|██████████| 7/7 [00:00<00:00, 76.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC0A0>: 100%|██████████| 7/7 [00:00<00:00, 118.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD040>: 100%|██████████| 7/7 [00:00<00:00, 84.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC880>: 100%|██████████| 7/7 [00:00<00:00, 126.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3160>:  29%|██▊       | 2/7 [00:00<00:00, 48.54 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001263_male_Asian_33.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001097_female_Asian_39."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC190>: 100%|██████████| 7/7 [00:00<00:00, 74.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE80>: 100%|██████████| 7/7 [00:00<00:00, 87.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC400>: 100%|██████████| 7/7 [00:00<00:00, 99.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F36D0>: 100%|██████████| 7/7 [00:00<00:00, 98.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABD8640>:  71%|███████▏  | 5/7 [00:00<00:00, 94.81 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001432_male_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001297_female_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC430>: 100%|██████████| 7/7 [00:00<00:00, 95.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68EE0>: 100%|██████████| 7/7 [00:00<00:00, 102.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A00>: 100%|██████████| 7/7 [00:00<00:00, 104.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1880>: 100%|██████████| 7/7 [00:00<00:00, 108.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD250>:  57%|█████▋    | 4/7 [00:00<00:00, 68.83 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003844_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003302_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3DF0>: 100%|██████████| 7/7 [00:00<00:00, 99.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A60>: 100%|██████████| 7/7 [00:00<00:00, 103.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30A0>: 100%|██████████| 7/7 [00:00<00:00, 102.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CA0>: 100%|██████████| 7/7 [00:00<00:00, 85.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EB0>:  14%|█▍        | 1/7 [00:00<00:00, 24.48 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003383_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004382_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F37C0>: 100%|██████████| 7/7 [00:00<00:00, 90.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE50>: 100%|██████████| 7/7 [00:00<00:00, 98.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9192E0>: 100%|██████████| 7/7 [00:00<00:00, 128.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3E80>: 100%|██████████| 7/7 [00:00<00:00, 119.82 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F70>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005287_male_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005027_female_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F35B0>: 100%|██████████| 7/7 [00:00<00:00, 69.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9199D0>: 100%|██████████| 7/7 [00:00<00:00, 64.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC220>: 100%|██████████| 7/7 [00:00<00:00, 85.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F40>: 100%|██████████| 7/7 [00:00<00:00, 66.33 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001614_female_Asian_44.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003158_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3BB0>: 100%|██████████| 7/7 [00:00<00:00, 79.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53730>: 100%|██████████| 7/7 [00:00<00:00, 146.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53CA0>: 100%|██████████| 7/7 [00:00<00:00, 98.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC610>: 100%|██████████| 7/7 [00:00<00:00, 84.80 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61490>:  14%|█▍        | 1/7 [00:00<00:00, 26.63 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003879_female_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006545_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C616D0>: 100%|██████████| 7/7 [00:00<00:00, 111.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC5B0>: 100%|██████████| 7/7 [00:00<00:00, 101.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FA0>: 100%|██████████| 7/7 [00:00<00:00, 77.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612E0>: 100%|██████████| 7/7 [00:00<00:00, 93.74 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001506_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006448_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3430>: 100%|██████████| 7/7 [00:00<00:00, 86.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61A90>: 100%|██████████| 7/7 [00:00<00:00, 82.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D00>: 100%|██████████| 7/7 [00:00<00:00, 92.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CD0>: 100%|██████████| 7/7 [00:00<00:00, 105.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D90>:  57%|█████▋    | 4/7 [00:00<00:00, 82.18 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006386_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005282_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919970>: 100%|██████████| 7/7 [00:00<00:00, 122.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53910>: 100%|██████████| 7/7 [00:00<00:00, 72.49 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC99B820>: 100%|██████████| 7/7 [00:00<00:00, 90.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B100>: 100%|██████████| 7/7 [00:00<00:00, 76.27 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006441_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001037_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53E50>: 100%|██████████| 7/7 [00:00<00:00, 75.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C613D0>: 100%|██████████| 7/7 [00:00<00:00, 107.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61940>: 100%|██████████| 7/7 [00:00<00:00, 95.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919A30>: 100%|██████████| 7/7 [00:00<00:00, 104.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D30>:  29%|██▊       | 2/7 [00:00<00:00, 42.81 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001498-1_female_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001588_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61880>: 100%|██████████| 7/7 [00:00<00:00, 87.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61820>: 100%|██████████| 7/7 [00:00<00:00, 99.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61AF0>: 100%|██████████| 7/7 [00:00<00:00, 100.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC6919D0>: 100%|██████████| 7/7 [00:00<00:00, 112.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614F0>: 100%|██████████| 7/7 [00:00<00:00, 120.81 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003849_male_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005234_male_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61BB0>: 100%|██████████| 7/7 [00:00<00:00, 95.69 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1F0>: 100%|██████████| 7/7 [00:00<00:00, 95.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9018E0>: 100%|██████████| 7/7 [00:00<00:00, 88.11 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003794_female_Asian_44.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006732_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3880>: 100%|██████████| 7/7 [00:00<00:00, 98.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61E50>: 100%|██████████| 7/7 [00:00<00:00, 99.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F40>: 100%|██████████| 7/7 [00:00<00:00, 98.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3670>: 100%|██████████| 7/7 [00:00<00:00, 90.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC190>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000245_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001511_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C10>: 100%|██████████| 7/7 [00:00<00:00, 99.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9199D0>: 100%|██████████| 7/7 [00:00<00:00, 85.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1AC0>: 100%|██████████| 7/7 [00:00<00:00, 82.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCAF0>: 100%|██████████| 7/7 [00:00<00:00, 124.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE50>:  57%|█████▋    | 4/7 [00:00<00:00, 84.85 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005229_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006636_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD940>: 100%|██████████| 7/7 [00:00<00:00, 119.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC5B0>: 100%|██████████| 7/7 [00:00<00:00, 79.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC760>: 100%|██████████| 7/7 [00:00<00:00, 111.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC640>: 100%|██████████| 7/7 [00:00<00:00, 90.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE20>:  14%|█▍        | 1/7 [00:00<00:00, 22.25 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003840_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003576_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC130>: 100%|██████████| 7/7 [00:00<00:00, 89.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919700>: 100%|██████████| 7/7 [00:00<00:00, 92.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919220>: 100%|██████████| 7/7 [00:00<00:00, 82.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD30>: 100%|██████████| 7/7 [00:00<00:00, 86.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDAC0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000077_male_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006578_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68070>: 100%|██████████| 7/7 [00:00<00:00, 114.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB14250>: 100%|██████████| 7/7 [00:00<00:00, 126.15 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3E20>: 100%|██████████| 7/7 [00:00<00:00, 106.49 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FFC1A93A0>: 100%|██████████| 7/7 [00:00<00:00, 87.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE20>:  14%|█▍        | 1/7 [00:00<00:00, 25.75 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006347_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000688_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC5B0>: 100%|██████████| 7/7 [00:00<00:00, 118.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F36D0>: 100%|██████████| 7/7 [00:00<00:00, 104.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A14F0>: 100%|██████████| 7/7 [00:00<00:00, 84.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C40>: 100%|██████████| 7/7 [00:00<00:00, 100.59 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001420_male_Asian_49.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003153_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1670>: 100%|██████████| 7/7 [00:00<00:00, 96.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919910>: 100%|██████████| 7/7 [00:00<00:00, 95.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD00>: 100%|██████████| 7/7 [00:00<00:00, 64.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30A0>:  57%|█████▋    | 4/7 [00:00<00:00, 54.22 Samples/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003885_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D90>: 100%|██████████| 7/7 [00:00<00:00, 72.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3100>: 100%|██████████| 7/7 [00:00<00:00, 102.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D539D0>: 100%|██████████| 7/7 [00:00<00:00, 73.48 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003672_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005040_male_Asian_30."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3160>: 100%|██████████| 7/7 [00:00<00:00, 79.75 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F40>: 100%|██████████| 7/7 [00:00<00:00, 83.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53E50>: 100%|██████████| 7/7 [00:00<00:00, 95.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3AC0>: 100%|██████████| 7/7 [00:00<00:00, 104.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919220>:  14%|█▍        | 1/7 [00:00<00:00, 21.10 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001582_female_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005475_female_Asian_44."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D60>: 100%|██████████| 7/7 [00:00<00:00, 79.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3490>: 100%|██████████| 7/7 [00:00<00:00, 91.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A90>: 100%|██████████| 7/7 [00:00<00:00, 106.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE80>: 100%|██████████| 7/7 [00:00<00:00, 100.83 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004329_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006219_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCCD0>: 100%|██████████| 7/7 [00:00<00:00, 36.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D90>: 100%|██████████| 7/7 [00:00<00:00, 39.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537C0>: 100%|██████████| 7/7 [00:00<00:00, 89.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC490>: 100%|██████████| 7/7 [00:00<00:00, 99.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6A0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001026_male_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003766_male_Asian_38."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C613A0>: 100%|██████████| 7/7 [00:00<00:00, 83.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D90>: 100%|██████████| 7/7 [00:00<00:00, 79.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58AF0>: 100%|██████████| 7/7 [00:00<00:00, 79.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D589D0>: 100%|██████████| 7/7 [00:00<00:00, 100.76 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC040>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000589_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006418_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9193D0>: 100%|██████████| 7/7 [00:00<00:00, 86.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D00>: 100%|██████████| 7/7 [00:00<00:00, 117.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61580>: 100%|██████████| 7/7 [00:00<00:00, 132.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D586A0>: 100%|██████████| 7/7 [00:00<00:00, 109.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C618E0>:  57%|█████▋    | 4/7 [00:00<00:00, 55.77 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003392_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000238_male_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D00>: 100%|██████████| 7/7 [00:00<00:00, 77.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B8B0>: 100%|██████████| 7/7 [00:00<00:00, 91.02 Samples/s] \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F40>: 100%|██████████| 7/7 [00:00<00:00, 123.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B80>: 100%|██████████| 7/7 [00:00<00:00, 96.44 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3610>:  43%|████▎     | 3/7 [00:00<00:00, 49.16 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006691_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005137_male_Asian_29."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3F10>: 100%|██████████| 7/7 [00:00<00:00, 87.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC760>: 100%|██████████| 7/7 [00:00<00:00, 131.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53EB0>: 100%|██████████| 7/7 [00:00<00:00, 85.36 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7D537F0>: 100%|██████████| 7/7 [00:00<00:00, 98.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F10>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006614_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001159_male_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CD0>: 100%|██████████| 7/7 [00:00<00:00, 95.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61DC0>: 100%|██████████| 7/7 [00:00<00:00, 98.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C615E0>: 100%|██████████| 7/7 [00:00<00:00, 98.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612E0>: 100%|██████████| 7/7 [00:00<00:00, 107.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919100>:  29%|██▊       | 2/7 [00:00<00:00, 33.91 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003560_male_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001183-1_male_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCFA0>: 100%|██████████| 7/7 [00:00<00:00, 90.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7D60>: 100%|██████████| 7/7 [00:00<00:00, 109.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1490>: 100%|██████████| 7/7 [00:00<00:00, 118.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919E50>: 100%|██████████| 7/7 [00:00<00:00, 102.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A13D0>:  86%|████████▌ | 6/7 [00:00<00:00, 89.08 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001780_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001130_male_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A13D0>: 100%|██████████| 7/7 [00:00<00:00, 101.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A14F0>: 100%|██████████| 7/7 [00:00<00:00, 86.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30A0>: 100%|██████████| 7/7 [00:00<00:00, 80.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A30>: 100%|██████████| 7/7 [00:00<00:00, 93.00 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000534_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004471_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D00>: 100%|██████████| 7/7 [00:00<00:00, 105.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD7C0>: 100%|██████████| 7/7 [00:00<00:00, 112.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD220>: 100%|██████████| 7/7 [00:00<00:00, 94.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1580>: 100%|██████████| 7/7 [00:00<00:00, 83.46 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000536_female_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000249_male_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD640>: 100%|██████████| 7/7 [00:00<00:00, 85.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABD8BB0>: 100%|██████████| 7/7 [00:00<00:00, 104.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABD8DC0>: 100%|██████████| 7/7 [00:00<00:00, 99.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919490>: 100%|██████████| 7/7 [00:00<00:00, 90.54 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FAABE6910>:  29%|██▊       | 2/7 [00:00<00:00, 42.85 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001177_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005052_male_Asian_46."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDF70>: 100%|██████████| 7/7 [00:00<00:00, 89.35 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD520>: 100%|██████████| 7/7 [00:00<00:00, 90.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9193D0>: 100%|██████████| 7/7 [00:00<00:00, 106.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68160>: 100%|██████████| 7/7 [00:00<00:00, 101.14 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004462_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006145_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A90>: 100%|██████████| 7/7 [00:00<00:00, 37.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3190>: 100%|██████████| 7/7 [00:00<00:00, 53.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3EE0>: 100%|██████████| 7/7 [00:00<00:00, 122.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61820>: 100%|██████████| 7/7 [00:00<00:00, 106.53 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A13D0>: 100%|██████████| 7/7 [00:00<00:00, 104.07 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003418_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000593_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68070>: 100%|██████████| 7/7 [00:00<00:00, 97.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919490>: 100%|██████████| 7/7 [00:00<00:00, 97.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3880>: 100%|██████████| 7/7 [00:00<00:00, 103.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614C0>:  29%|██▊       | 2/7 [00:00<00:00, 37.93 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004487_male_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006528_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D60>: 100%|██████████| 7/7 [00:00<00:00, 96.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61910>: 100%|██████████| 7/7 [00:00<00:00, 104.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53CA0>: 100%|██████████| 7/7 [00:00<00:00, 92.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECCA5CD0>: 100%|██████████| 7/7 [00:00<00:00, 86.31 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000568_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001624_female_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C190>: 100%|██████████| 7/7 [00:00<00:00, 86.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C40>: 100%|██████████| 7/7 [00:00<00:00, 79.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B50>: 100%|██████████| 7/7 [00:00<00:00, 103.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CA0>: 100%|██████████| 7/7 [00:00<00:00, 91.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB14250>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003365_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004453_male_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F70>: 100%|██████████| 7/7 [00:00<00:00, 67.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B20>: 100%|██████████| 7/7 [00:00<00:00, 80.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53040>: 100%|██████████| 7/7 [00:00<00:00, 78.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF40>: 100%|██████████| 7/7 [00:00<00:00, 97.35 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001011_male_Asian_30.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003437_female_Asian_30."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>: 100%|██████████| 7/7 [00:00<00:00, 82.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABD8850>: 100%|██████████| 7/7 [00:00<00:00, 73.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53430>: 100%|██████████| 7/7 [00:00<00:00, 114.16 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC70>: 100%|██████████| 7/7 [00:00<00:00, 83.19 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC220>:  57%|█████▋    | 4/7 [00:00<00:00, 80.05 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003398_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003061_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCAF0>: 100%|██████████| 7/7 [00:00<00:00, 108.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC130>: 100%|██████████| 7/7 [00:00<00:00, 70.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C40>: 100%|██████████| 7/7 [00:00<00:00, 69.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE68B0>: 100%|██████████| 7/7 [00:00<00:00, 122.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE68E0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001182_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006076_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C370>: 100%|██████████| 7/7 [00:00<00:00, 92.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1160>: 100%|██████████| 7/7 [00:00<00:00, 114.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F33A0>: 100%|██████████| 7/7 [00:00<00:00, 106.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68EE0>: 100%|██████████| 7/7 [00:00<00:00, 83.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3490>:  29%|██▊       | 2/7 [00:00<00:00, 47.50 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003002_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005268_male_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3430>: 100%|██████████| 7/7 [00:00<00:00, 85.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D30>: 100%|██████████| 7/7 [00:00<00:00, 97.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61850>: 100%|██████████| 7/7 [00:00<00:00, 111.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C616A0>: 100%|██████████| 7/7 [00:00<00:00, 99.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1520>: 100%|██████████| 7/7 [00:00<00:00, 113.85 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006397_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003305_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7940>: 100%|██████████| 7/7 [00:00<00:00, 95.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B20>: 100%|██████████| 7/7 [00:00<00:00, 79.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C616A0>: 100%|██████████| 7/7 [00:00<00:00, 106.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58AC0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001225_male_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000830_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919C10>: 100%|██████████| 7/7 [00:00<00:00, 93.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61DF0>: 100%|██████████| 7/7 [00:00<00:00, 92.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58B80>: 100%|██████████| 7/7 [00:00<00:00, 87.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3460>: 100%|██████████| 7/7 [00:00<00:00, 75.07 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003834_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001529_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C613A0>: 100%|██████████| 7/7 [00:00<00:00, 91.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58790>: 100%|██████████| 7/7 [00:00<00:00, 97.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9190A0>: 100%|██████████| 7/7 [00:00<00:00, 105.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3610>: 100%|██████████| 7/7 [00:00<00:00, 75.01 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006514_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000048_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919BB0>: 100%|██████████| 7/7 [00:00<00:00, 93.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDEE0>: 100%|██████████| 7/7 [00:00<00:00, 151.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58AF0>: 100%|██████████| 7/7 [00:00<00:00, 103.76 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8FDFA0>: 100%|██████████| 7/7 [00:00<00:00, 92.55 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001143_female_Asian_35.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001056_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F70>: 100%|██████████| 7/7 [00:00<00:00, 105.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919970>: 100%|██████████| 7/7 [00:00<00:00, 98.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919C10>: 100%|██████████| 7/7 [00:00<00:00, 84.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC5B0>: 100%|██████████| 7/7 [00:00<00:00, 104.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCD0>:  14%|█▍        | 1/7 [00:00<00:00, 24.04 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000570_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001810_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD160>: 100%|██████████| 7/7 [00:00<00:00, 91.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDFD0>: 100%|██████████| 7/7 [00:00<00:00, 88.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537F0>: 100%|██████████| 7/7 [00:00<00:00, 100.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D534F0>: 100%|██████████| 7/7 [00:00<00:00, 81.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC880>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000665_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001018_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD0A0>: 100%|██████████| 7/7 [00:00<00:00, 109.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA90>: 100%|██████████| 7/7 [00:00<00:00, 89.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC2E0>: 100%|██████████| 7/7 [00:00<00:00, 89.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA30>: 100%|██████████| 7/7 [00:00<00:00, 111.01 Samples/s]         \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001750_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006160_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58880>: 100%|██████████| 7/7 [00:00<00:00, 45.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BAC0>: 100%|██████████| 7/7 [00:00<00:00, 46.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919670>: 100%|██████████| 7/7 [00:00<00:00, 94.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7190>: 100%|██████████| 7/7 [00:00<00:00, 78.85 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003300_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001708_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF70>: 100%|██████████| 7/7 [00:00<00:00, 99.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919CA0>: 100%|██████████| 7/7 [00:00<00:00, 61.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919A30>: 100%|██████████| 7/7 [00:00<00:00, 94.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CA0>: 100%|██████████| 7/7 [00:00<00:00, 94.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E20>:  29%|██▊       | 2/7 [00:00<00:00, 46.14 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003340_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005284_male_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC430>: 100%|██████████| 7/7 [00:00<00:00, 96.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D688B0>: 100%|██████████| 7/7 [00:00<00:00, 98.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61880>: 100%|██████████| 7/7 [00:00<00:00, 96.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBCCA0>: 100%|██████████| 7/7 [00:00<00:00, 76.80 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001817_male_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005545_male_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31CA0>: 100%|██████████| 7/7 [00:00<00:00, 94.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68130>: 100%|██████████| 7/7 [00:00<00:00, 94.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31E20>: 100%|██████████| 7/7 [00:00<00:00, 92.55 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCDF0>: 100%|██████████| 7/7 [00:00<00:00, 109.01 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001325_female_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006142_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3700>: 100%|██████████| 7/7 [00:00<00:00, 43.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC610>: 100%|██████████| 7/7 [00:00<00:00, 44.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9196A0>: 100%|██████████| 7/7 [00:00<00:00, 72.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC220>: 100%|██████████| 7/7 [00:00<00:00, 87.08 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005489_female_Asian_43.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006088_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC580>: 100%|██████████| 7/7 [00:00<00:00, 93.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC40>: 100%|██████████| 7/7 [00:00<00:00, 82.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F36A0>: 100%|██████████| 7/7 [00:00<00:00, 96.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61820>: 100%|██████████| 7/7 [00:00<00:00, 89.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901970>:  29%|██▊       | 2/7 [00:00<00:00, 48.68 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001301_female_Asian_21.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006489_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901970>: 100%|██████████| 7/7 [00:00<00:00, 109.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61730>: 100%|██████████| 7/7 [00:00<00:00, 104.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61A60>: 100%|██████████| 7/7 [00:00<00:00, 82.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31F70>: 100%|██████████| 7/7 [00:00<00:00, 65.83 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003848_male_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001418_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68D00>: 100%|██████████| 7/7 [00:00<00:00, 110.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3E80>: 100%|██████████| 7/7 [00:00<00:00, 86.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F40>: 100%|██████████| 7/7 [00:00<00:00, 94.35 Samples/s]          \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61850>: 100%|██████████| 7/7 [00:00<00:00, 93.00 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006694_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005087_female_Asian_33."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D90>: 100%|██████████| 7/7 [00:00<00:00, 78.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A00>: 100%|██████████| 7/7 [00:00<00:00, 95.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C40>: 100%|██████████| 7/7 [00:00<00:00, 106.14 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1DC0>: 100%|██████████| 7/7 [00:00<00:00, 121.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198E0>:  57%|█████▋    | 4/7 [00:00<00:00, 61.51 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003177_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001348_female_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11C0>: 100%|██████████| 7/7 [00:00<00:00, 87.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EB0>: 100%|██████████| 7/7 [00:00<00:00, 115.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9196A0>: 100%|██████████| 7/7 [00:00<00:00, 117.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F36D0>: 100%|██████████| 7/7 [00:00<00:00, 79.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1190>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003080_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001176_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D587F0>: 100%|██████████| 7/7 [00:00<00:00, 101.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D589D0>: 100%|██████████| 7/7 [00:00<00:00, 80.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC640>: 100%|██████████| 7/7 [00:00<00:00, 86.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58A30>: 100%|██████████| 7/7 [00:00<00:00, 89.29 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006544_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000715_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3460>: 100%|██████████| 7/7 [00:00<00:00, 83.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A9340>: 100%|██████████| 7/7 [00:00<00:00, 79.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A30>: 100%|██████████| 7/7 [00:00<00:00, 90.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A13D0>: 100%|██████████| 7/7 [00:00<00:00, 74.04 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005091_female_Asian_29.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005015_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B20>: 100%|██████████| 7/7 [00:00<00:00, 66.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30A0>: 100%|██████████| 7/7 [00:00<00:00, 86.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F34F0>: 100%|██████████| 7/7 [00:00<00:00, 117.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF40>: 100%|██████████| 7/7 [00:00<00:00, 121.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC730>: 100%|██████████| 7/7 [00:00<00:00, 107.11 Samples/s]         \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001217_female_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001479_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA90>: 100%|██████████| 7/7 [00:00<00:00, 63.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD30>: 100%|██████████| 7/7 [00:00<00:00, 108.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535B0>: 100%|██████████| 7/7 [00:00<00:00, 86.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD90>:  57%|█████▋    | 4/7 [00:00<00:00, 84.64 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005054_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001108_female_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D587C0>: 100%|██████████| 7/7 [00:00<00:00, 129.79 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8FD250>: 100%|██████████| 7/7 [00:00<00:00, 134.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD520>: 100%|██████████| 7/7 [00:00<00:00, 95.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDFA0>: 100%|██████████| 7/7 [00:00<00:00, 82.09 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003309_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003774_female_Asian_30."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC40>: 100%|██████████| 7/7 [00:00<00:00, 93.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58A30>: 100%|██████████| 7/7 [00:00<00:00, 122.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC970>: 100%|██████████| 7/7 [00:00<00:00, 87.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC400>: 100%|██████████| 7/7 [00:00<00:00, 72.79 Samples/s]                  \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000517_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004430_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC250>: 100%|██████████| 7/7 [00:00<00:00, 75.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCBE0>: 100%|██████████| 7/7 [00:00<00:00, 103.31 Samples/s]         \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3670>: 100%|██████████| 7/7 [00:00<00:00, 95.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE20>: 100%|██████████| 7/7 [00:00<00:00, 91.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F33A0>:  14%|█▍        | 1/7 [00:00<00:00, 25.70 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003771_male_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000740_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE80>: 100%|██████████| 7/7 [00:00<00:00, 108.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D30>: 100%|██████████| 7/7 [00:00<00:00, 80.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCBE0>: 100%|██████████| 7/7 [00:00<00:00, 96.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BB20>: 100%|██████████| 7/7 [00:00<00:00, 105.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30A0>:  14%|█▍        | 1/7 [00:00<00:00, 20.59 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000644_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005293_male_Asian_31."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD790>: 100%|██████████| 7/7 [00:00<00:00, 77.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30D0>: 100%|██████████| 7/7 [00:00<00:00, 100.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA30>: 100%|██████████| 7/7 [00:00<00:00, 89.12 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7D68070>: 100%|██████████| 7/7 [00:00<00:00, 128.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B6A0>:  29%|██▊       | 2/7 [00:00<00:00, 37.98 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005468_female_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003558_female_Asian_45."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53910>: 100%|██████████| 7/7 [00:00<00:00, 96.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A60>: 100%|██████████| 7/7 [00:00<00:00, 124.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B700>: 100%|██████████| 7/7 [00:00<00:00, 94.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61430>: 100%|██████████| 7/7 [00:00<00:00, 102.55 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006447_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003117_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9016D0>: 100%|██████████| 7/7 [00:00<00:00, 86.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3520>: 100%|██████████| 7/7 [00:00<00:00, 85.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F32B0>: 100%|██████████| 7/7 [00:00<00:00, 129.07 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C618E0>: 100%|██████████| 7/7 [00:00<00:00, 79.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D30>:  43%|████▎     | 3/7 [00:00<00:00, 58.12 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003288_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004417_female_Asian_28."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30A0>: 100%|██████████| 7/7 [00:00<00:00, 95.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1190>: 100%|██████████| 7/7 [00:00<00:00, 111.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECCA5E20>: 100%|██████████| 7/7 [00:00<00:00, 94.01 Samples/s]          \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBC880>: 100%|██████████| 7/7 [00:00<00:00, 86.12 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006746_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001563_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68070>: 100%|██████████| 7/7 [00:00<00:00, 74.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1310>: 100%|██████████| 7/7 [00:00<00:00, 93.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D60>: 100%|██████████| 7/7 [00:00<00:00, 54.78 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006171_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919460>: 100%|██████████| 7/7 [00:00<00:00, 38.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CD0>: 100%|██████████| 7/7 [00:00<00:00, 85.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901940>: 100%|██████████| 7/7 [00:00<00:00, 87.27 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000755_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001417_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1490>: 100%|██████████| 7/7 [00:00<00:00, 107.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D30>: 100%|██████████| 7/7 [00:00<00:00, 129.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614F0>: 100%|██████████| 7/7 [00:00<00:00, 103.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919250>: 100%|██████████| 7/7 [00:00<00:00, 84.04 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3220>:  29%|██▊       | 2/7 [00:00<00:00, 48.74 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004100_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004433_female_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1DC0>: 100%|██████████| 7/7 [00:00<00:00, 120.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3520>: 100%|██████████| 7/7 [00:00<00:00, 116.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D30>: 100%|██████████| 7/7 [00:00<00:00, 87.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A00>: 100%|██████████| 7/7 [00:00<00:00, 79.57 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004204_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006597_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD610>: 100%|██████████| 7/7 [00:00<00:00, 71.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDFA0>: 100%|██████████| 7/7 [00:00<00:00, 93.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD430>: 100%|██████████| 7/7 [00:00<00:00, 89.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E80>: 100%|██████████| 7/7 [00:00<00:00, 91.56 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004480_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003297_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919100>: 100%|██████████| 7/7 [00:00<00:00, 89.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D587C0>: 100%|██████████| 7/7 [00:00<00:00, 110.48 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3A0>: 100%|██████████| 7/7 [00:00<00:00, 69.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC0A0>: 100%|██████████| 7/7 [00:00<00:00, 73.04 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001005_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000639_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD90>: 100%|██████████| 7/7 [00:00<00:00, 77.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3220>: 100%|██████████| 7/7 [00:00<00:00, 89.54 Samples/s]                  \n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC919A90>: 100%|██████████| 7/7 [00:00<00:00, 78.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA90>: 100%|██████████| 7/7 [00:00<00:00, 65.49 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005429_female_Asian_42.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001724_female_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FA0>: 100%|██████████| 7/7 [00:00<00:00, 72.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53400>: 100%|██████████| 7/7 [00:00<00:00, 121.30 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC3D0>: 100%|██████████| 7/7 [00:00<00:00, 107.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6A0>: 100%|██████████| 7/7 [00:00<00:00, 108.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC430>:  57%|█████▋    | 4/7 [00:00<00:00, 63.87 Samples/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005072_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001050_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC280>: 100%|██████████| 7/7 [00:00<00:00, 101.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA90>: 100%|██████████| 7/7 [00:00<00:00, 115.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA00>: 100%|██████████| 7/7 [00:00<00:00, 89.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F10>: 100%|██████████| 7/7 [00:00<00:00, 83.12 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003914_male_Asian_41.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001621_female_Asian_34."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CD0>: 100%|██████████| 7/7 [00:00<00:00, 98.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58BB0>: 100%|██████████| 7/7 [00:00<00:00, 97.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F40>: 100%|██████████| 7/7 [00:00<00:00, 105.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCFA0>: 100%|██████████| 7/7 [00:00<00:00, 93.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9199A0>:  71%|███████▏  | 5/7 [00:00<00:00, 102.40 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001524_female_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000745_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE20>: 100%|██████████| 7/7 [00:00<00:00, 104.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3670>: 100%|██████████| 7/7 [00:00<00:00, 79.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD490>: 100%|██████████| 7/7 [00:00<00:00, 93.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3100>: 100%|██████████| 7/7 [00:00<00:00, 89.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3610>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003113_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000296_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61790>: 100%|██████████| 7/7 [00:00<00:00, 96.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A9340>: 100%|██████████| 7/7 [00:00<00:00, 104.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919A90>: 100%|██████████| 7/7 [00:00<00:00, 96.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1880>: 100%|██████████| 7/7 [00:00<00:00, 109.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3700>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004093_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003198_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61400>: 100%|██████████| 7/7 [00:00<00:00, 70.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F39A0>: 100%|██████████| 7/7 [00:00<00:00, 108.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B100>: 100%|██████████| 7/7 [00:00<00:00, 102.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7F70>: 100%|██████████| 7/7 [00:00<00:00, 111.38 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1FD0>:  43%|████▎     | 3/7 [00:00<00:00, 51.70 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001757_female_Asian_45.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001028_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F40>: 100%|██████████| 7/7 [00:00<00:00, 86.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A13D0>: 100%|██████████| 7/7 [00:00<00:00, 104.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901940>: 100%|██████████| 7/7 [00:00<00:00, 108.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919670>: 100%|██████████| 7/7 [00:00<00:00, 74.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1BB0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003265_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005001_female_Asian_28."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901E50>: 100%|██████████| 7/7 [00:00<00:00, 100.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919CD0>: 100%|██████████| 7/7 [00:00<00:00, 112.83 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901760>: 100%|██████████| 7/7 [00:00<00:00, 71.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9012E0>: 100%|██████████| 7/7 [00:00<00:00, 76.14 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000538_male_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006056_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE33A0>: 100%|██████████| 7/7 [00:00<00:00, 35.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901100>: 100%|██████████| 7/7 [00:00<00:00, 35.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1CD0>: 100%|██████████| 7/7 [00:00<00:00, 98.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B100>: 100%|██████████| 7/7 [00:00<00:00, 102.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3880>:  71%|███████▏  | 5/7 [00:00<00:00, 104.93 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000571_male_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003803_female_Asian_46."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7F70>: 100%|██████████| 7/7 [00:00<00:00, 101.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1490>: 100%|██████████| 7/7 [00:00<00:00, 89.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D30>: 100%|██████████| 7/7 [00:00<00:00, 81.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3520>: 100%|██████████| 7/7 [00:00<00:00, 95.39 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006512_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001477_male_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919100>: 100%|██████████| 7/7 [00:00<00:00, 126.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68EE0>: 100%|██████████| 7/7 [00:00<00:00, 109.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919640>: 100%|██████████| 7/7 [00:00<00:00, 79.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1070>: 100%|██████████| 7/7 [00:00<00:00, 95.87 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003179_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003246_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D60>: 100%|██████████| 7/7 [00:00<00:00, 84.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CD0>: 100%|██████████| 7/7 [00:00<00:00, 99.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919220>: 100%|██████████| 7/7 [00:00<00:00, 107.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61550>: 100%|██████████| 7/7 [00:00<00:00, 111.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3F10>: 100%|██████████| 7/7 [00:00<00:00, 112.18 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006659_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006921_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61850>: 100%|██████████| 7/7 [00:00<00:00, 100.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD9D0>: 100%|██████████| 7/7 [00:00<00:00, 67.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD910>: 100%|██████████| 7/7 [00:00<00:00, 98.22 Samples/s]                  \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003573_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003504_male_Asian_49."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDFD0>: 100%|██████████| 7/7 [00:00<00:00, 87.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCA0>: 100%|██████████| 7/7 [00:00<00:00, 86.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD6D0>: 100%|██████████| 7/7 [00:00<00:00, 43.97 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006146_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919670>: 100%|██████████| 7/7 [00:00<00:00, 32.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CA0>: 100%|██████████| 7/7 [00:00<00:00, 111.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919BB0>: 100%|██████████| 7/7 [00:00<00:00, 90.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919100>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003413_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000827_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCAF0>: 100%|██████████| 7/7 [00:00<00:00, 100.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58910>: 100%|██████████| 7/7 [00:00<00:00, 119.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53910>: 100%|██████████| 7/7 [00:00<00:00, 87.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53940>: 100%|██████████| 7/7 [00:00<00:00, 72.34 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003836_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000630_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDF70>: 100%|██████████| 7/7 [00:00<00:00, 114.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9D0>: 100%|██████████| 7/7 [00:00<00:00, 101.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD2B0>: 100%|██████████| 7/7 [00:00<00:00, 92.74 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC400>: 100%|██████████| 7/7 [00:00<00:00, 93.99 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000825_male_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005274_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CD0>: 100%|██████████| 7/7 [00:00<00:00, 80.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC70>: 100%|██████████| 7/7 [00:00<00:00, 82.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D30>: 100%|██████████| 7/7 [00:00<00:00, 87.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9190A0>: 100%|██████████| 7/7 [00:00<00:00, 95.53 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004447_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005044_male_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9193D0>: 100%|██████████| 7/7 [00:00<00:00, 118.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61850>: 100%|██████████| 7/7 [00:00<00:00, 107.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC0A0>: 100%|██████████| 7/7 [00:00<00:00, 127.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919910>: 100%|██████████| 7/7 [00:00<00:00, 75.44 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003183_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000623_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC880>: 100%|██████████| 7/7 [00:00<00:00, 84.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA60>: 100%|██████████| 7/7 [00:00<00:00, 102.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9191F0>: 100%|██████████| 7/7 [00:00<00:00, 90.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198E0>: 100%|██████████| 7/7 [00:00<00:00, 113.87 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001308_male_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001412_male_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC580>: 100%|██████████| 7/7 [00:00<00:00, 67.18 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31AC0>: 100%|██████████| 7/7 [00:00<00:00, 90.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3DF0>: 100%|██████████| 7/7 [00:00<00:00, 124.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF75B0>: 100%|██████████| 7/7 [00:00<00:00, 121.10 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31D30>: 100%|██████████| 7/7 [00:00<00:00, 102.20 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001118_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000029_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C190>: 100%|██████████| 7/7 [00:00<00:00, 81.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC40>: 100%|██████████| 7/7 [00:00<00:00, 80.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9016D0>: 100%|██████████| 7/7 [00:00<00:00, 86.03 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005102_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003248_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901340>: 100%|██████████| 7/7 [00:00<00:00, 99.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901CA0>: 100%|██████████| 7/7 [00:00<00:00, 117.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3100>: 100%|██████████| 7/7 [00:00<00:00, 72.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7160>:  86%|████████▌ | 6/7 [00:00<00:00, 58.00 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000260_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7160>: 100%|██████████| 7/7 [00:00<00:00, 66.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919040>: 100%|██████████| 7/7 [00:00<00:00, 96.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B820>: 100%|██████████| 7/7 [00:00<00:00, 69.97 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000779_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003761_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919220>: 100%|██████████| 7/7 [00:00<00:00, 94.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68D00>: 100%|██████████| 7/7 [00:00<00:00, 84.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1520>: 100%|██████████| 7/7 [00:00<00:00, 102.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58730>: 100%|██████████| 7/7 [00:00<00:00, 85.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3460>:  29%|██▊       | 2/7 [00:00<00:00, 47.78 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003852_female_Asian_42.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003873_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61BB0>: 100%|██████████| 7/7 [00:00<00:00, 131.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919340>: 100%|██████████| 7/7 [00:00<00:00, 98.24 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C619A0>: 100%|██████████| 7/7 [00:00<00:00, 92.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>: 100%|██████████| 7/7 [00:00<00:00, 79.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3970>:  29%|██▊       | 2/7 [00:00<00:00, 110.16 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001657_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001293_female_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919670>: 100%|██████████| 7/7 [00:00<00:00, 123.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9197F0>: 100%|██████████| 7/7 [00:00<00:00, 84.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9197F0>: 100%|██████████| 7/7 [00:00<00:00, 81.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A13D0>: 100%|██████████| 7/7 [00:00<00:00, 87.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3760>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000274_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001320_male_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61820>: 100%|██████████| 7/7 [00:00<00:00, 86.44 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B20>: 100%|██████████| 7/7 [00:00<00:00, 107.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C40>: 100%|██████████| 7/7 [00:00<00:00, 100.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53BB0>: 100%|██████████| 7/7 [00:00<00:00, 97.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD430>:  14%|█▍        | 1/7 [00:00<00:00, 23.08 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004026_male_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001583-1_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC880>: 100%|██████████| 7/7 [00:00<00:00, 98.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C10>: 100%|██████████| 7/7 [00:00<00:00, 91.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD9A0>: 100%|██████████| 7/7 [00:00<00:00, 98.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53700>: 100%|██████████| 7/7 [00:00<00:00, 113.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDFD0>: 100%|██████████| 7/7 [00:00<00:00, 116.53 Samples/s]                 \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001882_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001035_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC460>: 100%|██████████| 7/7 [00:00<00:00, 100.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6850>: 100%|██████████| 7/7 [00:00<00:00, 122.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCB20>: 100%|██████████| 7/7 [00:00<00:00, 96.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38B0>:  57%|█████▋    | 4/7 [00:00<00:00, 62.94 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006952_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005448_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCEB0>: 100%|██████████| 7/7 [00:00<00:00, 100.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCBE0>: 100%|██████████| 7/7 [00:00<00:00, 96.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDF10>: 100%|██████████| 7/7 [00:00<00:00, 82.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3E20>: 100%|██████████| 7/7 [00:00<00:00, 69.58 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001643_female_Asian_21.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005477_female_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3880>: 100%|██████████| 7/7 [00:00<00:00, 103.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDB50>: 100%|██████████| 7/7 [00:00<00:00, 82.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD280>: 100%|██████████| 7/7 [00:00<00:00, 78.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3F10>: 100%|██████████| 7/7 [00:00<00:00, 73.06 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001424_male_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006430_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3190>: 100%|██████████| 7/7 [00:00<00:00, 81.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58790>: 100%|██████████| 7/7 [00:00<00:00, 84.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3AF0>: 100%|██████████| 7/7 [00:00<00:00, 126.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61550>: 100%|██████████| 7/7 [00:00<00:00, 94.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614C0>: 100%|██████████| 7/7 [00:00<00:00, 105.93 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004163_male_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000069_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3610>: 100%|██████████| 7/7 [00:00<00:00, 100.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A2100>: 100%|██████████| 7/7 [00:00<00:00, 76.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C619A0>: 100%|██████████| 7/7 [00:00<00:00, 82.84 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001640_male_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003238_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC250>: 100%|██████████| 7/7 [00:00<00:00, 99.95 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1670>: 100%|██████████| 7/7 [00:00<00:00, 69.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58B80>: 100%|██████████| 7/7 [00:00<00:00, 116.44 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1F0>: 100%|██████████| 7/7 [00:00<00:00, 95.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF1AF0>:  14%|█▍        | 1/7 [00:00<00:00, 17.15 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004436_male_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005128_male_Asian_45."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61580>: 100%|██████████| 7/7 [00:00<00:00, 77.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B670>: 100%|██████████| 7/7 [00:00<00:00, 88.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901520>:  86%|████████▌ | 6/7 [00:00<00:00, 27.76 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006221_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901520>: 100%|██████████| 7/7 [00:00<00:00, 34.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B100>: 100%|██████████| 7/7 [00:00<00:00, 28.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919B50>: 100%|██████████| 7/7 [00:00<00:00, 79.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919970>: 100%|██████████| 7/7 [00:00<00:00, 82.87 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000539_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006511_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE36A0>: 100%|██████████| 7/7 [00:00<00:00, 126.94 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FAABE32B0>: 100%|██████████| 7/7 [00:00<00:00, 104.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BB20>: 100%|██████████| 7/7 [00:00<00:00, 95.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901490>: 100%|██████████| 7/7 [00:00<00:00, 99.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C3D0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001523_male_Asian_28.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001228_male_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919130>: 100%|██████████| 7/7 [00:00<00:00, 88.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF12E0>: 100%|██████████| 7/7 [00:00<00:00, 84.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1520>: 100%|██████████| 7/7 [00:00<00:00, 35.92 Samples/s]                \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006128_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D587F0>: 100%|██████████| 7/7 [00:00<00:00, 53.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68F40>: 100%|██████████| 7/7 [00:00<00:00, 137.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68C70>: 100%|██████████| 7/7 [00:00<00:00, 109.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919100>:  57%|█████▋    | 4/7 [00:00<00:00, 51.37 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001594_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001792_male_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919550>: 100%|██████████| 7/7 [00:00<00:00, 83.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>: 100%|██████████| 7/7 [00:00<00:00, 80.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D30>: 100%|██████████| 7/7 [00:00<00:00, 91.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FD0>: 100%|██████████| 7/7 [00:00<00:00, 84.74 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005452_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004237_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A90>: 100%|██████████| 7/7 [00:00<00:00, 107.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDBE0>: 100%|██████████| 7/7 [00:00<00:00, 103.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61A90>: 100%|██████████| 7/7 [00:00<00:00, 90.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD6D0>: 100%|██████████| 7/7 [00:00<00:00, 78.44 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000816_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001578_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1DC0>: 100%|██████████| 7/7 [00:00<00:00, 81.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCCD0>: 100%|██████████| 7/7 [00:00<00:00, 82.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F35B0>: 100%|██████████| 7/7 [00:00<00:00, 96.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A30>: 100%|██████████| 7/7 [00:00<00:00, 70.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD9D0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003272_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003162_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FA0>: 100%|██████████| 7/7 [00:00<00:00, 89.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1BB0>: 100%|██████████| 7/7 [00:00<00:00, 83.55 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8FD2E0>: 100%|██████████| 7/7 [00:00<00:00, 79.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCBE0>: 100%|██████████| 7/7 [00:00<00:00, 101.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD0A0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003323_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000711_female_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A90>: 100%|██████████| 7/7 [00:00<00:00, 90.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6A0>: 100%|██████████| 7/7 [00:00<00:00, 86.08 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC2E0>: 100%|██████████| 7/7 [00:00<00:00, 110.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC490>: 100%|██████████| 7/7 [00:00<00:00, 75.86 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004457_female_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005042_female_Asian_49."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD7F0>: 100%|██████████| 7/7 [00:00<00:00, 71.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC970>: 100%|██████████| 7/7 [00:00<00:00, 70.46 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABD80D0>: 100%|██████████| 7/7 [00:00<00:00, 36.27 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006243_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDF10>: 100%|██████████| 7/7 [00:00<00:00, 34.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC220>: 100%|██████████| 7/7 [00:00<00:00, 86.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3C10>: 100%|██████████| 7/7 [00:00<00:00, 98.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA30>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005023_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005294_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901340>: 100%|██████████| 7/7 [00:00<00:00, 84.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3AF0>: 100%|██████████| 7/7 [00:00<00:00, 117.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD910>: 100%|██████████| 7/7 [00:00<00:00, 98.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD970>: 100%|██████████| 7/7 [00:00<00:00, 82.49 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000613_male_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003357_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1310>: 100%|██████████| 7/7 [00:00<00:00, 80.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61820>: 100%|██████████| 7/7 [00:00<00:00, 155.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53BB0>: 100%|██████████| 7/7 [00:00<00:00, 100.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE20>: 100%|██████████| 7/7 [00:00<00:00, 116.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61A90>:  71%|███████▏  | 5/7 [00:00<00:00, 78.95 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003828_female_Asian_29.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003026_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53FD0>: 100%|██████████| 7/7 [00:00<00:00, 90.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F39A0>: 100%|██████████| 7/7 [00:00<00:00, 117.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C613D0>: 100%|██████████| 7/7 [00:00<00:00, 87.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68E20>: 100%|██████████| 7/7 [00:00<00:00, 83.94 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000545_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006644_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C370>: 100%|██████████| 7/7 [00:00<00:00, 88.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A9340>: 100%|██████████| 7/7 [00:00<00:00, 98.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68C70>: 100%|██████████| 7/7 [00:00<00:00, 100.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58A00>: 100%|██████████| 7/7 [00:00<00:00, 82.32 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006004_male_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003363_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7D58B80>: 100%|██████████| 7/7 [00:00<00:00, 102.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA00>: 100%|██████████| 7/7 [00:00<00:00, 113.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1F0>: 100%|██████████| 7/7 [00:00<00:00, 93.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF75B0>: 100%|██████████| 7/7 [00:00<00:00, 111.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D681C0>:  43%|████▎     | 3/7 [00:00<00:00, 52.95 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006664_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006245_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>: 100%|██████████| 7/7 [00:00<00:00, 99.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A22E0>: 100%|██████████| 7/7 [00:00<00:00, 85.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919910>: 100%|██████████| 7/7 [00:00<00:00, 108.36 Samples/s]         \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1F0>: 100%|██████████| 7/7 [00:00<00:00, 91.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3D60>:  57%|█████▋    | 4/7 [00:00<00:00, 93.62 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005490_female_Asian_42.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004451_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919790>: 100%|██████████| 7/7 [00:00<00:00, 109.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC70>: 100%|██████████| 7/7 [00:00<00:00, 124.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919970>: 100%|██████████| 7/7 [00:00<00:00, 87.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE20>: 100%|██████████| 7/7 [00:00<00:00, 85.77 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006380_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000726_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE36A0>: 100%|██████████| 7/7 [00:00<00:00, 91.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B670>: 100%|██████████| 7/7 [00:00<00:00, 79.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D681C0>: 100%|██████████| 7/7 [00:00<00:00, 85.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31AC0>: 100%|██████████| 7/7 [00:00<00:00, 72.64 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003154_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005491_male_Asian_46."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA90>: 100%|██████████| 7/7 [00:00<00:00, 80.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC550>: 100%|██████████| 7/7 [00:00<00:00, 98.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3400>: 100%|██████████| 7/7 [00:00<00:00, 86.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D588E0>: 100%|██████████| 7/7 [00:00<00:00, 118.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6A0>:  14%|█▍        | 1/7 [00:00<00:00, 17.91 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006108_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005250_male_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF40>: 100%|██████████| 7/7 [00:00<00:00, 107.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3370>: 100%|██████████| 7/7 [00:00<00:00, 74.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A60>: 100%|██████████| 7/7 [00:00<00:00, 74.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA90>: 100%|██████████| 7/7 [00:00<00:00, 105.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901280>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003280_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005548_female_Asian_40."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC2E0>: 100%|██████████| 7/7 [00:00<00:00, 113.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901400>: 100%|██████████| 7/7 [00:00<00:00, 97.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3EB0>: 100%|██████████| 7/7 [00:00<00:00, 38.04 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006155_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE30A0>: 100%|██████████| 7/7 [00:00<00:00, 49.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF70>: 100%|██████████| 7/7 [00:00<00:00, 97.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDAC0>: 100%|██████████| 7/7 [00:00<00:00, 93.70 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FAABE3EE0>:  43%|████▎     | 3/7 [00:00<00:00, 61.15 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000225_male_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003006_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3F40>: 100%|██████████| 7/7 [00:00<00:00, 98.42 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE34C0>: 100%|██████████| 7/7 [00:00<00:00, 101.30 Samples/s]         \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC640>: 100%|██████████| 7/7 [00:00<00:00, 74.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3910>: 100%|██████████| 7/7 [00:00<00:00, 108.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD250>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001785_male_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001253_male_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE32E0>: 100%|██████████| 7/7 [00:00<00:00, 97.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE33A0>: 100%|██████████| 7/7 [00:00<00:00, 82.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3D0>: 100%|██████████| 7/7 [00:00<00:00, 108.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD9A0>: 100%|██████████| 7/7 [00:00<00:00, 85.44 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000739_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001550_male_Asian_28."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3550>: 100%|██████████| 7/7 [00:00<00:00, 75.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3370>: 100%|██████████| 7/7 [00:00<00:00, 76.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53130>: 100%|██████████| 7/7 [00:00<00:00, 115.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D30>: 100%|██████████| 7/7 [00:00<00:00, 84.38 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001223_female_Asian_21.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001505_female_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F40>: 100%|██████████| 7/7 [00:00<00:00, 66.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1850>: 100%|██████████| 7/7 [00:00<00:00, 73.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901C70>: 100%|██████████| 7/7 [00:00<00:00, 109.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CD0>: 100%|██████████| 7/7 [00:00<00:00, 89.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD700>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001238_female_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000820_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53850>: 100%|██████████| 7/7 [00:00<00:00, 85.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C40>: 100%|██████████| 7/7 [00:00<00:00, 121.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA30>: 100%|██████████| 7/7 [00:00<00:00, 106.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9016D0>: 100%|██████████| 7/7 [00:00<00:00, 84.94 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000699_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001394_male_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F34F0>: 100%|██████████| 7/7 [00:00<00:00, 97.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3880>: 100%|██████████| 7/7 [00:00<00:00, 108.19 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF70>: 100%|██████████| 7/7 [00:00<00:00, 104.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9D0>: 100%|██████████| 7/7 [00:00<00:00, 81.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD30>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003171_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001187_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30D0>: 100%|██████████| 7/7 [00:00<00:00, 96.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3F10>: 100%|██████████| 7/7 [00:00<00:00, 88.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDB50>: 100%|██████████| 7/7 [00:00<00:00, 92.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3DF0>: 100%|██████████| 7/7 [00:00<00:00, 74.58 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004413_male_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005481_female_Asian_39."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF1AC0>: 100%|██████████| 7/7 [00:00<00:00, 90.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7940>: 100%|██████████| 7/7 [00:00<00:00, 80.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58DC0>: 100%|██████████| 7/7 [00:00<00:00, 73.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD700>: 100%|██████████| 7/7 [00:00<00:00, 124.98 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001470_male_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006069_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3AF0>: 100%|██████████| 7/7 [00:00<00:00, 45.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3700>: 100%|██████████| 7/7 [00:00<00:00, 37.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B970>: 100%|██████████| 7/7 [00:00<00:00, 78.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC520>: 100%|██████████| 7/7 [00:00<00:00, 104.42 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003752_female_Asian_44.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006536_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCEE0>: 100%|██████████| 7/7 [00:00<00:00, 80.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE20>: 100%|██████████| 7/7 [00:00<00:00, 78.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58880>: 100%|██████████| 7/7 [00:00<00:00, 74.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3070>:  29%|██▊       | 2/7 [00:00<00:00, 23.50 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003090_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3490>: 100%|██████████| 7/7 [00:00<00:00, 55.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E80>: 100%|██████████| 7/7 [00:00<00:00, 91.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3FD0>: 100%|██████████| 7/7 [00:00<00:00, 89.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3CD0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006955_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005262_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B6A0>: 100%|██████████| 7/7 [00:00<00:00, 75.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BB20>: 100%|██████████| 7/7 [00:00<00:00, 128.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B6A0>: 100%|██████████| 7/7 [00:00<00:00, 88.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7E66820>: 100%|██████████| 7/7 [00:00<00:00, 88.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3790>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001157_female_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001669_male_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31FD0>: 100%|██████████| 7/7 [00:00<00:00, 91.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3580>: 100%|██████████| 7/7 [00:00<00:00, 68.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58730>: 100%|██████████| 7/7 [00:00<00:00, 90.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CA0>: 100%|██████████| 7/7 [00:00<00:00, 100.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A00>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005264_male_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003134_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC580>: 100%|██████████| 7/7 [00:00<00:00, 81.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58940>: 100%|██████████| 7/7 [00:00<00:00, 100.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF10>: 100%|██████████| 7/7 [00:00<00:00, 84.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D586A0>: 100%|██████████| 7/7 [00:00<00:00, 93.93 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005228_male_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006439_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE31C0>: 100%|██████████| 7/7 [00:00<00:00, 114.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC490>: 100%|██████████| 7/7 [00:00<00:00, 83.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6A0>: 100%|██████████| 7/7 [00:00<00:00, 104.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901040>: 100%|██████████| 7/7 [00:00<00:00, 106.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3550>:  71%|███████▏  | 5/7 [00:00<00:00, 83.22 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000022_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006622_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3400>: 100%|██████████| 7/7 [00:00<00:00, 101.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCD0>: 100%|██████████| 7/7 [00:00<00:00, 105.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3670>: 100%|██████████| 7/7 [00:00<00:00, 93.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD9A0>: 100%|██████████| 7/7 [00:00<00:00, 88.65 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003081_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006207_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C10>: 100%|██████████| 7/7 [00:00<00:00, 44.08 Samples/s]                \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE20>: 100%|██████████| 7/7 [00:00<00:00, 37.46 Samples/s]                \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDC40>: 100%|██████████| 7/7 [00:00<00:00, 83.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC970>: 100%|██████████| 7/7 [00:00<00:00, 106.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3910>:  29%|██▊       | 2/7 [00:00<00:00, 46.91 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003843_male_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003632_male_Asian_43."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CA0>: 100%|██████████| 7/7 [00:00<00:00, 94.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53EE0>: 100%|██████████| 7/7 [00:00<00:00, 89.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61850>: 100%|██████████| 7/7 [00:00<00:00, 94.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EE0>: 100%|██████████| 7/7 [00:00<00:00, 81.88 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003746_male_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000901_female_Asian_49."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3190>: 100%|██████████| 7/7 [00:00<00:00, 75.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53130>: 100%|██████████| 7/7 [00:00<00:00, 102.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DC0>: 100%|██████████| 7/7 [00:00<00:00, 138.10 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C613D0>: 100%|██████████| 7/7 [00:00<00:00, 126.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1CD0>: 100%|██████████| 7/7 [00:00<00:00, 92.63 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001572_female_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003396_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1AC0>: 100%|██████████| 7/7 [00:00<00:00, 87.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536A0>: 100%|██████████| 7/7 [00:00<00:00, 99.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1490>: 100%|██████████| 7/7 [00:00<00:00, 76.54 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005237_male_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001646_female_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11C0>: 100%|██████████| 7/7 [00:00<00:00, 75.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61790>: 100%|██████████| 7/7 [00:00<00:00, 82.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9018E0>: 100%|██████████| 7/7 [00:00<00:00, 142.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD220>: 100%|██████████| 7/7 [00:00<00:00, 88.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC970>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001151_male_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003342_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD520>: 100%|██████████| 7/7 [00:00<00:00, 82.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A00>: 100%|██████████| 7/7 [00:00<00:00, 88.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD7C0>: 100%|██████████| 7/7 [00:00<00:00, 135.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3F10>: 100%|██████████| 7/7 [00:00<00:00, 138.84 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001564_male_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006228_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC850>: 100%|██████████| 7/7 [00:00<00:00, 51.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F34F0>: 100%|██████████| 7/7 [00:00<00:00, 32.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD910>: 100%|██████████| 7/7 [00:00<00:00, 72.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD90>:  14%|█▍        | 1/7 [00:00<00:00, 14.29 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000626_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCCA0>: 100%|██████████| 7/7 [00:00<00:00, 56.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCD0>: 100%|██████████| 7/7 [00:00<00:00, 84.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CA0>: 100%|██████████| 7/7 [00:00<00:00, 90.93 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003582_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003096_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3610>: 100%|██████████| 7/7 [00:00<00:00, 102.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A93A0>: 100%|██████████| 7/7 [00:00<00:00, 96.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B700>: 100%|██████████| 7/7 [00:00<00:00, 92.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B040>: 100%|██████████| 7/7 [00:00<00:00, 104.20 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7160>:  29%|██▊       | 2/7 [00:00<00:00, 50.77 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003011_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005415_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A30>: 100%|██████████| 7/7 [00:00<00:00, 115.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD340>: 100%|██████████| 7/7 [00:00<00:00, 82.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3BE0>: 100%|██████████| 7/7 [00:00<00:00, 74.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6D0>: 100%|██████████| 7/7 [00:00<00:00, 78.32 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003168_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001249_female_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDF10>: 100%|██████████| 7/7 [00:00<00:00, 78.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F10>: 100%|██████████| 7/7 [00:00<00:00, 84.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68160>: 100%|██████████| 7/7 [00:00<00:00, 77.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3850>: 100%|██████████| 7/7 [00:00<00:00, 89.67 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000215_female_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001016_male_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3E20>: 100%|██████████| 7/7 [00:00<00:00, 83.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE37F0>: 100%|██████████| 7/7 [00:00<00:00, 100.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7D60>: 100%|██████████| 7/7 [00:00<00:00, 94.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58790>: 100%|██████████| 7/7 [00:00<00:00, 72.41 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003132_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003887_female_Asian_32."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC100>: 100%|██████████| 7/7 [00:00<00:00, 99.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC370>: 100%|██████████| 7/7 [00:00<00:00, 92.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58880>: 100%|██████████| 7/7 [00:00<00:00, 73.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58FA0>: 100%|██████████| 7/7 [00:00<00:00, 83.36 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001454_female_Asian_49.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005029_female_Asian_49."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F10>: 100%|██████████| 7/7 [00:00<00:00, 79.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3A30>: 100%|██████████| 7/7 [00:00<00:00, 79.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901940>: 100%|██████████| 7/7 [00:00<00:00, 90.62 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3460>: 100%|██████████| 7/7 [00:00<00:00, 118.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE36D0>:  29%|██▊       | 2/7 [00:00<00:00, 35.41 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001558_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001411_male_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC970>: 100%|██████████| 7/7 [00:00<00:00, 90.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901850>: 100%|██████████| 7/7 [00:00<00:00, 78.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3190>: 100%|██████████| 7/7 [00:00<00:00, 84.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC520>: 100%|██████████| 7/7 [00:00<00:00, 89.17 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000563_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006179_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE20>: 100%|██████████| 7/7 [00:00<00:00, 42.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC850>: 100%|██████████| 7/7 [00:00<00:00, 42.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE38E0>: 100%|██████████| 7/7 [00:00<00:00, 105.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA30>: 100%|██████████| 7/7 [00:00<00:00, 87.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD130>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005021_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006467_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC3D0>: 100%|██████████| 7/7 [00:00<00:00, 100.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536A0>: 100%|██████████| 7/7 [00:00<00:00, 84.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3820>: 100%|██████████| 7/7 [00:00<00:00, 88.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA30>: 100%|██████████| 7/7 [00:00<00:00, 107.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3D0>:  43%|████▎     | 3/7 [00:00<00:00, 60.12 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001796_female_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003892_female_Asian_42."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD940>: 100%|██████████| 7/7 [00:00<00:00, 109.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3D00>: 100%|██████████| 7/7 [00:00<00:00, 84.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD90>: 100%|██████████| 7/7 [00:00<00:00, 107.13 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1160>: 100%|██████████| 7/7 [00:00<00:00, 134.05 Samples/s]                 \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003329_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006066_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD340>: 100%|██████████| 7/7 [00:00<00:00, 47.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919B50>: 100%|██████████| 7/7 [00:00<00:00, 37.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C40>: 100%|██████████| 7/7 [00:00<00:00, 100.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDDF0>: 100%|██████████| 7/7 [00:00<00:00, 107.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612B0>:  29%|██▊       | 2/7 [00:00<00:00, 43.18 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003185_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001066_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD820>: 100%|██████████| 7/7 [00:00<00:00, 87.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD00>: 100%|██████████| 7/7 [00:00<00:00, 71.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC95D790>: 100%|██████████| 7/7 [00:00<00:00, 108.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61DC0>: 100%|██████████| 7/7 [00:00<00:00, 114.65 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61580>:  57%|█████▋    | 4/7 [00:00<00:00, 61.84 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001332_male_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003536_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53340>: 100%|██████████| 7/7 [00:00<00:00, 91.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C615E0>: 100%|██████████| 7/7 [00:00<00:00, 105.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F37C0>: 100%|██████████| 7/7 [00:00<00:00, 83.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31520>: 100%|██████████| 7/7 [00:00<00:00, 112.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1BE0>:  43%|████▎     | 3/7 [00:00<00:00, 62.38 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003039_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001197_male_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901CA0>: 100%|██████████| 7/7 [00:00<00:00, 118.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31D30>: 100%|██████████| 7/7 [00:00<00:00, 90.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61430>: 100%|██████████| 7/7 [00:00<00:00, 93.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D30>: 100%|██████████| 7/7 [00:00<00:00, 79.16 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006340_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004439_female_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1FD0>: 100%|██████████| 7/7 [00:00<00:00, 96.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDEE0>: 100%|██████████| 7/7 [00:00<00:00, 121.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901760>: 100%|██████████| 7/7 [00:00<00:00, 103.18 Samples/s]         \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BAC0>: 100%|██████████| 7/7 [00:00<00:00, 74.53 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005107_female_Asian_38.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003029_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3400>: 100%|██████████| 7/7 [00:00<00:00, 116.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1130>: 100%|██████████| 7/7 [00:00<00:00, 95.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC370>: 100%|██████████| 7/7 [00:00<00:00, 101.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1160>: 100%|██████████| 7/7 [00:00<00:00, 100.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD250>:  14%|█▍        | 1/7 [00:00<00:00, 19.60 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001728_female_Asian_38.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005265_male_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF1AF0>: 100%|██████████| 7/7 [00:00<00:00, 82.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC7F0>: 100%|██████████| 7/7 [00:00<00:00, 75.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901400>: 100%|██████████| 7/7 [00:00<00:00, 89.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F10>: 100%|██████████| 7/7 [00:00<00:00, 93.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3970>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000817_male_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003062_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD100>: 100%|██████████| 7/7 [00:00<00:00, 120.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE31C0>: 100%|██████████| 7/7 [00:00<00:00, 128.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C10>: 100%|██████████| 7/7 [00:00<00:00, 90.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC310>: 100%|██████████| 7/7 [00:00<00:00, 90.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC250>:  14%|█▍        | 1/7 [00:00<00:00, 25.72 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001257_male_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001120_female_Asian_28."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9190D0>: 100%|██████████| 7/7 [00:00<00:00, 105.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E50>: 100%|██████████| 7/7 [00:00<00:00, 79.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9194F0>: 100%|██████████| 7/7 [00:00<00:00, 133.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58760>: 100%|██████████| 7/7 [00:00<00:00, 127.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCAF0>: 100%|██████████| 7/7 [00:00<00:00, 102.77 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001864_female_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003937_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E20>: 100%|██████████| 7/7 [00:00<00:00, 79.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D90>: 100%|██████████| 7/7 [00:00<00:00, 82.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3A60>: 100%|██████████| 7/7 [00:00<00:00, 72.38 Samples/s]                  \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003590_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001653_female_Asian_36."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A30>: 100%|██████████| 7/7 [00:00<00:00, 79.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA60>: 100%|██████████| 7/7 [00:00<00:00, 108.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1820>: 100%|██████████| 7/7 [00:00<00:00, 105.36 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCFA0>: 100%|██████████| 7/7 [00:00<00:00, 76.23 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006426_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003296_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11C0>: 100%|██████████| 7/7 [00:00<00:00, 103.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCCD0>: 100%|██████████| 7/7 [00:00<00:00, 96.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC70>: 100%|██████████| 7/7 [00:00<00:00, 81.54 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3100>: 100%|██████████| 7/7 [00:00<00:00, 89.77 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006565_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000694_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE34C0>: 100%|██████████| 7/7 [00:00<00:00, 90.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EB0>: 100%|██████████| 7/7 [00:00<00:00, 106.41 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC95D790>: 100%|██████████| 7/7 [00:00<00:00, 76.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A00>: 100%|██████████| 7/7 [00:00<00:00, 124.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53940>:  29%|██▊       | 2/7 [00:00<00:00, 47.77 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004086_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001705_male_Asian_37."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F36A0>: 100%|██████████| 7/7 [00:00<00:00, 112.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31F70>: 100%|██████████| 7/7 [00:00<00:00, 102.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53130>: 100%|██████████| 7/7 [00:00<00:00, 104.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53580>: 100%|██████████| 7/7 [00:00<00:00, 107.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B20>:  29%|██▊       | 2/7 [00:00<00:00, 37.60 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001153_female_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003063_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A60>: 100%|██████████| 7/7 [00:00<00:00, 98.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD00>: 100%|██████████| 7/7 [00:00<00:00, 132.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53EE0>: 100%|██████████| 7/7 [00:00<00:00, 94.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCD0>: 100%|██████████| 7/7 [00:00<00:00, 98.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53CA0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006742_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001132_female_Asian_43."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C10>: 100%|██████████| 7/7 [00:00<00:00, 107.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD430>: 100%|██████████| 7/7 [00:00<00:00, 75.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1BB0>: 100%|██████████| 7/7 [00:00<00:00, 69.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC2B0>: 100%|██████████| 7/7 [00:00<00:00, 84.72 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003377_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000781_male_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61850>: 100%|██████████| 7/7 [00:00<00:00, 92.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C310>: 100%|██████████| 7/7 [00:00<00:00, 120.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53430>: 100%|██████████| 7/7 [00:00<00:00, 81.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F34F0>: 100%|██████████| 7/7 [00:00<00:00, 132.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F36A0>:  43%|████▎     | 3/7 [00:00<00:00, 52.70 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001739_male_Asian_29.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006425_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68160>: 100%|██████████| 7/7 [00:00<00:00, 76.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68EE0>: 100%|██████████| 7/7 [00:00<00:00, 71.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B160>: 100%|██████████| 7/7 [00:00<00:00, 100.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53BB0>: 100%|██████████| 7/7 [00:00<00:00, 78.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53280>:  14%|█▍        | 1/7 [00:00<00:00, 27.18 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001099_male_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005006_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901520>: 100%|██████████| 7/7 [00:00<00:00, 130.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901940>: 100%|██████████| 7/7 [00:00<00:00, 87.93 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D539A0>: 100%|██████████| 7/7 [00:00<00:00, 110.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38B0>: 100%|██████████| 7/7 [00:00<00:00, 112.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1130>:  57%|█████▋    | 4/7 [00:00<00:00, 57.31 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004013_male_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/002826_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3190>: 100%|██████████| 7/7 [00:00<00:00, 97.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58C40>: 100%|██████████| 7/7 [00:00<00:00, 83.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53130>: 100%|██████████| 7/7 [00:00<00:00, 86.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58730>: 100%|██████████| 7/7 [00:00<00:00, 100.40 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005105_male_Asian_33.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003233_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF1AF0>: 100%|██████████| 7/7 [00:00<00:00, 67.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD910>: 100%|██████████| 7/7 [00:00<00:00, 83.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE80>: 100%|██████████| 7/7 [00:00<00:00, 91.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D90>: 100%|██████████| 7/7 [00:00<00:00, 87.09 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005103_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003411_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E20>: 100%|██████████| 7/7 [00:00<00:00, 113.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD2E0>: 100%|██████████| 7/7 [00:00<00:00, 66.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A60>: 100%|██████████| 7/7 [00:00<00:00, 87.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A19D0>: 100%|██████████| 7/7 [00:00<00:00, 101.08 Samples/s]                 \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003048_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005525_female_Asian_39."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1C0>: 100%|██████████| 7/7 [00:00<00:00, 66.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD250>: 100%|██████████| 7/7 [00:00<00:00, 54.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC580>: 100%|██████████| 7/7 [00:00<00:00, 66.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1F0>:  71%|███████▏  | 5/7 [00:00<00:00, 56.68 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006431_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A00>: 100%|██████████| 7/7 [00:00<00:00, 71.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC490>: 100%|██████████| 7/7 [00:00<00:00, 66.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC70>:  71%|███████▏  | 5/7 [00:00<00:00, 68.72 Samples/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005405_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6A0>: 100%|██████████| 7/7 [00:00<00:00, 72.06 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FAABCCD30>: 100%|██████████| 7/7 [00:00<00:00, 95.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC700>: 100%|██████████| 7/7 [00:00<00:00, 88.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919070>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006106_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006530_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1820>: 100%|██████████| 7/7 [00:00<00:00, 118.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A22E0>: 100%|██████████| 7/7 [00:00<00:00, 101.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE31C0>: 100%|██████████| 7/7 [00:00<00:00, 88.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC640>: 100%|██████████| 7/7 [00:00<00:00, 82.14 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003007_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001754_female_Asian_43."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58BB0>: 100%|██████████| 7/7 [00:00<00:00, 95.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF40>: 100%|██████████| 7/7 [00:00<00:00, 103.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535E0>: 100%|██████████| 7/7 [00:00<00:00, 100.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA00>: 100%|██████████| 7/7 [00:00<00:00, 103.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3A00>:  29%|██▊       | 2/7 [00:00<00:00, 34.24 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006754_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000689_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58820>: 100%|██████████| 7/7 [00:00<00:00, 82.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D00>: 100%|██████████| 7/7 [00:00<00:00, 111.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919910>: 100%|██████████| 7/7 [00:00<00:00, 88.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536D0>: 100%|██████████| 7/7 [00:00<00:00, 121.57 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9190A0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004310_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001084_female_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCFA0>: 100%|██████████| 7/7 [00:00<00:00, 100.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD520>: 100%|██████████| 7/7 [00:00<00:00, 96.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDB20>: 100%|██████████| 7/7 [00:00<00:00, 92.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3910>: 100%|██████████| 7/7 [00:00<00:00, 88.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3F40>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005005_female_Asian_28.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003313_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD160>: 100%|██████████| 7/7 [00:00<00:00, 111.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7190>: 100%|██████████| 7/7 [00:00<00:00, 100.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3E80>: 100%|██████████| 7/7 [00:00<00:00, 98.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3040>: 100%|██████████| 7/7 [00:00<00:00, 67.64 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003031_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005004_female_Asian_30."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5B0>: 100%|██████████| 7/7 [00:00<00:00, 83.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE34C0>: 100%|██████████| 7/7 [00:00<00:00, 77.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3B80>: 100%|██████████| 7/7 [00:00<00:00, 85.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31AC0>: 100%|██████████| 7/7 [00:00<00:00, 76.40 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003001_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000698_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3400>: 100%|██████████| 7/7 [00:00<00:00, 73.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68130>: 100%|██████████| 7/7 [00:00<00:00, 99.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68D60>: 100%|██████████| 7/7 [00:00<00:00, 118.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C613A0>: 100%|██████████| 7/7 [00:00<00:00, 97.27 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8FD340>:  57%|█████▋    | 4/7 [00:00<00:00, 62.67 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006657_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000265_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3160>: 100%|██████████| 7/7 [00:00<00:00, 87.95 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31520>: 100%|██████████| 7/7 [00:00<00:00, 85.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCD0>: 100%|██████████| 7/7 [00:00<00:00, 92.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF14C0>: 100%|██████████| 7/7 [00:00<00:00, 93.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901850>:  14%|█▍        | 1/7 [00:00<00:00, 23.96 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005537_male_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003757_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FFC1A93A0>: 100%|██████████| 7/7 [00:00<00:00, 121.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FA0>: 100%|██████████| 7/7 [00:00<00:00, 121.14 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3880>: 100%|██████████| 7/7 [00:00<00:00, 79.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D688B0>: 100%|██████████| 7/7 [00:00<00:00, 66.10 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003823_male_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001725_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A20A0>: 100%|██████████| 7/7 [00:00<00:00, 126.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F36A0>: 100%|██████████| 7/7 [00:00<00:00, 106.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53250>: 100%|██████████| 7/7 [00:00<00:00, 97.16 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD940>: 100%|██████████| 7/7 [00:00<00:00, 84.82 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003648_male_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003854_female_Asian_47."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58760>: 100%|██████████| 7/7 [00:00<00:00, 121.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1400>: 100%|██████████| 7/7 [00:00<00:00, 86.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EE0>: 100%|██████████| 7/7 [00:00<00:00, 93.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A90>: 100%|██████████| 7/7 [00:00<00:00, 90.76 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003523_male_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006341_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58940>: 100%|██████████| 7/7 [00:00<00:00, 88.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD0A0>: 100%|██████████| 7/7 [00:00<00:00, 93.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53AC0>: 100%|██████████| 7/7 [00:00<00:00, 112.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E50>: 100%|██████████| 7/7 [00:00<00:00, 83.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EB0>:  43%|████▎     | 3/7 [00:00<00:00, 61.90 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001573_female_Asian_34.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005221_male_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A90>: 100%|██████████| 7/7 [00:00<00:00, 95.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1430>: 100%|██████████| 7/7 [00:00<00:00, 93.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6A0>: 100%|██████████| 7/7 [00:00<00:00, 93.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCCA0>: 100%|██████████| 7/7 [00:00<00:00, 92.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919A90>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001918_male_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001548_female_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6A0>: 100%|██████████| 7/7 [00:00<00:00, 94.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9191F0>: 100%|██████████| 7/7 [00:00<00:00, 126.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBC3D0>: 100%|██████████| 7/7 [00:00<00:00, 116.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3D60>: 100%|██████████| 7/7 [00:00<00:00, 142.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919C10>: 100%|██████████| 7/7 [00:00<00:00, 81.19 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006653_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003708_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9197F0>: 100%|██████████| 7/7 [00:00<00:00, 94.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919400>: 100%|██████████| 7/7 [00:00<00:00, 82.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE31C0>: 100%|██████████| 7/7 [00:00<00:00, 98.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCCD0>:  29%|██▊       | 2/7 [00:00<00:00, 101.72 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003456_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003245_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC4C0>: 100%|██████████| 7/7 [00:00<00:00, 114.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3A0>: 100%|██████████| 7/7 [00:00<00:00, 128.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1F70>: 100%|██████████| 7/7 [00:00<00:00, 98.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE36D0>: 100%|██████████| 7/7 [00:00<00:00, 92.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC910>:  14%|█▍        | 1/7 [00:00<00:00, 20.78 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004481_male_Asian_29.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001256_female_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A2100>: 100%|██████████| 7/7 [00:00<00:00, 131.20 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC850>: 100%|██████████| 7/7 [00:00<00:00, 98.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBC730>: 100%|██████████| 7/7 [00:00<00:00, 63.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D586D0>: 100%|██████████| 7/7 [00:00<00:00, 83.84 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003610_male_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003368_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53940>: 100%|██████████| 7/7 [00:00<00:00, 115.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC3D0>: 100%|██████████| 7/7 [00:00<00:00, 83.19 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD250>: 100%|██████████| 7/7 [00:00<00:00, 138.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3F10>: 100%|██████████| 7/7 [00:00<00:00, 81.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD700>:  14%|█▍        | 1/7 [00:00<00:00, 17.20 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000693_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001567_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D688B0>: 100%|██████████| 7/7 [00:00<00:00, 75.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A00>: 100%|██████████| 7/7 [00:00<00:00, 98.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECCA5B50>: 100%|██████████| 7/7 [00:00<00:00, 97.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1070>: 100%|██████████| 7/7 [00:00<00:00, 80.83 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001617_female_Asian_37.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003299_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BB20>: 100%|██████████| 7/7 [00:00<00:00, 98.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDB50>: 100%|██████████| 7/7 [00:00<00:00, 98.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BB20>: 100%|██████████| 7/7 [00:00<00:00, 103.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A60>: 100%|██████████| 7/7 [00:00<00:00, 77.53 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000573_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005503_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD700>: 100%|██████████| 7/7 [00:00<00:00, 73.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3F10>: 100%|██████████| 7/7 [00:00<00:00, 121.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDAC0>: 100%|██████████| 7/7 [00:00<00:00, 126.69 Samples/s]         \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53160>: 100%|██████████| 7/7 [00:00<00:00, 120.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61A60>: 100%|██████████| 7/7 [00:00<00:00, 122.89 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005210_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003509_male_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901100>: 100%|██████████| 7/7 [00:00<00:00, 86.06 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC6919D0>: 100%|██████████| 7/7 [00:00<00:00, 98.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61550>: 100%|██████████| 7/7 [00:00<00:00, 88.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D688B0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003228_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003268_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C160>: 100%|██████████| 7/7 [00:00<00:00, 98.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901E50>: 100%|██████████| 7/7 [00:00<00:00, 87.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD9D0>: 100%|██████████| 7/7 [00:00<00:00, 133.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58820>: 100%|██████████| 7/7 [00:00<00:00, 92.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61730>: 100%|██████████| 7/7 [00:00<00:00, 120.91 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001519_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000218_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3F10>: 100%|██████████| 7/7 [00:00<00:00, 116.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1CD0>: 100%|██████████| 7/7 [00:00<00:00, 109.66 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A00>: 100%|██████████| 7/7 [00:00<00:00, 73.70 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCA0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001716_male_Asian_27.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000285_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5B0>: 100%|██████████| 7/7 [00:00<00:00, 81.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD7C0>: 100%|██████████| 7/7 [00:00<00:00, 81.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53BB0>: 100%|██████████| 7/7 [00:00<00:00, 110.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>: 100%|██████████| 7/7 [00:00<00:00, 104.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC850>:  71%|███████▏  | 5/7 [00:00<00:00, 77.42 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004375_female_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003511_male_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D586A0>: 100%|██████████| 7/7 [00:00<00:00, 85.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC5B0>: 100%|██████████| 7/7 [00:00<00:00, 95.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53250>: 100%|██████████| 7/7 [00:00<00:00, 80.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1130>: 100%|██████████| 7/7 [00:00<00:00, 90.48 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001384_female_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006379_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC640>: 100%|██████████| 7/7 [00:00<00:00, 77.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC640>: 100%|██████████| 7/7 [00:00<00:00, 99.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535B0>: 100%|██████████| 7/7 [00:00<00:00, 122.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D90>: 100%|██████████| 7/7 [00:00<00:00, 93.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9199D0>: 100%|██████████| 7/7 [00:00<00:00, 119.04 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003112_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001141_male_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58730>: 100%|██████████| 7/7 [00:00<00:00, 105.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE38E0>: 100%|██████████| 7/7 [00:00<00:00, 92.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5E0>: 100%|██████████| 7/7 [00:00<00:00, 101.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3AC0>:  29%|██▊       | 2/7 [00:00<00:00, 39.50 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005138_male_Asian_30.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001317_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD730>: 100%|██████████| 7/7 [00:00<00:00, 92.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919340>: 100%|██████████| 7/7 [00:00<00:00, 110.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919C10>: 100%|██████████| 7/7 [00:00<00:00, 105.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68070>: 100%|██████████| 7/7 [00:00<00:00, 81.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7160>:  14%|█▍        | 1/7 [00:00<00:00, 23.89 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005266_male_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003278_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BB20>: 100%|██████████| 7/7 [00:00<00:00, 97.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C370>: 100%|██████████| 7/7 [00:00<00:00, 101.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919BB0>: 100%|██████████| 7/7 [00:00<00:00, 91.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA60>: 100%|██████████| 7/7 [00:00<00:00, 71.81 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006730_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006654_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A00>: 100%|██████████| 7/7 [00:00<00:00, 97.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901940>: 100%|██████████| 7/7 [00:00<00:00, 96.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198E0>: 100%|██████████| 7/7 [00:00<00:00, 121.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919820>: 100%|██████████| 7/7 [00:00<00:00, 90.83 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7C616D0>:  71%|███████▏  | 5/7 [00:00<00:00, 91.68 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001442_female_Asian_43.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003242_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF1AF0>: 100%|██████████| 7/7 [00:00<00:00, 109.23 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612B0>: 100%|██████████| 7/7 [00:00<00:00, 86.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F70>: 100%|██████████| 7/7 [00:00<00:00, 77.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1FD0>: 100%|██████████| 7/7 [00:00<00:00, 89.19 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004212_female_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001765_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9018E0>: 100%|██████████| 7/7 [00:00<00:00, 92.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1070>: 100%|██████████| 7/7 [00:00<00:00, 101.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A19D0>: 100%|██████████| 7/7 [00:00<00:00, 77.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF10>: 100%|██████████| 7/7 [00:00<00:00, 122.89 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006687_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003351_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC700>: 100%|██████████| 7/7 [00:00<00:00, 86.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD790>: 100%|██████████| 7/7 [00:00<00:00, 68.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919640>: 100%|██████████| 7/7 [00:00<00:00, 82.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9199A0>: 100%|██████████| 7/7 [00:00<00:00, 102.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCD0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006491_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005143_female_Asian_29."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1F0>: 100%|██████████| 7/7 [00:00<00:00, 86.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD040>: 100%|██████████| 7/7 [00:00<00:00, 97.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30D0>: 100%|██████████| 7/7 [00:00<00:00, 83.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9A0>: 100%|██████████| 7/7 [00:00<00:00, 80.92 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003378_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001167_male_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3190>: 100%|██████████| 7/7 [00:00<00:00, 78.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC730>: 100%|██████████| 7/7 [00:00<00:00, 87.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDB50>: 100%|██████████| 7/7 [00:00<00:00, 68.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD7F0>: 100%|██████████| 7/7 [00:00<00:00, 109.28 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003306_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006743_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E50>: 100%|██████████| 7/7 [00:00<00:00, 103.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D90>: 100%|██████████| 7/7 [00:00<00:00, 96.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38B0>: 100%|██████████| 7/7 [00:00<00:00, 71.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53AF0>: 100%|██████████| 7/7 [00:00<00:00, 99.70 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003152_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001752_male_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE50>: 100%|██████████| 7/7 [00:00<00:00, 90.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD040>: 100%|██████████| 7/7 [00:00<00:00, 138.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F34F0>: 100%|██████████| 7/7 [00:00<00:00, 102.10 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD640>: 100%|██████████| 7/7 [00:00<00:00, 89.93 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003877_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006148_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1DC0>: 100%|██████████| 7/7 [00:00<00:00, 39.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A13D0>: 100%|██████████| 7/7 [00:00<00:00, 39.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1C0>: 100%|██████████| 7/7 [00:00<00:00, 71.38 Samples/s]          \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5B0>:  57%|█████▋    | 4/7 [00:00<00:00, 39.69 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001048_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3220>: 100%|██████████| 7/7 [00:00<00:00, 67.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC400>: 100%|██████████| 7/7 [00:00<00:00, 84.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD520>: 100%|██████████| 7/7 [00:00<00:00, 88.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C616D0>:  14%|█▍        | 1/7 [00:00<00:00, 54.18 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006670_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000670_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11C0>: 100%|██████████| 7/7 [00:00<00:00, 115.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7D60>: 100%|██████████| 7/7 [00:00<00:00, 81.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC250>: 100%|██████████| 7/7 [00:00<00:00, 90.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD7F0>: 100%|██████████| 7/7 [00:00<00:00, 79.47 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001495-1_male_Asian_21.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005473_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7E66850>: 100%|██████████| 7/7 [00:00<00:00, 127.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612E0>: 100%|██████████| 7/7 [00:00<00:00, 112.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDB20>: 100%|██████████| 7/7 [00:00<00:00, 94.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC790>: 100%|██████████| 7/7 [00:00<00:00, 94.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC580>:  29%|██▊       | 2/7 [00:00<00:00, 45.98 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003812_male_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006504_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD610>: 100%|██████████| 7/7 [00:00<00:00, 93.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B550>: 100%|██████████| 7/7 [00:00<00:00, 92.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61DF0>: 100%|██████████| 7/7 [00:00<00:00, 70.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68070>: 100%|██████████| 7/7 [00:00<00:00, 81.39 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001599_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003703_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61490>: 100%|██████████| 7/7 [00:00<00:00, 91.12 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC070>: 100%|██████████| 7/7 [00:00<00:00, 83.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61DC0>: 100%|██████████| 7/7 [00:00<00:00, 63.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC310>:  71%|███████▏  | 5/7 [00:00<00:00, 63.59 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006258_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3D0>: 100%|██████████| 7/7 [00:00<00:00, 72.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919C10>: 100%|██████████| 7/7 [00:00<00:00, 128.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D90>: 100%|██████████| 7/7 [00:00<00:00, 114.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61AF0>: 100%|██████████| 7/7 [00:00<00:00, 107.87 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001252_male_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006375_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9018E0>: 100%|██████████| 7/7 [00:00<00:00, 101.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A00>: 100%|██████████| 7/7 [00:00<00:00, 39.69 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006131_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC640>: 100%|██████████| 7/7 [00:00<00:00, 46.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61280>: 100%|██████████| 7/7 [00:00<00:00, 73.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>: 100%|██████████| 7/7 [00:00<00:00, 99.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614C0>:  29%|██▊       | 2/7 [00:00<00:00, 70.74 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006239_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001645-1_female_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EE0>: 100%|██████████| 7/7 [00:00<00:00, 90.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9197F0>: 100%|██████████| 7/7 [00:00<00:00, 125.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901760>: 100%|██████████| 7/7 [00:00<00:00, 91.15 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC919760>: 100%|██████████| 7/7 [00:00<00:00, 85.41 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001574_female_Asian_34.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005433_female_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919BE0>: 100%|██████████| 7/7 [00:00<00:00, 110.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A00>: 100%|██████████| 7/7 [00:00<00:00, 92.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1F10>: 100%|██████████| 7/7 [00:00<00:00, 98.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC280>: 100%|██████████| 7/7 [00:00<00:00, 114.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD00>: 100%|██████████| 7/7 [00:00<00:00, 115.48 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001128_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000519_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD700>: 100%|██████████| 7/7 [00:00<00:00, 98.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC190>: 100%|██████████| 7/7 [00:00<00:00, 114.43 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC910>: 100%|██████████| 7/7 [00:00<00:00, 107.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F37C0>: 100%|██████████| 7/7 [00:00<00:00, 103.23 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005053_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003444_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1C0>: 100%|██████████| 7/7 [00:00<00:00, 99.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919220>: 100%|██████████| 7/7 [00:00<00:00, 89.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD970>: 100%|██████████| 7/7 [00:00<00:00, 117.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CA0>:  14%|█▍        | 1/7 [00:00<00:00, 23.17 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005146_female_Asian_40.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003537_male_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>: 100%|██████████| 7/7 [00:00<00:00, 99.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537C0>: 100%|██████████| 7/7 [00:00<00:00, 90.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC580>: 100%|██████████| 7/7 [00:00<00:00, 83.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C10>: 100%|██████████| 7/7 [00:00<00:00, 86.37 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003395_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000526_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53580>: 100%|██████████| 7/7 [00:00<00:00, 80.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53AC0>: 100%|██████████| 7/7 [00:00<00:00, 73.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53310>: 100%|██████████| 7/7 [00:00<00:00, 91.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD00>: 100%|██████████| 7/7 [00:00<00:00, 94.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53220>:  14%|█▍        | 1/7 [00:00<00:00, 22.19 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001619_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000754_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3490>: 100%|██████████| 7/7 [00:00<00:00, 86.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58B80>: 100%|██████████| 7/7 [00:00<00:00, 74.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38E0>: 100%|██████████| 7/7 [00:00<00:00, 104.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CA0>: 100%|██████████| 7/7 [00:00<00:00, 108.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3D90>: 100%|██████████| 7/7 [00:00<00:00, 110.06 Samples/s]                 \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006435_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000567_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53310>: 100%|██████████| 7/7 [00:00<00:00, 92.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3AC0>: 100%|██████████| 7/7 [00:00<00:00, 82.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1F10>: 100%|██████████| 7/7 [00:00<00:00, 92.10 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004444_male_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003243_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6D0>: 100%|██████████| 7/7 [00:00<00:00, 82.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1190>: 100%|██████████| 7/7 [00:00<00:00, 89.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE50>: 100%|██████████| 7/7 [00:00<00:00, 83.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1BC6A0>: 100%|██████████| 7/7 [00:00<00:00, 84.80 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006387_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001288_female_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9D0>: 100%|██████████| 7/7 [00:00<00:00, 105.24 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901970>: 100%|██████████| 7/7 [00:00<00:00, 90.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1F0>: 100%|██████████| 7/7 [00:00<00:00, 80.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1CD0>: 100%|██████████| 7/7 [00:00<00:00, 87.49 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000778_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003457_female_Asian_45."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7160>: 100%|██████████| 7/7 [00:00<00:00, 93.44 Samples/s] \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31E80>: 100%|██████████| 7/7 [00:00<00:00, 83.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC580>: 100%|██████████| 7/7 [00:00<00:00, 78.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A14F0>: 100%|██████████| 7/7 [00:00<00:00, 99.75 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005123_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000736_male_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B8B0>: 100%|██████████| 7/7 [00:00<00:00, 123.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D680A0>: 100%|██████████| 7/7 [00:00<00:00, 137.36 Samples/s]         \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612B0>: 100%|██████████| 7/7 [00:00<00:00, 121.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD30>: 100%|██████████| 7/7 [00:00<00:00, 100.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919130>:  57%|█████▋    | 4/7 [00:00<00:00, 61.96 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001292_female_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003167_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC250>: 100%|██████████| 7/7 [00:00<00:00, 83.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61610>: 100%|██████████| 7/7 [00:00<00:00, 67.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EE0>: 100%|██████████| 7/7 [00:00<00:00, 119.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C613A0>: 100%|██████████| 7/7 [00:00<00:00, 114.50 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC4C0>:  71%|███████▏  | 5/7 [00:00<00:00, 67.68 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006682_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006553_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1400>: 100%|██████████| 7/7 [00:00<00:00, 87.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7E66850>: 100%|██████████| 7/7 [00:00<00:00, 98.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61DF0>: 100%|██████████| 7/7 [00:00<00:00, 91.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919700>: 100%|██████████| 7/7 [00:00<00:00, 69.71 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006087_male_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006567_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61430>: 100%|██████████| 7/7 [00:00<00:00, 110.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A00>: 100%|██████████| 7/7 [00:00<00:00, 88.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B940>: 100%|██████████| 7/7 [00:00<00:00, 116.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F10>: 100%|██████████| 7/7 [00:00<00:00, 127.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D00>: 100%|██████████| 7/7 [00:00<00:00, 101.39 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005263_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006516_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61550>: 100%|██████████| 7/7 [00:00<00:00, 115.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C613A0>: 100%|██████████| 7/7 [00:00<00:00, 92.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61940>: 100%|██████████| 7/7 [00:00<00:00, 81.52 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006706_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001494-1_female_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC250>: 100%|██████████| 7/7 [00:00<00:00, 86.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA00>: 100%|██████████| 7/7 [00:00<00:00, 81.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919490>: 100%|██████████| 7/7 [00:00<00:00, 95.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EB0>: 100%|██████████| 7/7 [00:00<00:00, 93.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC2B0>:  29%|██▊       | 2/7 [00:00<00:00, 44.83 Samples/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001917_male_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001443_female_Asian_45."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDF70>: 100%|██████████| 7/7 [00:00<00:00, 122.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD340>: 100%|██████████| 7/7 [00:00<00:00, 93.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD280>: 100%|██████████| 7/7 [00:00<00:00, 83.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A13D0>: 100%|██████████| 7/7 [00:00<00:00, 82.52 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005447_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003415_male_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198E0>: 100%|██████████| 7/7 [00:00<00:00, 89.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD400>: 100%|██████████| 7/7 [00:00<00:00, 70.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A90>: 100%|██████████| 7/7 [00:00<00:00, 85.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC196EB0>: 100%|██████████| 7/7 [00:00<00:00, 125.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D531C0>:  57%|█████▋    | 4/7 [00:00<00:00, 78.41 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005478_female_Asian_43.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001341_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535B0>: 100%|██████████| 7/7 [00:00<00:00, 100.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9199D0>: 100%|██████████| 7/7 [00:00<00:00, 119.92 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537F0>: 100%|██████████| 7/7 [00:00<00:00, 109.64 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9199A0>: 100%|██████████| 7/7 [00:00<00:00, 76.76 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006461_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003367_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38E0>: 100%|██████████| 7/7 [00:00<00:00, 66.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3970>: 100%|██████████| 7/7 [00:00<00:00, 98.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919970>: 100%|██████████| 7/7 [00:00<00:00, 88.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53850>: 100%|██████████| 7/7 [00:00<00:00, 95.48 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536A0>:  14%|█▍        | 1/7 [00:00<00:00, 23.80 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005292_female_Asian_40.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006541_female_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3190>: 100%|██████████| 7/7 [00:00<00:00, 86.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1580>: 100%|██████████| 7/7 [00:00<00:00, 88.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3EE0>: 100%|██████████| 7/7 [00:00<00:00, 90.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919A30>: 100%|██████████| 7/7 [00:00<00:00, 85.03 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000672_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004468_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3EE0>: 100%|██████████| 7/7 [00:00<00:00, 86.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D534F0>: 100%|██████████| 7/7 [00:00<00:00, 100.64 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58B20>: 100%|██████████| 7/7 [00:00<00:00, 84.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1430>: 100%|██████████| 7/7 [00:00<00:00, 77.19 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003866_male_Asian_40.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000541_female_Asian_35."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58970>: 100%|██████████| 7/7 [00:00<00:00, 127.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9196A0>: 100%|██████████| 7/7 [00:00<00:00, 77.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919CD0>: 100%|██████████| 7/7 [00:00<00:00, 85.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD040>: 100%|██████████| 7/7 [00:00<00:00, 79.85 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001661_female_Asian_45.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003768_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919910>: 100%|██████████| 7/7 [00:00<00:00, 77.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDAC0>: 100%|██████████| 7/7 [00:00<00:00, 97.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901190>: 100%|██████████| 7/7 [00:00<00:00, 84.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901280>: 100%|██████████| 7/7 [00:00<00:00, 94.76 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000673_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000618_male_Asian_37."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919A30>: 100%|██████████| 7/7 [00:00<00:00, 81.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919040>: 100%|██████████| 7/7 [00:00<00:00, 105.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BE20>: 100%|██████████| 7/7 [00:00<00:00, 107.96 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC9190A0>: 100%|██████████| 7/7 [00:00<00:00, 130.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919040>:  71%|███████▏  | 5/7 [00:00<00:00, 65.99 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001079_female_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006355_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA00>: 100%|██████████| 7/7 [00:00<00:00, 90.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61E50>: 100%|██████████| 7/7 [00:00<00:00, 73.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919BE0>: 100%|██████████| 7/7 [00:00<00:00, 76.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA90>:  71%|███████▏  | 5/7 [00:00<00:00, 47.97 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006346_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1F0>: 100%|██████████| 7/7 [00:00<00:00, 62.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D60>: 100%|██████████| 7/7 [00:00<00:00, 96.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD640>: 100%|██████████| 7/7 [00:00<00:00, 87.74 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003056_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006564_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612B0>: 100%|██████████| 7/7 [00:00<00:00, 68.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9199A0>: 100%|██████████| 7/7 [00:00<00:00, 74.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD250>: 100%|██████████| 7/7 [00:00<00:00, 117.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919250>: 100%|██████████| 7/7 [00:00<00:00, 91.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6850>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005470_female_Asian_42.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006417_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C615B0>: 100%|██████████| 7/7 [00:00<00:00, 67.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A20A0>: 100%|██████████| 7/7 [00:00<00:00, 119.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD070>: 100%|██████████| 7/7 [00:00<00:00, 127.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614C0>: 100%|██████████| 7/7 [00:00<00:00, 105.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9019D0>:  43%|████▎     | 3/7 [00:00<00:00, 41.11 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001195_female_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001340_male_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68EB0>: 100%|██████████| 7/7 [00:00<00:00, 88.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD9A0>: 100%|██████████| 7/7 [00:00<00:00, 100.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC190>: 100%|██████████| 7/7 [00:00<00:00, 84.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68D00>: 100%|██████████| 7/7 [00:00<00:00, 89.50 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D681C0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001165_female_Asian_44.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005236_male_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDBB0>: 100%|██████████| 7/7 [00:00<00:00, 127.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD7F0>: 100%|██████████| 7/7 [00:00<00:00, 102.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD30>: 100%|██████████| 7/7 [00:00<00:00, 102.53 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC7F0>: 100%|██████████| 7/7 [00:00<00:00, 105.11 Samples/s]         \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9190D0>:  43%|████▎     | 3/7 [00:00<00:00, 54.92 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001254_female_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001979_female_Asian_29."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919610>: 100%|██████████| 7/7 [00:00<00:00, 106.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31E20>: 100%|██████████| 7/7 [00:00<00:00, 93.97 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919460>: 100%|██████████| 7/7 [00:00<00:00, 93.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58A30>: 100%|██████████| 7/7 [00:00<00:00, 103.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53160>: 100%|██████████| 7/7 [00:00<00:00, 150.84 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003066_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001883_female_Asian_49."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1430>: 100%|██████████| 7/7 [00:00<00:00, 89.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD970>:  57%|█████▋    | 4/7 [00:00<00:00,  7.33 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006062_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EE0>: 100%|██████████| 7/7 [00:00<00:00, 33.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC370>: 100%|██████████| 7/7 [00:00<00:00, 34.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD100>: 100%|██████████| 7/7 [00:00<00:00, 70.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EB0>: 100%|██████████| 7/7 [00:00<00:00, 97.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919CA0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003759_male_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000609_male_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF10>: 100%|██████████| 7/7 [00:00<00:00, 110.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC700>: 100%|██████████| 7/7 [00:00<00:00, 104.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC5B0>: 100%|██████████| 7/7 [00:00<00:00, 117.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDEE0>: 100%|██████████| 7/7 [00:00<00:00, 77.77 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001210_male_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001246_male_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1310>: 100%|██████████| 7/7 [00:00<00:00, 72.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9191F0>: 100%|██████████| 7/7 [00:00<00:00, 129.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A90>: 100%|██████████| 7/7 [00:00<00:00, 106.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC3D0>: 100%|██████████| 7/7 [00:00<00:00, 81.95 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005028_male_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005245_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3F10>: 100%|██████████| 7/7 [00:00<00:00, 87.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D531C0>: 100%|██████████| 7/7 [00:00<00:00, 116.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9D0>: 100%|██████████| 7/7 [00:00<00:00, 98.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919400>: 100%|██████████| 7/7 [00:00<00:00, 82.59 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004087_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000062_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31E50>: 100%|██████████| 7/7 [00:00<00:00, 94.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537C0>: 100%|██████████| 7/7 [00:00<00:00, 103.72 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA00>: 100%|██████████| 7/7 [00:00<00:00, 119.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536A0>: 100%|██████████| 7/7 [00:00<00:00, 82.17 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000598_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001091_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1610>: 100%|██████████| 7/7 [00:00<00:00, 67.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCFA0>: 100%|██████████| 7/7 [00:00<00:00, 105.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D90>: 100%|██████████| 7/7 [00:00<00:00, 101.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC790>: 100%|██████████| 7/7 [00:00<00:00, 88.36 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000664_male_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003467_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901CA0>: 100%|██████████| 7/7 [00:00<00:00, 83.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919340>: 100%|██████████| 7/7 [00:00<00:00, 86.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A30>: 100%|██████████| 7/7 [00:00<00:00, 82.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9018E0>: 100%|██████████| 7/7 [00:00<00:00, 93.80 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001826_female_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005458_male_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691B20>: 100%|██████████| 7/7 [00:00<00:00, 99.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A60>: 100%|██████████| 7/7 [00:00<00:00, 95.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919CD0>: 100%|██████████| 7/7 [00:00<00:00, 77.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD220>: 100%|██████████| 7/7 [00:00<00:00, 121.92 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001589_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006722_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF75B0>: 100%|██████████| 7/7 [00:00<00:00, 74.03 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A60>: 100%|██████████| 7/7 [00:00<00:00, 73.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901940>: 100%|██████████| 7/7 [00:00<00:00, 119.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612E0>: 100%|██████████| 7/7 [00:00<00:00, 123.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D90>: 100%|██████████| 7/7 [00:00<00:00, 101.12 Samples/s]                 \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001986_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003104_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D60>: 100%|██████████| 7/7 [00:00<00:00, 86.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE09D0>: 100%|██████████| 7/7 [00:00<00:00, 122.56 Samples/s]         \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901340>: 100%|██████████| 7/7 [00:00<00:00, 78.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE66D0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006652_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000019_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9197F0>: 100%|██████████| 7/7 [00:00<00:00, 104.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6F10>: 100%|██████████| 7/7 [00:00<00:00, 81.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919400>: 100%|██████████| 7/7 [00:00<00:00, 58.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6910>: 100%|██████████| 7/7 [00:00<00:00, 96.98 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001131_female_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004263_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECCA5E20>: 100%|██████████| 7/7 [00:00<00:00, 106.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A2100>: 100%|██████████| 7/7 [00:00<00:00, 89.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDBB0>: 100%|██████████| 7/7 [00:00<00:00, 116.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC196EB0>: 100%|██████████| 7/7 [00:00<00:00, 134.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB10100>: 100%|██████████| 7/7 [00:00<00:00, 102.20 Samples/s]         \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006402_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003222_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5B0>: 100%|██████████| 7/7 [00:00<00:00, 127.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1F70>: 100%|██████████| 7/7 [00:00<00:00, 125.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1190>: 100%|██████████| 7/7 [00:00<00:00, 86.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD250>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003748_male_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003514_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31FD0>: 100%|██████████| 7/7 [00:00<00:00, 66.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1AF0>: 100%|██████████| 7/7 [00:00<00:00, 69.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58760>: 100%|██████████| 7/7 [00:00<00:00, 84.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD610>: 100%|██████████| 7/7 [00:00<00:00, 88.29 Samples/s]                  \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000336_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001306_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C70>: 100%|██████████| 7/7 [00:00<00:00, 73.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901520>: 100%|██████████| 7/7 [00:00<00:00, 87.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD9A0>: 100%|██████████| 7/7 [00:00<00:00, 99.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D30>: 100%|██████████| 7/7 [00:00<00:00, 105.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F10>:  14%|█▍        | 1/7 [00:00<00:00, 18.91 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000212_female_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001800_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDB50>: 100%|██████████| 7/7 [00:00<00:00, 85.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA00>: 100%|██████████| 7/7 [00:00<00:00, 114.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1430>: 100%|██████████| 7/7 [00:00<00:00, 125.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EB0>: 100%|██████████| 7/7 [00:00<00:00, 89.51 Samples/s]                  \n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8F3FA0>: 100%|██████████| 7/7 [00:00<00:00, 126.03 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000645_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001390_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3700>: 100%|██████████| 7/7 [00:00<00:00, 77.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCDF0>: 100%|██████████| 7/7 [00:00<00:00, 82.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE0070>: 100%|██████████| 7/7 [00:00<00:00, 68.36 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003518_male_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003509-1_male_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9194F0>: 100%|██████████| 7/7 [00:00<00:00, 83.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9D0>: 100%|██████████| 7/7 [00:00<00:00, 85.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53280>: 100%|██████████| 7/7 [00:00<00:00, 39.43 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006235_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D539D0>: 100%|██████████| 7/7 [00:00<00:00, 33.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1310>: 100%|██████████| 7/7 [00:00<00:00, 38.93 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006057_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1580>: 100%|██████████| 7/7 [00:00<00:00, 35.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9193D0>: 100%|██████████| 7/7 [00:00<00:00, 103.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A30>: 100%|██████████| 7/7 [00:00<00:00, 133.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1FD0>: 100%|██████████| 7/7 [00:00<00:00, 92.89 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000719_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006446_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53AF0>: 100%|██████████| 7/7 [00:00<00:00, 80.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9019D0>: 100%|██████████| 7/7 [00:00<00:00, 82.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D539A0>: 100%|██████████| 7/7 [00:00<00:00, 95.86 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001201_male_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003733_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58760>: 100%|██████████| 7/7 [00:00<00:00, 96.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919C40>: 100%|██████████| 7/7 [00:00<00:00, 83.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1C0>: 100%|██████████| 7/7 [00:00<00:00, 90.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD250>: 100%|██████████| 7/7 [00:00<00:00, 82.95 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001240_female_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000600-1_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9193D0>: 100%|██████████| 7/7 [00:00<00:00, 87.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C40>: 100%|██████████| 7/7 [00:00<00:00, 102.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BE20>: 100%|██████████| 7/7 [00:00<00:00, 113.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58C40>: 100%|██████████| 7/7 [00:00<00:00, 96.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1C0>:  29%|██▊       | 2/7 [00:00<00:00, 35.15 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000001_female_Asian_45.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000631_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CA0>: 100%|██████████| 7/7 [00:00<00:00, 83.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A93A0>: 100%|██████████| 7/7 [00:00<00:00, 85.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD160>: 100%|██████████| 7/7 [00:00<00:00, 116.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE62E0>: 100%|██████████| 7/7 [00:00<00:00, 84.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614C0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006660_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001169_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919CD0>: 100%|██████████| 7/7 [00:00<00:00, 105.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68130>: 100%|██████████| 7/7 [00:00<00:00, 105.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61A60>: 100%|██████████| 7/7 [00:00<00:00, 95.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDFD0>: 100%|██████████| 7/7 [00:00<00:00, 104.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC400>:  43%|████▎     | 3/7 [00:00<00:00, 57.82 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001036_female_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001467_female_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9012E0>: 100%|██████████| 7/7 [00:00<00:00, 97.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE62B0>: 100%|██████████| 7/7 [00:00<00:00, 76.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919A30>: 100%|██████████| 7/7 [00:00<00:00, 109.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61610>: 100%|██████████| 7/7 [00:00<00:00, 100.08 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC901CA0>:  86%|████████▌ | 6/7 [00:00<00:00, 99.64 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005280_male_Asian_21.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000015_male_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC901CA0>: 100%|██████████| 7/7 [00:00<00:00, 112.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31CA0>: 100%|██████████| 7/7 [00:00<00:00, 84.39 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FECB1C160>: 100%|██████████| 7/7 [00:00<00:00, 78.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B970>: 100%|██████████| 7/7 [00:00<00:00, 83.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B670>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001545_female_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006455_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B100>: 100%|██████████| 7/7 [00:00<00:00, 98.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D586A0>: 100%|██████████| 7/7 [00:00<00:00, 99.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3F10>: 100%|██████████| 7/7 [00:00<00:00, 106.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58B20>: 100%|██████████| 7/7 [00:00<00:00, 82.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31D30>:  29%|██▊       | 2/7 [00:00<00:00, 44.99 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003578_female_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003433_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901520>: 100%|██████████| 7/7 [00:00<00:00, 79.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919160>: 100%|██████████| 7/7 [00:00<00:00, 91.46 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A13D0>: 100%|██████████| 7/7 [00:00<00:00, 66.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1820>: 100%|██████████| 7/7 [00:00<00:00, 90.03 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000684_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000646_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>: 100%|██████████| 7/7 [00:00<00:00, 135.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A14F0>: 100%|██████████| 7/7 [00:00<00:00, 92.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1490>: 100%|██████████| 7/7 [00:00<00:00, 85.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD940>: 100%|██████████| 7/7 [00:00<00:00, 88.46 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003430_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000558_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919670>: 100%|██████████| 7/7 [00:00<00:00, 86.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6250>: 100%|██████████| 7/7 [00:00<00:00, 106.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCCD0>: 100%|██████████| 7/7 [00:00<00:00, 102.10 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC70>: 100%|██████████| 7/7 [00:00<00:00, 112.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3BB0>: 100%|██████████| 7/7 [00:00<00:00, 116.93 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003983_male_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001226_male_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9197F0>: 100%|██████████| 7/7 [00:00<00:00, 138.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919A30>: 100%|██████████| 7/7 [00:00<00:00, 89.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F32B0>: 100%|██████████| 7/7 [00:00<00:00, 118.61 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919340>:  43%|████▎     | 3/7 [00:00<00:00, 58.35 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006369_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003356_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC100>: 100%|██████████| 7/7 [00:00<00:00, 93.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A30>: 100%|██████████| 7/7 [00:00<00:00, 84.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC400>: 100%|██████████| 7/7 [00:00<00:00, 107.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31520>: 100%|██████████| 7/7 [00:00<00:00, 93.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1CD0>: 100%|██████████| 7/7 [00:00<00:00, 127.88 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003194_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003106_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919BE0>: 100%|██████████| 7/7 [00:00<00:00, 107.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31E20>: 100%|██████████| 7/7 [00:00<00:00, 93.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD310>: 100%|██████████| 7/7 [00:00<00:00, 109.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1F0>:  57%|█████▋    | 4/7 [00:00<00:00, 73.25 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001406_male_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003379_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDEE0>: 100%|██████████| 7/7 [00:00<00:00, 91.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B50>: 100%|██████████| 7/7 [00:00<00:00, 84.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919E50>: 100%|██████████| 7/7 [00:00<00:00, 71.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7190>: 100%|██████████| 7/7 [00:00<00:00, 79.08 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000590_male_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001799_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1580>: 100%|██████████| 7/7 [00:00<00:00, 94.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBC3D0>: 100%|██████████| 7/7 [00:00<00:00, 93.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B100>: 100%|██████████| 7/7 [00:00<00:00, 82.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C3D0>: 100%|██████████| 7/7 [00:00<00:00, 84.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11C0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001476_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001772_male_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68EE0>: 100%|██████████| 7/7 [00:00<00:00, 103.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EE0>: 100%|██████████| 7/7 [00:00<00:00, 107.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A90>: 100%|██████████| 7/7 [00:00<00:00, 105.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3700>: 100%|██████████| 7/7 [00:00<00:00, 96.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901640>: 100%|██████████| 7/7 [00:00<00:00, 132.47 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000653_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005011_female_Asian_45."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D681C0>: 100%|██████████| 7/7 [00:00<00:00, 106.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58940>: 100%|██████████| 7/7 [00:00<00:00, 70.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919070>: 100%|██████████| 7/7 [00:00<00:00, 92.53 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001855_female_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005476_female_Asian_43."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1580>: 100%|██████████| 7/7 [00:00<00:00, 78.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE69A0>: 100%|██████████| 7/7 [00:00<00:00, 107.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A00>: 100%|██████████| 7/7 [00:00<00:00, 90.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61BB0>: 100%|██████████| 7/7 [00:00<00:00, 92.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE0580>:  14%|█▍        | 1/7 [00:00<00:00, 24.46 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005534_female_Asian_40.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006373_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE0790>: 100%|██████████| 7/7 [00:00<00:00, 106.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1AF0>: 100%|██████████| 7/7 [00:00<00:00, 102.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD400>: 100%|██████████| 7/7 [00:00<00:00, 85.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDEE0>: 100%|██████████| 7/7 [00:00<00:00, 88.49 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001046_female_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003990_male_Asian_43."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCD30>: 100%|██████████| 7/7 [00:00<00:00, 106.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCA30>: 100%|██████████| 7/7 [00:00<00:00, 63.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCB20>: 100%|██████████| 7/7 [00:00<00:00, 103.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCA00>: 100%|██████████| 7/7 [00:00<00:00, 117.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68D60>: 100%|██████████| 7/7 [00:00<00:00, 127.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCFA0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006715_male_Asian_21.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003458_female_Asian_46."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B940>: 100%|██████████| 7/7 [00:00<00:00, 125.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC1C0>: 100%|██████████| 7/7 [00:00<00:00, 85.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901190>: 100%|██████████| 7/7 [00:00<00:00, 64.20 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005030_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006098_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC2B0>: 100%|██████████| 7/7 [00:00<00:00, 96.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D681C0>: 100%|██████████| 7/7 [00:00<00:00, 75.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC940>: 100%|██████████| 7/7 [00:00<00:00, 102.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61730>: 100%|██████████| 7/7 [00:00<00:00, 88.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCD30>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000658_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001038-1_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F10>: 100%|██████████| 7/7 [00:00<00:00, 70.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61400>: 100%|██████████| 7/7 [00:00<00:00, 85.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919670>: 100%|██████████| 7/7 [00:00<00:00, 94.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53220>: 100%|██████████| 7/7 [00:00<00:00, 131.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC8B0>:  57%|█████▋    | 4/7 [00:00<00:00, 78.78 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000720_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000075_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919220>: 100%|██████████| 7/7 [00:00<00:00, 75.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC730>: 100%|██████████| 7/7 [00:00<00:00, 68.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC5E0>: 100%|██████████| 7/7 [00:00<00:00, 98.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D531C0>: 100%|██████████| 7/7 [00:00<00:00, 80.11 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003587_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006579_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC910>: 100%|██████████| 7/7 [00:00<00:00, 109.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53400>: 100%|██████████| 7/7 [00:00<00:00, 80.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>: 100%|██████████| 7/7 [00:00<00:00, 91.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53400>: 100%|██████████| 7/7 [00:00<00:00, 76.72 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003882_female_Asian_36.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005508_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D539A0>: 100%|██████████| 7/7 [00:00<00:00, 90.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC9D0>: 100%|██████████| 7/7 [00:00<00:00, 85.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC40>: 100%|██████████| 7/7 [00:00<00:00, 73.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537F0>: 100%|██████████| 7/7 [00:00<00:00, 107.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCAF0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000769_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001719_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3400>: 100%|██████████| 7/7 [00:00<00:00, 104.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCAC0>: 100%|██████████| 7/7 [00:00<00:00, 86.83 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F36D0>: 100%|██████████| 7/7 [00:00<00:00, 90.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1C0>: 100%|██████████| 7/7 [00:00<00:00, 117.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF14C0>:  14%|█▍        | 1/7 [00:00<00:00, 19.72 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005020_female_Asian_29.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006356_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B80>: 100%|██████████| 7/7 [00:00<00:00, 96.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC40>: 100%|██████████| 7/7 [00:00<00:00, 72.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC400>: 100%|██████████| 7/7 [00:00<00:00, 60.62 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7D539A0>: 100%|██████████| 7/7 [00:00<00:00, 102.20 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003371_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006631_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EB0>: 100%|██████████| 7/7 [00:00<00:00, 87.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3550>: 100%|██████████| 7/7 [00:00<00:00, 85.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA90>: 100%|██████████| 7/7 [00:00<00:00, 115.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919910>: 100%|██████████| 7/7 [00:00<00:00, 85.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3970>:  29%|██▊       | 2/7 [00:00<00:00, 40.93 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004432_female_Asian_43.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003557_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A60>: 100%|██████████| 7/7 [00:00<00:00, 120.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53130>: 100%|██████████| 7/7 [00:00<00:00, 117.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919250>: 100%|██████████| 7/7 [00:00<00:00, 85.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61AF0>: 100%|██████████| 7/7 [00:00<00:00, 70.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FA0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003264_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005408_male_Asian_28."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198B0>: 100%|██████████| 7/7 [00:00<00:00, 128.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537F0>: 100%|██████████| 7/7 [00:00<00:00, 83.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61AF0>: 100%|██████████| 7/7 [00:00<00:00, 102.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61790>: 100%|██████████| 7/7 [00:00<00:00, 101.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A93D0>:  43%|████▎     | 3/7 [00:00<00:00, 67.08 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000657_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006396_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>: 100%|██████████| 7/7 [00:00<00:00, 85.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3BE0>: 100%|██████████| 7/7 [00:00<00:00, 87.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61790>: 100%|██████████| 7/7 [00:00<00:00, 69.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3910>: 100%|██████████| 7/7 [00:00<00:00, 93.45 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001484_male_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006420_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53EE0>: 100%|██████████| 7/7 [00:00<00:00, 58.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC190>: 100%|██████████| 7/7 [00:00<00:00, 64.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A00>: 100%|██████████| 7/7 [00:00<00:00, 99.49 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919BE0>: 100%|██████████| 7/7 [00:00<00:00, 95.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCEB0>:  57%|█████▋    | 4/7 [00:00<00:00, 81.53 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006339_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000263_female_Asian_48."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919C10>: 100%|██████████| 7/7 [00:00<00:00, 115.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C70>: 100%|██████████| 7/7 [00:00<00:00, 81.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30D0>: 100%|██████████| 7/7 [00:00<00:00, 107.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EE0>: 100%|██████████| 7/7 [00:00<00:00, 101.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC940>: 100%|██████████| 7/7 [00:00<00:00, 117.19 Samples/s]         \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006943_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005151_female_Asian_32."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC9D0>: 100%|██████████| 7/7 [00:00<00:00, 121.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC1F0>: 100%|██████████| 7/7 [00:00<00:00, 84.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD00>: 100%|██████████| 7/7 [00:00<00:00, 86.52 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000637_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001926_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD400>: 100%|██████████| 7/7 [00:00<00:00, 111.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B6A0>: 100%|██████████| 7/7 [00:00<00:00, 87.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA00>: 100%|██████████| 7/7 [00:00<00:00, 67.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5E0>: 100%|██████████| 7/7 [00:00<00:00, 101.46 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005024_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003227_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCB80>: 100%|██████████| 7/7 [00:00<00:00, 89.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901CA0>: 100%|██████████| 7/7 [00:00<00:00, 84.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC430>: 100%|██████████| 7/7 [00:00<00:00, 85.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCAF0>: 100%|██████████| 7/7 [00:00<00:00, 78.40 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001294_male_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000607_female_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31FD0>: 100%|██████████| 7/7 [00:00<00:00, 76.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC3A0>: 100%|██████████| 7/7 [00:00<00:00, 95.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61610>: 100%|██████████| 7/7 [00:00<00:00, 82.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D60>: 100%|██████████| 7/7 [00:00<00:00, 116.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F10>:  29%|██▊       | 2/7 [00:00<00:00, 43.59 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000695_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000829_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61580>: 100%|██████████| 7/7 [00:00<00:00, 68.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCC40>: 100%|██████████| 7/7 [00:00<00:00, 80.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536D0>: 100%|██████████| 7/7 [00:00<00:00, 78.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FA0>: 100%|██████████| 7/7 [00:00<00:00, 71.79 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001140_female_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001702_female_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC7C0>: 100%|██████████| 7/7 [00:00<00:00, 98.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53AF0>: 100%|██████████| 7/7 [00:00<00:00, 115.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537C0>: 100%|██████████| 7/7 [00:00<00:00, 96.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198B0>: 100%|██████████| 7/7 [00:00<00:00, 116.57 Samples/s]         \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC640>:  14%|█▍        | 1/7 [00:00<00:00, 16.16 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000008_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000697_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919BE0>: 100%|██████████| 7/7 [00:00<00:00, 85.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DC0>: 100%|██████████| 7/7 [00:00<00:00, 91.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919820>: 100%|██████████| 7/7 [00:00<00:00, 121.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53580>: 100%|██████████| 7/7 [00:00<00:00, 103.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3760>:  29%|██▊       | 2/7 [00:00<00:00, 34.08 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004486_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000235_male_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD250>: 100%|██████████| 7/7 [00:00<00:00, 76.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53340>: 100%|██████████| 7/7 [00:00<00:00, 88.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC40>: 100%|██████████| 7/7 [00:00<00:00, 91.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FA0>: 100%|██████████| 7/7 [00:00<00:00, 85.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC2E0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001131-1_male_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006680_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B80>: 100%|██████████| 7/7 [00:00<00:00, 84.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDB20>: 100%|██████████| 7/7 [00:00<00:00, 106.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3910>: 100%|██████████| 7/7 [00:00<00:00, 106.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCCD0>: 100%|██████████| 7/7 [00:00<00:00, 138.64 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7DF14C0>:  43%|████▎     | 3/7 [00:00<00:00, 72.43 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001531_female_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003036_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D534F0>: 100%|██████████| 7/7 [00:00<00:00, 75.13 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD30>: 100%|██████████| 7/7 [00:00<00:00, 65.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D90>: 100%|██████████| 7/7 [00:00<00:00, 92.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F36D0>: 100%|██████████| 7/7 [00:00<00:00, 74.39 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001742_female_Asian_43.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006081_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53250>: 100%|██████████| 7/7 [00:00<00:00, 98.83 Samples/s] \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61880>: 100%|██████████| 7/7 [00:00<00:00, 90.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53340>: 100%|██████████| 7/7 [00:00<00:00, 82.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61550>: 100%|██████████| 7/7 [00:00<00:00, 111.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D60>:  29%|██▊       | 2/7 [00:00<00:00, 45.24 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006533_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001083_female_Asian_34."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612E0>: 100%|██████████| 7/7 [00:00<00:00, 87.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919640>: 100%|██████████| 7/7 [00:00<00:00, 107.81 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31F10>: 100%|██████████| 7/7 [00:00<00:00, 101.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9191F0>: 100%|██████████| 7/7 [00:00<00:00, 97.59 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006725_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006175_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919040>: 100%|██████████| 7/7 [00:00<00:00, 38.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCBB0>: 100%|██████████| 7/7 [00:00<00:00, 36.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691850>: 100%|██████████| 7/7 [00:00<00:00, 93.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901190>: 100%|██████████| 7/7 [00:00<00:00, 84.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC70>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001840_male_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003399_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901280>: 100%|██████████| 7/7 [00:00<00:00, 110.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B940>: 100%|██████████| 7/7 [00:00<00:00, 97.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BAC0>: 100%|██████████| 7/7 [00:00<00:00, 86.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCDF0>: 100%|██████████| 7/7 [00:00<00:00, 88.09 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006713_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006268_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC8B0>: 100%|██████████| 7/7 [00:00<00:00, 90.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCC40>: 100%|██████████| 7/7 [00:00<00:00, 117.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD30>: 100%|██████████| 7/7 [00:00<00:00, 106.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D30>: 100%|██████████| 7/7 [00:00<00:00, 72.64 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001827_male_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003515_male_Asian_49."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCAF0>: 100%|██████████| 7/7 [00:00<00:00, 92.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDB20>: 100%|██████████| 7/7 [00:00<00:00, 121.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919100>: 100%|██████████| 7/7 [00:00<00:00, 106.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EE0>: 100%|██████████| 7/7 [00:00<00:00, 116.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCC40>: 100%|██████████| 7/7 [00:00<00:00, 139.82 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005493_female_Asian_38.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006080_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B1C0>: 100%|██████████| 7/7 [00:00<00:00, 106.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C310>: 100%|██████████| 7/7 [00:00<00:00, 88.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C3D0>: 100%|██████████| 7/7 [00:00<00:00, 70.40 Samples/s]                  \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003955_male_Asian_41.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003269_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D688B0>: 100%|██████████| 7/7 [00:00<00:00, 109.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68C70>: 100%|██████████| 7/7 [00:00<00:00, 84.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDAC0>: 100%|██████████| 7/7 [00:00<00:00, 91.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCC10>: 100%|██████████| 7/7 [00:00<00:00, 104.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCC40>:  29%|██▊       | 2/7 [00:00<00:00, 47.39 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003871_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005558_male_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD700>: 100%|██████████| 7/7 [00:00<00:00, 92.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612E0>: 100%|██████████| 7/7 [00:00<00:00, 92.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD820>: 100%|██████████| 7/7 [00:00<00:00, 119.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE50>: 100%|██████████| 7/7 [00:00<00:00, 95.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD2B0>:  71%|███████▏  | 5/7 [00:00<00:00, 92.87 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003481_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005497_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD9A0>: 100%|██████████| 7/7 [00:00<00:00, 104.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC7C0>: 100%|██████████| 7/7 [00:00<00:00, 141.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCC70>: 100%|██████████| 7/7 [00:00<00:00, 87.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCB80>: 100%|██████████| 7/7 [00:00<00:00, 77.05 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000678_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006023_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC2B0>: 100%|██████████| 7/7 [00:00<00:00, 99.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC3D0>: 100%|██████████| 7/7 [00:00<00:00, 94.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919F70>: 100%|██████████| 7/7 [00:00<00:00, 95.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC7F0>: 100%|██████████| 7/7 [00:00<00:00, 94.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919670>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005411_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005083_female_Asian_27."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCC40>: 100%|██████████| 7/7 [00:00<00:00, 75.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC4C0>: 100%|██████████| 7/7 [00:00<00:00, 83.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53700>: 100%|██████████| 7/7 [00:00<00:00, 89.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCB20>: 100%|██████████| 7/7 [00:00<00:00, 82.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC610>:  14%|█▍        | 1/7 [00:00<00:00, 63.65 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000811_male_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000273_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD610>: 100%|██████████| 7/7 [00:00<00:00, 103.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53430>: 100%|██████████| 7/7 [00:00<00:00, 112.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3430>: 100%|██████████| 7/7 [00:00<00:00, 97.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3AC0>: 100%|██████████| 7/7 [00:00<00:00, 101.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A13D0>:  29%|██▊       | 2/7 [00:00<00:00, 37.53 Samples/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001027_male_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000269_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC850>: 100%|██████████| 7/7 [00:00<00:00, 70.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD610>: 100%|██████████| 7/7 [00:00<00:00, 95.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1190>: 100%|██████████| 7/7 [00:00<00:00, 94.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3880>: 100%|██████████| 7/7 [00:00<00:00, 100.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B50>:  14%|█▍        | 1/7 [00:00<00:00, 19.58 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001045_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001439_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3700>: 100%|██████████| 7/7 [00:00<00:00, 73.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3100>: 100%|██████████| 7/7 [00:00<00:00, 68.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E20>: 100%|██████████| 7/7 [00:00<00:00, 72.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE20>: 100%|██████████| 7/7 [00:00<00:00, 82.86 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006372_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001122_male_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11C0>: 100%|██████████| 7/7 [00:00<00:00, 81.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B50>: 100%|██████████| 7/7 [00:00<00:00, 84.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C10>: 100%|██████████| 7/7 [00:00<00:00, 81.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53130>:  43%|████▎     | 3/7 [00:00<00:00, 28.97 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003290_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9190A0>: 100%|██████████| 7/7 [00:00<00:00, 54.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919970>: 100%|██████████| 7/7 [00:00<00:00, 80.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCCD0>: 100%|██████████| 7/7 [00:00<00:00, 95.93 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003304_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006676_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53CA0>: 100%|██████████| 7/7 [00:00<00:00, 85.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A20A0>: 100%|██████████| 7/7 [00:00<00:00, 86.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53E50>: 100%|██████████| 7/7 [00:00<00:00, 89.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD430>: 100%|██████████| 7/7 [00:00<00:00, 74.18 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000040_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001773_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC970>: 100%|██████████| 7/7 [00:00<00:00, 82.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C3D0>: 100%|██████████| 7/7 [00:00<00:00, 68.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61A60>: 100%|██████████| 7/7 [00:00<00:00, 75.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE50>: 100%|██████████| 7/7 [00:00<00:00, 77.06 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003155_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003184_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD340>: 100%|██████████| 7/7 [00:00<00:00, 67.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614C0>: 100%|██████████| 7/7 [00:00<00:00, 74.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68EE0>: 100%|██████████| 7/7 [00:00<00:00, 70.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD220>:  57%|█████▋    | 4/7 [00:00<00:00, 44.37 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003343_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9199A0>: 100%|██████████| 7/7 [00:00<00:00, 65.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919E50>: 100%|██████████| 7/7 [00:00<00:00, 86.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD070>: 100%|██████████| 7/7 [00:00<00:00, 80.24 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005249_male_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003773_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919C40>: 100%|██████████| 7/7 [00:00<00:00, 65.34 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCAF0>: 100%|██████████| 7/7 [00:00<00:00, 86.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDBE0>: 100%|██████████| 7/7 [00:00<00:00, 69.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDBE0>: 100%|██████████| 7/7 [00:00<00:00, 82.84 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003831_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000731_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC220>: 100%|██████████| 7/7 [00:00<00:00, 89.76 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901400>: 100%|██████████| 7/7 [00:00<00:00, 83.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A93A0>: 100%|██████████| 7/7 [00:00<00:00, 88.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC970>: 100%|██████████| 7/7 [00:00<00:00, 107.56 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8FD1F0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003133_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006755_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7190>: 100%|██████████| 7/7 [00:00<00:00, 79.66 Samples/s]          \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECCA5E20>: 100%|██████████| 7/7 [00:00<00:00, 86.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901280>: 100%|██████████| 7/7 [00:00<00:00, 76.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9012E0>: 100%|██████████| 7/7 [00:00<00:00, 93.65 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003175_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000619_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCAF0>: 100%|██████████| 7/7 [00:00<00:00, 65.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC100>: 100%|██████████| 7/7 [00:00<00:00, 68.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD90>: 100%|██████████| 7/7 [00:00<00:00, 66.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF40>: 100%|██████████| 7/7 [00:00<00:00, 81.11 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001351_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006928_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC2E0>: 100%|██████████| 7/7 [00:00<00:00, 90.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D90>: 100%|██████████| 7/7 [00:00<00:00, 93.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE20>: 100%|██████████| 7/7 [00:00<00:00, 78.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF12E0>:  71%|███████▏  | 5/7 [00:00<00:00, 37.40 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005531_male_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1BC550>: 100%|██████████| 7/7 [00:00<00:00, 58.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD070>: 100%|██████████| 7/7 [00:00<00:00, 67.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD00>:  43%|████▎     | 3/7 [00:00<00:00, 46.51 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001879_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD370>: 100%|██████████| 7/7 [00:00<00:00, 70.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53280>: 100%|██████████| 7/7 [00:00<00:00, 65.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919400>:  43%|████▎     | 3/7 [00:00<00:00, 35.71 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006345_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C40>: 100%|██████████| 7/7 [00:00<00:00, 73.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1610>: 100%|██████████| 7/7 [00:00<00:00, 93.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919C10>: 100%|██████████| 7/7 [00:00<00:00, 100.72 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3700>:  29%|██▊       | 2/7 [00:00<00:00, 39.26 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005456_female_Asian_45.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000030_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A14F0>: 100%|██████████| 7/7 [00:00<00:00, 85.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3430>: 100%|██████████| 7/7 [00:00<00:00, 55.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD730>: 100%|██████████| 7/7 [00:00<00:00, 60.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1160>:  71%|███████▏  | 5/7 [00:00<00:00, 66.31 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000280_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D90>: 100%|██████████| 7/7 [00:00<00:00, 75.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198B0>: 100%|██████████| 7/7 [00:00<00:00, 69.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A14F0>: 100%|██████████| 7/7 [00:00<00:00, 92.47 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001295_female_Asian_21.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001704_male_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A22E0>: 100%|██████████| 7/7 [00:00<00:00, 85.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA30>: 100%|██████████| 7/7 [00:00<00:00, 79.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A30>: 100%|██████████| 7/7 [00:00<00:00, 109.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919040>: 100%|██████████| 7/7 [00:00<00:00, 93.58 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003592_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003374_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC400>: 100%|██████████| 7/7 [00:00<00:00, 82.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3EE0>: 100%|██████████| 7/7 [00:00<00:00, 73.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D00>: 100%|██████████| 7/7 [00:00<00:00, 68.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919070>: 100%|██████████| 7/7 [00:00<00:00, 91.62 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006637_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003615_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF1AC0>: 100%|██████████| 7/7 [00:00<00:00, 79.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC940>: 100%|██████████| 7/7 [00:00<00:00, 69.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>: 100%|██████████| 7/7 [00:00<00:00, 86.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198B0>: 100%|██████████| 7/7 [00:00<00:00, 83.75 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006470_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001259_male_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919070>: 100%|██████████| 7/7 [00:00<00:00, 59.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EB0>: 100%|██████████| 7/7 [00:00<00:00, 84.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD6D0>: 100%|██████████| 7/7 [00:00<00:00, 81.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC820>: 100%|██████████| 7/7 [00:00<00:00, 93.84 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004368_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001287_male_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCB20>: 100%|██████████| 7/7 [00:00<00:00, 97.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D30>: 100%|██████████| 7/7 [00:00<00:00, 76.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCE50>: 100%|██████████| 7/7 [00:00<00:00, 111.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC7C0>: 100%|██████████| 7/7 [00:00<00:00, 87.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC100>:  57%|█████▋    | 4/7 [00:00<00:00, 85.19 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006452_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001378_female_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCD90>: 100%|██████████| 7/7 [00:00<00:00, 101.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD970>: 100%|██████████| 7/7 [00:00<00:00, 107.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>: 100%|██████████| 7/7 [00:00<00:00, 93.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD790>: 100%|██████████| 7/7 [00:00<00:00, 74.88 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001829_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000651_male_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD790>: 100%|██████████| 7/7 [00:00<00:00, 114.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD7F0>: 100%|██████████| 7/7 [00:00<00:00, 111.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCFA0>: 100%|██████████| 7/7 [00:00<00:00, 111.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC40>: 100%|██████████| 7/7 [00:00<00:00, 112.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDEE0>:  71%|███████▏  | 5/7 [00:00<00:00, 75.13 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006384_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001010_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCD0>: 100%|██████████| 7/7 [00:00<00:00, 95.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61A60>: 100%|██████████| 7/7 [00:00<00:00, 70.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBC3D0>: 100%|██████████| 7/7 [00:00<00:00, 128.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68F40>: 100%|██████████| 7/7 [00:00<00:00, 140.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612B0>: 100%|██████████| 7/7 [00:00<00:00, 122.44 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003391_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001395_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614C0>: 100%|██████████| 7/7 [00:00<00:00, 86.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68160>: 100%|██████████| 7/7 [00:00<00:00, 109.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68F40>: 100%|██████████| 7/7 [00:00<00:00, 111.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612B0>:  71%|███████▏  | 5/7 [00:00<00:00, 75.54 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003366_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001029-1_female_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A60>: 100%|██████████| 7/7 [00:00<00:00, 84.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61A60>: 100%|██████████| 7/7 [00:00<00:00, 87.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC2B0>: 100%|██████████| 7/7 [00:00<00:00, 112.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC2E0>: 100%|██████████| 7/7 [00:00<00:00, 121.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9014C0>: 100%|██████████| 7/7 [00:00<00:00, 116.14 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000525_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003032_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53850>: 100%|██████████| 7/7 [00:00<00:00, 84.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901340>: 100%|██████████| 7/7 [00:00<00:00, 86.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C70>: 100%|██████████| 7/7 [00:00<00:00, 89.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD070>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005067_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005269_male_Asian_21."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD310>: 100%|██████████| 7/7 [00:00<00:00, 108.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901640>: 100%|██████████| 7/7 [00:00<00:00, 85.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3A0>: 100%|██████████| 7/7 [00:00<00:00, 71.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68160>: 100%|██████████| 7/7 [00:00<00:00, 86.08 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006465_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003850_female_Asian_47."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD730>: 100%|██████████| 7/7 [00:00<00:00, 96.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCBE0>: 100%|██████████| 7/7 [00:00<00:00, 103.90 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1C0>: 100%|██████████| 7/7 [00:00<00:00, 97.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58970>: 100%|██████████| 7/7 [00:00<00:00, 91.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1F0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000270_female_Asian_49.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005454_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9195E0>: 100%|██████████| 7/7 [00:00<00:00, 96.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDF70>: 100%|██████████| 7/7 [00:00<00:00, 76.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC190>: 100%|██████████| 7/7 [00:00<00:00, 88.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC4C0>: 100%|██████████| 7/7 [00:00<00:00, 103.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC730>:  14%|█▍        | 1/7 [00:00<00:00, 40.68 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001076_male_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003460_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38B0>: 100%|██████████| 7/7 [00:00<00:00, 93.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC370>: 100%|██████████| 7/7 [00:00<00:00, 90.56 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C40>: 100%|██████████| 7/7 [00:00<00:00, 78.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FD0>: 100%|██████████| 7/7 [00:00<00:00, 92.63 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003762_female_Asian_44.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003813_male_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3550>: 100%|██████████| 7/7 [00:00<00:00, 133.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1FD0>: 100%|██████████| 7/7 [00:00<00:00, 87.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3BE0>: 100%|██████████| 7/7 [00:00<00:00, 76.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9D0>: 100%|██████████| 7/7 [00:00<00:00, 88.50 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006469_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003851_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC4F0>: 100%|██████████| 7/7 [00:00<00:00, 97.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC0A0>: 100%|██████████| 7/7 [00:00<00:00, 100.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3430>: 100%|██████████| 7/7 [00:00<00:00, 37.74 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006060_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC100>: 100%|██████████| 7/7 [00:00<00:00, 35.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FA0>: 100%|██████████| 7/7 [00:00<00:00, 105.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3610>: 100%|██████████| 7/7 [00:00<00:00, 87.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC310>:  43%|████▎     | 3/7 [00:00<00:00, 66.32 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006363_male_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003860_male_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCD00>: 100%|██████████| 7/7 [00:00<00:00, 102.07 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC919B50>: 100%|██████████| 7/7 [00:00<00:00, 100.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC280>: 100%|██████████| 7/7 [00:00<00:00, 108.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC700>: 100%|██████████| 7/7 [00:00<00:00, 86.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC970>:  14%|█▍        | 1/7 [00:00<00:00, 21.51 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003157_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001449_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC670>: 100%|██████████| 7/7 [00:00<00:00, 98.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC910>: 100%|██████████| 7/7 [00:00<00:00, 114.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD9A0>: 100%|██████████| 7/7 [00:00<00:00, 94.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD6D0>: 100%|██████████| 7/7 [00:00<00:00, 84.81 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001541_female_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001555_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDEE0>: 100%|██████████| 7/7 [00:00<00:00, 74.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD640>: 100%|██████████| 7/7 [00:00<00:00, 80.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901190>: 100%|██████████| 7/7 [00:00<00:00, 74.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A60>: 100%|██████████| 7/7 [00:00<00:00, 126.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE20>:  14%|█▍        | 1/7 [00:00<00:00, 24.39 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001458_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003429_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7D533A0>: 100%|██████████| 7/7 [00:00<00:00, 102.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD340>: 100%|██████████| 7/7 [00:00<00:00, 84.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCBE0>: 100%|██████████| 7/7 [00:00<00:00, 106.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCE80>: 100%|██████████| 7/7 [00:00<00:00, 114.10 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006094_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006150_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53430>: 100%|██████████| 7/7 [00:00<00:00, 38.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9D0>: 100%|██████████| 7/7 [00:00<00:00, 37.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDDF0>: 100%|██████████| 7/7 [00:00<00:00, 86.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA312E0>: 100%|██████████| 7/7 [00:00<00:00, 88.80 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006415_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000621_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC2B0>: 100%|██████████| 7/7 [00:00<00:00, 105.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C618E0>: 100%|██████████| 7/7 [00:00<00:00, 101.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCC70>: 100%|██████████| 7/7 [00:00<00:00, 97.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C2E0>: 100%|██████████| 7/7 [00:00<00:00, 71.14 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000610_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006429_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31F10>: 100%|██████████| 7/7 [00:00<00:00, 89.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A93A0>: 100%|██████████| 7/7 [00:00<00:00, 95.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD340>: 100%|██████████| 7/7 [00:00<00:00, 131.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68340>: 100%|██████████| 7/7 [00:00<00:00, 84.46 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8FD2B0>:  29%|██▊       | 2/7 [00:00<00:00, 46.19 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001514_female_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006611_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31CA0>: 100%|██████████| 7/7 [00:00<00:00, 86.12 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901760>: 100%|██████████| 7/7 [00:00<00:00, 109.05 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC310>: 100%|██████████| 7/7 [00:00<00:00, 100.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD280>: 100%|██████████| 7/7 [00:00<00:00, 130.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD90>:  71%|███████▏  | 5/7 [00:00<00:00, 80.67 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000600_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003595_male_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901CA0>: 100%|██████████| 7/7 [00:00<00:00, 86.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68340>: 100%|██████████| 7/7 [00:00<00:00, 96.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC070>: 100%|██████████| 7/7 [00:00<00:00, 66.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD700>: 100%|██████████| 7/7 [00:00<00:00, 95.54 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004376_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006942_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC3D0>: 100%|██████████| 7/7 [00:00<00:00, 98.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD820>: 100%|██████████| 7/7 [00:00<00:00, 88.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E80>: 100%|██████████| 7/7 [00:00<00:00, 78.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC100>: 100%|██████████| 7/7 [00:00<00:00, 89.46 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006621_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001491_male_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D60>: 100%|██████████| 7/7 [00:00<00:00, 82.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A30>: 100%|██████████| 7/7 [00:00<00:00, 129.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC910>: 100%|██████████| 7/7 [00:00<00:00, 84.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919490>: 100%|██████████| 7/7 [00:00<00:00, 103.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD520>:  14%|█▍        | 1/7 [00:00<00:00, 26.57 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006237_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005046_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53E50>: 100%|██████████| 7/7 [00:00<00:00, 100.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1580>: 100%|██████████| 7/7 [00:00<00:00, 95.23 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EB0>: 100%|██████████| 7/7 [00:00<00:00, 101.15 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDFA0>: 100%|██████████| 7/7 [00:00<00:00, 107.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1130>:  57%|█████▋    | 4/7 [00:00<00:00, 69.29 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001641_male_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004482_male_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1F10>: 100%|██████████| 7/7 [00:00<00:00, 102.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC3D0>: 100%|██████████| 7/7 [00:00<00:00, 119.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919460>: 100%|██████████| 7/7 [00:00<00:00, 105.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A19D0>: 100%|██████████| 7/7 [00:00<00:00, 92.30 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCA60>:  14%|█▍        | 1/7 [00:00<00:00, 19.67 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001251_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001590_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB14250>: 100%|██████████| 7/7 [00:00<00:00, 69.64 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D587C0>: 100%|██████████| 7/7 [00:00<00:00, 87.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53160>: 100%|██████████| 7/7 [00:00<00:00, 97.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C160>: 100%|██████████| 7/7 [00:00<00:00, 89.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58BB0>:  29%|██▊       | 2/7 [00:00<00:00, 46.13 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000559_female_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003507_male_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FD0>: 100%|██████████| 7/7 [00:00<00:00, 108.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919CD0>: 100%|██████████| 7/7 [00:00<00:00, 93.66 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53580>: 100%|██████████| 7/7 [00:00<00:00, 93.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDCEB0>: 100%|██████████| 7/7 [00:00<00:00, 110.37 Samples/s]         \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53F40>:  29%|██▊       | 2/7 [00:00<00:00, 35.72 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006658_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001626_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B50>: 100%|██████████| 7/7 [00:00<00:00, 77.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53580>: 100%|██████████| 7/7 [00:00<00:00, 84.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9193D0>: 100%|██████████| 7/7 [00:00<00:00, 74.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53580>: 100%|██████████| 7/7 [00:00<00:00, 95.28 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003140_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006950_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901C70>: 100%|██████████| 7/7 [00:00<00:00, 98.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDEE0>: 100%|██████████| 7/7 [00:00<00:00, 128.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536A0>: 100%|██████████| 7/7 [00:00<00:00, 92.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCCA0>: 100%|██████████| 7/7 [00:00<00:00, 102.69 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC400>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001557_female_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003382_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901640>: 100%|██████████| 7/7 [00:00<00:00, 84.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA90>: 100%|██████████| 7/7 [00:00<00:00, 105.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535B0>: 100%|██████████| 7/7 [00:00<00:00, 88.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD00>: 100%|██████████| 7/7 [00:00<00:00, 89.78 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003804_female_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000628_male_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5B0>: 100%|██████████| 7/7 [00:00<00:00, 90.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC790>: 100%|██████████| 7/7 [00:00<00:00, 110.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C615B0>: 100%|██████████| 7/7 [00:00<00:00, 112.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCD0>: 100%|██████████| 7/7 [00:00<00:00, 91.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD940>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001286_female_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001737_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC3D0>: 100%|██████████| 7/7 [00:00<00:00, 81.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C616D0>: 100%|██████████| 7/7 [00:00<00:00, 83.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC370>: 100%|██████████| 7/7 [00:00<00:00, 75.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C612E0>: 100%|██████████| 7/7 [00:00<00:00, 76.70 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001748_female_Asian_47.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003575_male_Asian_43."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD940>: 100%|██████████| 7/7 [00:00<00:00, 79.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3A0>: 100%|██████████| 7/7 [00:00<00:00, 77.89 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDFA0>: 100%|██████████| 7/7 [00:00<00:00, 114.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31BE0>: 100%|██████████| 7/7 [00:00<00:00, 95.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58A30>: 100%|██████████| 7/7 [00:00<00:00, 128.24 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003344_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001622_female_Asian_40."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61730>: 100%|██████████| 7/7 [00:00<00:00, 106.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE80>: 100%|██████████| 7/7 [00:00<00:00, 113.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D681C0>: 100%|██████████| 7/7 [00:00<00:00, 71.07 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001592_male_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005517_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B940>: 100%|██████████| 7/7 [00:00<00:00, 74.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68FD0>: 100%|██████████| 7/7 [00:00<00:00, 71.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68D60>: 100%|██████████| 7/7 [00:00<00:00, 95.04 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C615B0>: 100%|██████████| 7/7 [00:00<00:00, 110.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536A0>:  14%|█▍        | 1/7 [00:00<00:00, 19.32 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000242_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005511_female_Asian_35."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58FA0>: 100%|██████████| 7/7 [00:00<00:00, 66.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58A00>: 100%|██████████| 7/7 [00:00<00:00, 109.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD640>: 100%|██████████| 7/7 [00:00<00:00, 121.75 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B550>: 100%|██████████| 7/7 [00:00<00:00, 108.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919340>: 100%|██████████| 7/7 [00:00<00:00, 136.88 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001190_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000262_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B50>: 100%|██████████| 7/7 [00:00<00:00, 67.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDF70>: 100%|██████████| 7/7 [00:00<00:00, 86.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53160>: 100%|██████████| 7/7 [00:00<00:00, 93.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6A0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001112_male_Asian_28.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006957_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A90>: 100%|██████████| 7/7 [00:00<00:00, 99.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919CD0>: 100%|██████████| 7/7 [00:00<00:00, 100.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9192B0>: 100%|██████████| 7/7 [00:00<00:00, 92.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53250>: 100%|██████████| 7/7 [00:00<00:00, 86.45 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003529_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000010_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A60>: 100%|██████████| 7/7 [00:00<00:00, 92.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919910>: 100%|██████████| 7/7 [00:00<00:00, 101.62 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901940>: 100%|██████████| 7/7 [00:00<00:00, 97.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901970>: 100%|██████████| 7/7 [00:00<00:00, 81.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919EE0>:  14%|█▍        | 1/7 [00:00<00:00, 38.01 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001804_female_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001762_male_Asian_40."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC790>: 100%|██████████| 7/7 [00:00<00:00, 105.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD340>: 100%|██████████| 7/7 [00:00<00:00, 85.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CD0>: 100%|██████████| 7/7 [00:00<00:00, 93.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3AF0>: 100%|██████████| 7/7 [00:00<00:00, 75.30 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000542_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003331_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901760>: 100%|██████████| 7/7 [00:00<00:00, 89.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901400>: 100%|██████████| 7/7 [00:00<00:00, 70.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A90>: 100%|██████████| 7/7 [00:00<00:00, 79.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9019D0>: 100%|██████████| 7/7 [00:00<00:00, 88.94 Samples/s]                  \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000025_female_Asian_49.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004442_male_Asian_40."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD280>: 100%|██████████| 7/7 [00:00<00:00, 82.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901100>: 100%|██████████| 7/7 [00:00<00:00, 59.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CD0>: 100%|██████████| 7/7 [00:00<00:00, 81.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C70>: 100%|██████████| 7/7 [00:00<00:00, 82.89 Samples/s]                  \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001975_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006712_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919340>: 100%|██████████| 7/7 [00:00<00:00, 77.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B80>: 100%|██████████| 7/7 [00:00<00:00, 111.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53760>: 100%|██████████| 7/7 [00:00<00:00, 76.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58DC0>: 100%|██████████| 7/7 [00:00<00:00, 95.53 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003053_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003472_female_Asian_48."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53580>: 100%|██████████| 7/7 [00:00<00:00, 62.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58BB0>: 100%|██████████| 7/7 [00:00<00:00, 90.97 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919BB0>: 100%|██████████| 7/7 [00:00<00:00, 85.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD610>: 100%|██████████| 7/7 [00:00<00:00, 91.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9190D0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001235_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003042_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3A0>: 100%|██████████| 7/7 [00:00<00:00, 109.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C190>: 100%|██████████| 7/7 [00:00<00:00, 88.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B040>: 100%|██████████| 7/7 [00:00<00:00, 114.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD610>: 100%|██████████| 7/7 [00:00<00:00, 96.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD100>:  29%|██▊       | 2/7 [00:00<00:00, 38.84 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005106_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005444_male_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA60>: 100%|██████████| 7/7 [00:00<00:00, 85.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC700>: 100%|██████████| 7/7 [00:00<00:00, 112.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD2B0>: 100%|██████████| 7/7 [00:00<00:00, 79.91 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68070>: 100%|██████████| 7/7 [00:00<00:00, 80.45 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005127_female_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000209_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1520>: 100%|██████████| 7/7 [00:00<00:00, 113.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D00>: 100%|██████████| 7/7 [00:00<00:00, 84.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31CA0>: 100%|██████████| 7/7 [00:00<00:00, 92.83 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61AF0>: 100%|██████████| 7/7 [00:00<00:00, 88.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD820>:  14%|█▍        | 1/7 [00:00<00:00, 24.54 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001017_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001098_male_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C615E0>: 100%|██████████| 7/7 [00:00<00:00, 117.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9A0>: 100%|██████████| 7/7 [00:00<00:00, 112.90 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C619A0>: 100%|██████████| 7/7 [00:00<00:00, 97.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A93D0>: 100%|██████████| 7/7 [00:00<00:00, 73.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBC3D0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006442_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005544_male_Asian_32."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68160>: 100%|██████████| 7/7 [00:00<00:00, 88.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A60>: 100%|██████████| 7/7 [00:00<00:00, 91.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A13D0>: 100%|██████████| 7/7 [00:00<00:00, 103.59 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7D58700>: 100%|██████████| 7/7 [00:00<00:00, 86.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A00>:  14%|█▍        | 1/7 [00:00<00:00, 22.19 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003865_male_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003071_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68D60>: 100%|██████████| 7/7 [00:00<00:00, 128.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B550>: 100%|██████████| 7/7 [00:00<00:00, 71.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A14F0>: 100%|██████████| 7/7 [00:00<00:00, 75.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1820>: 100%|██████████| 7/7 [00:00<00:00, 106.29 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001729_male_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006770_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCCD0>: 100%|██████████| 7/7 [00:00<00:00, 74.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCCD0>: 100%|██████████| 7/7 [00:00<00:00, 113.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53AF0>: 100%|██████████| 7/7 [00:00<00:00, 81.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D586D0>: 100%|██████████| 7/7 [00:00<00:00, 96.12 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003861_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000807_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1BB0>: 100%|██████████| 7/7 [00:00<00:00, 102.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCD0>: 100%|██████████| 7/7 [00:00<00:00, 120.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA00>: 100%|██████████| 7/7 [00:00<00:00, 104.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCD0>: 100%|██████████| 7/7 [00:00<00:00, 78.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58CA0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003734_male_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004267_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9018E0>: 100%|██████████| 7/7 [00:00<00:00, 106.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD160>: 100%|██████████| 7/7 [00:00<00:00, 120.81 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7D58D90>: 100%|██████████| 7/7 [00:00<00:00, 91.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9016D0>: 100%|██████████| 7/7 [00:00<00:00, 101.77 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FA0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001504_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001178_female_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC7F0>: 100%|██████████| 7/7 [00:00<00:00, 75.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE50>: 100%|██████████| 7/7 [00:00<00:00, 108.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919640>: 100%|██████████| 7/7 [00:00<00:00, 97.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCC40>: 100%|██████████| 7/7 [00:00<00:00, 100.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCBE0>:  14%|█▍        | 1/7 [00:00<00:00, 23.17 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004331_female_Asian_48.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003023_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC250>: 100%|██████████| 7/7 [00:00<00:00, 83.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919A90>: 100%|██████████| 7/7 [00:00<00:00, 73.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC7C0>: 100%|██████████| 7/7 [00:00<00:00, 103.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3D60>: 100%|██████████| 7/7 [00:00<00:00, 109.17 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E80>:  43%|████▎     | 3/7 [00:00<00:00, 72.72 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006724_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006522_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9195E0>: 100%|██████████| 7/7 [00:00<00:00, 93.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D90>: 100%|██████████| 7/7 [00:00<00:00, 88.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D589D0>: 100%|██████████| 7/7 [00:00<00:00, 99.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919340>: 100%|██████████| 7/7 [00:00<00:00, 97.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA00>:  29%|██▊       | 2/7 [00:00<00:00, 40.05 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003553_female_Asian_47.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006484_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3A90>: 100%|██████████| 7/7 [00:00<00:00, 90.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9196A0>: 100%|██████████| 7/7 [00:00<00:00, 80.86 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDF10>: 100%|██████████| 7/7 [00:00<00:00, 109.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198B0>: 100%|██████████| 7/7 [00:00<00:00, 97.82 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A60>:  57%|█████▋    | 4/7 [00:00<00:00, 70.23 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001513_male_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001611_male_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3A0>: 100%|██████████| 7/7 [00:00<00:00, 102.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD9A0>: 100%|██████████| 7/7 [00:00<00:00, 93.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53EE0>: 100%|██████████| 7/7 [00:00<00:00, 156.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3E20>: 100%|██████████| 7/7 [00:00<00:00, 79.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA30>:  43%|████▎     | 3/7 [00:00<00:00, 59.18 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006719_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000002_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FA0>: 100%|██████████| 7/7 [00:00<00:00, 87.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53400>: 100%|██████████| 7/7 [00:00<00:00, 90.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1AC0>: 100%|██████████| 7/7 [00:00<00:00, 125.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3C40>: 100%|██████████| 7/7 [00:00<00:00, 87.02 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000572_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006140_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDB50>: 100%|██████████| 7/7 [00:00<00:00, 39.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C340>: 100%|██████████| 7/7 [00:00<00:00, 43.33 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B040>: 100%|██████████| 7/7 [00:00<00:00, 126.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3D0>: 100%|██████████| 7/7 [00:00<00:00, 73.93 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53340>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006352_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000279_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1670>: 100%|██████████| 7/7 [00:00<00:00, 112.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B1C0>: 100%|██████████| 7/7 [00:00<00:00, 85.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD3A0>: 100%|██████████| 7/7 [00:00<00:00, 113.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68130>: 100%|██████████| 7/7 [00:00<00:00, 104.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68CA0>:  57%|█████▋    | 4/7 [00:00<00:00, 65.37 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000261_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001544_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11C0>: 100%|██████████| 7/7 [00:00<00:00, 96.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDB50>: 100%|██████████| 7/7 [00:00<00:00, 81.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C615E0>: 100%|██████████| 7/7 [00:00<00:00, 63.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1F10>: 100%|██████████| 7/7 [00:00<00:00, 97.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3940>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000748_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001335_male_Asian_30."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68EB0>: 100%|██████████| 7/7 [00:00<00:00, 136.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC640>: 100%|██████████| 7/7 [00:00<00:00, 104.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614F0>: 100%|██████████| 7/7 [00:00<00:00, 81.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A93D0>: 100%|██████████| 7/7 [00:00<00:00, 77.75 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001812_male_Asian_21.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001077_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68070>: 100%|██████████| 7/7 [00:00<00:00, 92.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1430>: 100%|██████████| 7/7 [00:00<00:00, 89.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31BE0>: 100%|██████████| 7/7 [00:00<00:00, 103.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C616A0>: 100%|██████████| 7/7 [00:00<00:00, 90.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D90>:  29%|██▊       | 2/7 [00:00<00:00, 39.60 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005149_male_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006483_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A17C0>: 100%|██████████| 7/7 [00:00<00:00, 85.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC190>: 100%|██████████| 7/7 [00:00<00:00, 103.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF75B0>: 100%|██████████| 7/7 [00:00<00:00, 95.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A60>: 100%|██████████| 7/7 [00:00<00:00, 110.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC790>:  57%|█████▋    | 4/7 [00:00<00:00, 84.55 Samples/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006671_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005417_female_Asian_43."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53EE0>: 100%|██████████| 7/7 [00:00<00:00, 99.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D531C0>: 100%|██████████| 7/7 [00:00<00:00, 80.97 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9012E0>: 100%|██████████| 7/7 [00:00<00:00, 96.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5E0>: 100%|██████████| 7/7 [00:00<00:00, 96.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9A0>:  14%|█▍        | 1/7 [00:00<00:00, 23.43 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001419_male_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001386_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD970>: 100%|██████████| 7/7 [00:00<00:00, 84.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDB50>: 100%|██████████| 7/7 [00:00<00:00, 136.20 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD00>: 100%|██████████| 7/7 [00:00<00:00, 92.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68F40>: 100%|██████████| 7/7 [00:00<00:00, 80.39 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005148_male_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000667_male_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD220>: 100%|██████████| 7/7 [00:00<00:00, 106.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD070>: 100%|██████████| 7/7 [00:00<00:00, 88.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D90>: 100%|██████████| 7/7 [00:00<00:00, 85.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D537C0>: 100%|██████████| 7/7 [00:00<00:00, 84.48 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005111_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003013_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD5E0>: 100%|██████████| 7/7 [00:00<00:00, 97.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9190A0>: 100%|██████████| 7/7 [00:00<00:00, 92.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3430>: 100%|██████████| 7/7 [00:00<00:00, 85.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCFA0>: 100%|██████████| 7/7 [00:00<00:00, 74.76 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000005_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001450_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCDF0>: 100%|██████████| 7/7 [00:00<00:00, 88.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC490>: 100%|██████████| 7/7 [00:00<00:00, 102.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38B0>: 100%|██████████| 7/7 [00:00<00:00, 126.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38E0>: 100%|██████████| 7/7 [00:00<00:00, 85.28 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004383_male_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003743_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CD0>: 100%|██████████| 7/7 [00:00<00:00, 65.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919700>: 100%|██████████| 7/7 [00:00<00:00, 131.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD280>: 100%|██████████| 7/7 [00:00<00:00, 91.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD250>: 100%|██████████| 7/7 [00:00<00:00, 72.50 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006456_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006172_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A60>: 100%|██████████| 7/7 [00:00<00:00, 40.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53310>: 100%|██████████| 7/7 [00:00<00:00, 39.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3190>: 100%|██████████| 7/7 [00:00<00:00, 79.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D90>: 100%|██████████| 7/7 [00:00<00:00, 99.48 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8F3AF0>:  29%|██▊       | 2/7 [00:00<00:00, 88.95 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000763_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001047-1_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919070>: 100%|██████████| 7/7 [00:00<00:00, 98.45 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3BE0>: 100%|██████████| 7/7 [00:00<00:00, 88.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDAC0>: 100%|██████████| 7/7 [00:00<00:00, 83.24 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA00>: 100%|██████████| 7/7 [00:00<00:00, 80.84 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001356_male_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004418_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53700>: 100%|██████████| 7/7 [00:00<00:00, 72.66 Samples/s]          \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD040>: 100%|██████████| 7/7 [00:00<00:00, 86.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3E80>: 100%|██████████| 7/7 [00:00<00:00, 81.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9199A0>: 100%|██████████| 7/7 [00:00<00:00, 108.83 Samples/s]                 \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003224_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006649_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B970>: 100%|██████████| 7/7 [00:00<00:00, 92.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C10>: 100%|██████████| 7/7 [00:00<00:00, 83.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1850>: 100%|██████████| 7/7 [00:00<00:00, 89.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BAC0>: 100%|██████████| 7/7 [00:00<00:00, 105.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B8B0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001135_male_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000635_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B20>: 100%|██████████| 7/7 [00:00<00:00, 109.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A30>: 100%|██████████| 7/7 [00:00<00:00, 100.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1310>: 100%|██████████| 7/7 [00:00<00:00, 84.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D688B0>: 100%|██████████| 7/7 [00:00<00:00, 92.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B820>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003041_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003287_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BAC0>: 100%|██████████| 7/7 [00:00<00:00, 93.50 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1400>: 100%|██████████| 7/7 [00:00<00:00, 94.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A00>: 100%|██████████| 7/7 [00:00<00:00, 89.73 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FC23A1C10>: 100%|██████████| 7/7 [00:00<00:00, 103.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3AF0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004470_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000533_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1310>: 100%|██████████| 7/7 [00:00<00:00, 104.26 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A13D0>: 100%|██████████| 7/7 [00:00<00:00, 92.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61280>: 100%|██████████| 7/7 [00:00<00:00, 107.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBCCA0>: 100%|██████████| 7/7 [00:00<00:00, 99.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC490>:  43%|████▎     | 3/7 [00:00<00:00, 58.62 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003784_female_Asian_47.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000516_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B1C0>: 100%|██████████| 7/7 [00:00<00:00, 107.23 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A60>: 100%|██████████| 7/7 [00:00<00:00, 101.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC850>: 100%|██████████| 7/7 [00:00<00:00, 82.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A13D0>: 100%|██████████| 7/7 [00:00<00:00, 83.83 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000378_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003807_male_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614C0>: 100%|██████████| 7/7 [00:00<00:00, 99.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919400>: 100%|██████████| 7/7 [00:00<00:00, 149.26 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58700>: 100%|██████████| 7/7 [00:00<00:00, 103.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919100>: 100%|██████████| 7/7 [00:00<00:00, 124.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1850>:  43%|████▎     | 3/7 [00:00<00:00, 43.88 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006668_male_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004318_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919340>: 100%|██████████| 7/7 [00:00<00:00, 74.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D90>: 100%|██████████| 7/7 [00:00<00:00, 81.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6A0>: 100%|██████████| 7/7 [00:00<00:00, 103.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9018E0>: 100%|██████████| 7/7 [00:00<00:00, 108.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D30>:  57%|█████▋    | 4/7 [00:00<00:00, 65.74 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003028_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000632_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58B20>: 100%|██████████| 7/7 [00:00<00:00, 93.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC250>: 100%|██████████| 7/7 [00:00<00:00, 99.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E20>: 100%|██████████| 7/7 [00:00<00:00, 98.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901B80>: 100%|██████████| 7/7 [00:00<00:00, 83.81 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003100_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003765_male_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53AC0>: 100%|██████████| 7/7 [00:00<00:00, 90.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919C40>: 100%|██████████| 7/7 [00:00<00:00, 111.34 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE80>: 100%|██████████| 7/7 [00:00<00:00, 96.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9D0>: 100%|██████████| 7/7 [00:00<00:00, 90.05 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001040_male_Asian_30.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006361_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C70>: 100%|██████████| 7/7 [00:00<00:00, 60.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919460>: 100%|██████████| 7/7 [00:00<00:00, 90.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3BB0>: 100%|██████████| 7/7 [00:00<00:00, 94.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D539D0>: 100%|██████████| 7/7 [00:00<00:00, 90.98 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3400>:  29%|██▊       | 2/7 [00:00<00:00, 47.25 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000656_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000775_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCFA0>: 100%|██████████| 7/7 [00:00<00:00, 113.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53160>: 100%|██████████| 7/7 [00:00<00:00, 97.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDB50>: 100%|██████████| 7/7 [00:00<00:00, 94.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6340>: 100%|██████████| 7/7 [00:00<00:00, 89.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE3850>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000232_male_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004325_female_Asian_42."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B80>: 100%|██████████| 7/7 [00:00<00:00, 106.02 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919670>: 100%|██████████| 7/7 [00:00<00:00, 72.69 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDBE0>: 100%|██████████| 7/7 [00:00<00:00, 61.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3E20>: 100%|██████████| 7/7 [00:00<00:00, 86.28 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003138_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001336_male_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A00>: 100%|██████████| 7/7 [00:00<00:00, 112.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53EE0>: 100%|██████████| 7/7 [00:00<00:00, 107.71 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901520>: 100%|██████████| 7/7 [00:00<00:00, 84.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCBB0>: 100%|██████████| 7/7 [00:00<00:00, 116.38 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006393_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006151_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A90>: 100%|██████████| 7/7 [00:00<00:00, 41.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EE0>: 100%|██████████| 7/7 [00:00<00:00, 51.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA00>: 100%|██████████| 7/7 [00:00<00:00, 85.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF10>: 100%|██████████| 7/7 [00:00<00:00, 107.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCEE0>:  29%|██▊       | 2/7 [00:00<00:00, 43.27 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001830_male_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005231_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D587C0>: 100%|██████████| 7/7 [00:00<00:00, 93.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F35B0>: 100%|██████████| 7/7 [00:00<00:00, 86.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30D0>: 100%|██████████| 7/7 [00:00<00:00, 83.63 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD280>: 100%|██████████| 7/7 [00:00<00:00, 109.28 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000815_female_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006086_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDCA0>: 100%|██████████| 7/7 [00:00<00:00, 68.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A60>: 100%|██████████| 7/7 [00:00<00:00, 129.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11F0>: 100%|██████████| 7/7 [00:00<00:00, 87.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1430>: 100%|██████████| 7/7 [00:00<00:00, 76.70 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001462_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006510_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EE0>: 100%|██████████| 7/7 [00:00<00:00, 130.71 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC99B820>: 100%|██████████| 7/7 [00:00<00:00, 95.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC9D0>: 100%|██████████| 7/7 [00:00<00:00, 82.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68E20>: 100%|██████████| 7/7 [00:00<00:00, 97.04 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003200_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001274_female_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD280>: 100%|██████████| 7/7 [00:00<00:00, 113.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD100>: 100%|██████████| 7/7 [00:00<00:00, 91.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD910>: 100%|██████████| 7/7 [00:00<00:00, 91.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A00>: 100%|██████████| 7/7 [00:00<00:00, 81.85 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000767_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006058_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6EB0>: 100%|██████████| 7/7 [00:00<00:00, 41.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD430>: 100%|██████████| 7/7 [00:00<00:00, 45.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C3D0>: 100%|██████████| 7/7 [00:00<00:00, 107.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD730>: 100%|██████████| 7/7 [00:00<00:00, 111.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C340>: 100%|██████████| 7/7 [00:00<00:00, 127.36 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004420_female_Asian_32.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003115_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614C0>: 100%|██████████| 7/7 [00:00<00:00, 130.76 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBC3D0>: 100%|██████████| 7/7 [00:00<00:00, 95.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D586D0>: 100%|██████████| 7/7 [00:00<00:00, 75.12 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000311_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003722_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F10>: 100%|██████████| 7/7 [00:00<00:00, 98.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD820>: 100%|██████████| 7/7 [00:00<00:00, 105.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD100>: 100%|██████████| 7/7 [00:00<00:00, 100.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C40>: 100%|██████████| 7/7 [00:00<00:00, 84.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD910>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005258_male_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003777_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B040>: 100%|██████████| 7/7 [00:00<00:00, 105.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53700>: 100%|██████████| 7/7 [00:00<00:00, 104.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD070>: 100%|██████████| 7/7 [00:00<00:00, 80.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3E20>: 100%|██████████| 7/7 [00:00<00:00, 91.06 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000654_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005422_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD00>: 100%|██████████| 7/7 [00:00<00:00, 92.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC280>: 100%|██████████| 7/7 [00:00<00:00, 114.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA00>: 100%|██████████| 7/7 [00:00<00:00, 86.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B8B0>: 100%|██████████| 7/7 [00:00<00:00, 107.45 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3460>:  29%|██▊       | 2/7 [00:00<00:00, 47.59 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006518_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006748_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC580>: 100%|██████████| 7/7 [00:00<00:00, 90.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3490>: 100%|██████████| 7/7 [00:00<00:00, 102.32 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3DF0>: 100%|██████████| 7/7 [00:00<00:00, 105.58 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919CD0>: 100%|██████████| 7/7 [00:00<00:00, 100.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3610>:  29%|██▊       | 2/7 [00:00<00:00, 35.92 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003315_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000758_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9195E0>: 100%|██████████| 7/7 [00:00<00:00, 95.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCEE0>: 100%|██████████| 7/7 [00:00<00:00, 68.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6220>: 100%|██████████| 7/7 [00:00<00:00, 97.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D534F0>: 100%|██████████| 7/7 [00:00<00:00, 91.41 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006353_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001183_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC250>: 100%|██████████| 7/7 [00:00<00:00, 89.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6190>: 100%|██████████| 7/7 [00:00<00:00, 77.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3AF0>: 100%|██████████| 7/7 [00:00<00:00, 75.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6340>: 100%|██████████| 7/7 [00:00<00:00, 92.30 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001173_male_Asian_30.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001233_male_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3400>: 100%|██████████| 7/7 [00:00<00:00, 105.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6430>: 100%|██████████| 7/7 [00:00<00:00, 87.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC280>: 100%|██████████| 7/7 [00:00<00:00, 83.52 Samples/s]          \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF10>: 100%|██████████| 7/7 [00:00<00:00, 129.76 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001269_female_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006129_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901280>: 100%|██████████| 7/7 [00:00<00:00, 38.92 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53310>: 100%|██████████| 7/7 [00:00<00:00, 41.01 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC250>: 100%|██████████| 7/7 [00:00<00:00, 93.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B160>: 100%|██████████| 7/7 [00:00<00:00, 88.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDD00>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001720_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005281_male_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6460>: 100%|██████████| 7/7 [00:00<00:00, 73.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCB20>: 100%|██████████| 7/7 [00:00<00:00, 98.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7E66820>: 100%|██████████| 7/7 [00:00<00:00, 90.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3CD0>: 100%|██████████| 7/7 [00:00<00:00, 110.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6910>:  43%|████▎     | 3/7 [00:00<00:00, 65.34 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000812_male_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000004_male_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6790>: 100%|██████████| 7/7 [00:00<00:00, 114.35 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F36D0>: 100%|██████████| 7/7 [00:00<00:00, 82.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDE20>: 100%|██████████| 7/7 [00:00<00:00, 97.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6AF0>: 100%|██████████| 7/7 [00:00<00:00, 74.69 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000553_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001096_male_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F10>: 100%|██████████| 7/7 [00:00<00:00, 82.27 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58AF0>: 100%|██████████| 7/7 [00:00<00:00, 67.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691850>: 100%|██████████| 7/7 [00:00<00:00, 91.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC5B0>: 100%|██████████| 7/7 [00:00<00:00, 103.19 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001710_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003060_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCB20>: 100%|██████████| 7/7 [00:00<00:00, 84.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6790>: 100%|██████████| 7/7 [00:00<00:00, 76.58 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F39A0>: 100%|██████████| 7/7 [00:00<00:00, 99.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38B0>: 100%|██████████| 7/7 [00:00<00:00, 94.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1CD0>:  43%|████▎     | 3/7 [00:00<00:00, 68.16 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005543_female_Asian_30.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000655_male_Asian_53."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A9340>: 100%|██████████| 7/7 [00:00<00:00, 101.77 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1F0>: 100%|██████████| 7/7 [00:00<00:00, 80.47 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE61F0>: 100%|██████████| 7/7 [00:00<00:00, 95.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECC98E80>: 100%|██████████| 7/7 [00:00<00:00, 101.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3550>:  57%|█████▋    | 4/7 [00:00<00:00, 81.22 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003085_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000675_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBC880>: 100%|██████████| 7/7 [00:00<00:00, 104.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31F10>: 100%|██████████| 7/7 [00:00<00:00, 85.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1F0>: 100%|██████████| 7/7 [00:00<00:00, 99.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C190>: 100%|██████████| 7/7 [00:00<00:00, 95.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD940>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003108_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001840-1_male_Asian_22."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1670>: 100%|██████████| 7/7 [00:00<00:00, 82.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3DF0>: 100%|██████████| 7/7 [00:00<00:00, 98.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D30>: 100%|██████████| 7/7 [00:00<00:00, 105.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3220>: 100%|██████████| 7/7 [00:00<00:00, 95.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA60>:  14%|█▍        | 1/7 [00:00<00:00, 18.75 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000268_male_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004425_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58AF0>: 100%|██████████| 7/7 [00:00<00:00, 83.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA312E0>: 100%|██████████| 7/7 [00:00<00:00, 105.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53910>: 100%|██████████| 7/7 [00:00<00:00, 111.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A00>: 100%|██████████| 7/7 [00:00<00:00, 120.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58A00>:  71%|███████▏  | 5/7 [00:00<00:00, 70.73 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005425_female_Asian_40.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003223_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3460>: 100%|██████████| 7/7 [00:00<00:00, 82.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC280>: 100%|██████████| 7/7 [00:00<00:00, 87.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCA00>: 100%|██████████| 7/7 [00:00<00:00, 77.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3400>: 100%|██████████| 7/7 [00:00<00:00, 101.51 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006099_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006421_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD2E0>: 100%|██████████| 7/7 [00:00<00:00, 105.67 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F32B0>: 100%|██████████| 7/7 [00:00<00:00, 84.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58820>: 100%|██████████| 7/7 [00:00<00:00, 92.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3D90>: 100%|██████████| 7/7 [00:00<00:00, 74.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919640>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003050_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006226_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6850>: 100%|██████████| 7/7 [00:00<00:00, 115.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58EE0>: 100%|██████████| 7/7 [00:00<00:00, 104.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30A0>: 100%|██████████| 7/7 [00:00<00:00, 86.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCEE0>: 100%|██████████| 7/7 [00:00<00:00, 83.48 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003109_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003775_female_Asian_29."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919910>: 100%|██████████| 7/7 [00:00<00:00, 111.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC490>: 100%|██████████| 7/7 [00:00<00:00, 88.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919E20>: 100%|██████████| 7/7 [00:00<00:00, 95.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABDC610>: 100%|██████████| 7/7 [00:00<00:00, 132.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6E20>:  57%|█████▋    | 4/7 [00:00<00:00, 60.53 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004308_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006079_male_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCB20>: 100%|██████████| 7/7 [00:00<00:00, 80.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919820>: 100%|██████████| 7/7 [00:00<00:00, 82.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC730>: 100%|██████████| 7/7 [00:00<00:00, 95.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC640>: 100%|██████████| 7/7 [00:00<00:00, 107.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC2E0>:  71%|███████▏  | 5/7 [00:00<00:00, 91.01 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006107_male_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001596_male_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6D0>: 100%|██████████| 7/7 [00:00<00:00, 102.18 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919160>: 100%|██████████| 7/7 [00:00<00:00, 76.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6670>: 100%|██████████| 7/7 [00:00<00:00, 70.34 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DC0>: 100%|██████████| 7/7 [00:00<00:00, 76.74 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001423_male_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000275_female_Asian_54."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6790>: 100%|██████████| 7/7 [00:00<00:00, 95.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F30D0>: 100%|██████████| 7/7 [00:00<00:00, 76.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDBE0>: 100%|██████████| 7/7 [00:00<00:00, 88.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDAC0>: 100%|██████████| 7/7 [00:00<00:00, 88.61 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001714_female_Asian_35.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000801_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E50>: 100%|██████████| 7/7 [00:00<00:00, 85.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901940>: 100%|██████████| 7/7 [00:00<00:00, 67.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9018E0>: 100%|██████████| 7/7 [00:00<00:00, 103.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6520>: 100%|██████████| 7/7 [00:00<00:00, 102.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDFD0>:  71%|███████▏  | 5/7 [00:00<00:00, 85.36 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004428_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001043-1_male_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C2E0>: 100%|██████████| 7/7 [00:00<00:00, 114.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD7F0>: 100%|██████████| 7/7 [00:00<00:00, 87.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECDF7B20>: 100%|██████████| 7/7 [00:00<00:00, 99.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C310>: 100%|██████████| 7/7 [00:00<00:00, 70.80 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001766_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006497_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31E80>: 100%|██████████| 7/7 [00:00<00:00, 94.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31520>: 100%|██████████| 7/7 [00:00<00:00, 76.74 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD610>: 100%|██████████| 7/7 [00:00<00:00, 104.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901760>: 100%|██████████| 7/7 [00:00<00:00, 90.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3AC0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005124_female_Asian_51.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003015_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B970>: 100%|██████████| 7/7 [00:00<00:00, 77.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691A60>: 100%|██████████| 7/7 [00:00<00:00, 83.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901A00>: 100%|██████████| 7/7 [00:00<00:00, 101.85 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901850>: 100%|██████████| 7/7 [00:00<00:00, 91.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3100>:  43%|████▎     | 3/7 [00:00<00:00, 62.50 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003005_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003059_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901CA0>: 100%|██████████| 7/7 [00:00<00:00, 88.58 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE64C0>: 100%|██████████| 7/7 [00:00<00:00, 106.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9016D0>: 100%|██████████| 7/7 [00:00<00:00, 90.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68E20>: 100%|██████████| 7/7 [00:00<00:00, 120.54 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58790>:  29%|██▊       | 2/7 [00:00<00:00, 39.02 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000021_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005295_male_Asian_29."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691B20>: 100%|██████████| 7/7 [00:00<00:00, 91.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E50>: 100%|██████████| 7/7 [00:00<00:00, 102.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901520>: 100%|██████████| 7/7 [00:00<00:00, 98.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68FD0>: 100%|██████████| 7/7 [00:00<00:00, 101.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1310>:  43%|████▎     | 3/7 [00:00<00:00, 76.67 Samples/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003795_male_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001164_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EE0>: 100%|██████████| 7/7 [00:00<00:00, 110.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B20>: 100%|██████████| 7/7 [00:00<00:00, 86.79 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53BB0>: 100%|██████████| 7/7 [00:00<00:00, 76.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1AF0>: 100%|██████████| 7/7 [00:00<00:00, 66.40 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003373_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006678_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D586A0>: 100%|██████████| 7/7 [00:00<00:00, 61.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD90>: 100%|██████████| 7/7 [00:00<00:00, 105.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3100>: 100%|██████████| 7/7 [00:00<00:00, 116.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC3D0>: 100%|██████████| 7/7 [00:00<00:00, 102.08 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38E0>:  29%|██▊       | 2/7 [00:00<00:00, 30.96 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004455_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001758_male_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53160>: 100%|██████████| 7/7 [00:00<00:00, 81.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC8B0>: 100%|██████████| 7/7 [00:00<00:00, 78.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3E20>: 100%|██████████| 7/7 [00:00<00:00, 127.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD90>: 100%|██████████| 7/7 [00:00<00:00, 73.66 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3BE0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003853_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005057_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61AF0>: 100%|██████████| 7/7 [00:00<00:00, 90.60 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61BB0>: 100%|██████████| 7/7 [00:00<00:00, 106.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C70>: 100%|██████████| 7/7 [00:00<00:00, 38.13 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006244_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC670>: 100%|██████████| 7/7 [00:00<00:00, 37.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53310>: 100%|██████████| 7/7 [00:00<00:00, 83.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53C70>: 100%|██████████| 7/7 [00:00<00:00, 66.13 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006259_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003725_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC4C0>: 100%|██████████| 7/7 [00:00<00:00, 91.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11C0>: 100%|██████████| 7/7 [00:00<00:00, 98.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1610>: 100%|██████████| 7/7 [00:00<00:00, 82.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCCA0>: 100%|██████████| 7/7 [00:00<00:00, 86.70 Samples/s]          \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919E50>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000577_female_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006726_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FECA31E50>: 100%|██████████| 7/7 [00:00<00:00, 119.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FD0>: 100%|██████████| 7/7 [00:00<00:00, 78.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919B50>: 100%|██████████| 7/7 [00:00<00:00, 105.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1C0>: 100%|██████████| 7/7 [00:00<00:00, 86.56 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001030_male_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004424_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF12E0>: 100%|██████████| 7/7 [00:00<00:00, 95.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDAC0>: 100%|██████████| 7/7 [00:00<00:00, 97.03 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDF70>: 100%|██████████| 7/7 [00:00<00:00, 93.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919160>: 100%|██████████| 7/7 [00:00<00:00, 102.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC700>:  29%|██▊       | 2/7 [00:00<00:00, 39.80 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001638_male_Asian_35.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004475_male_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC850>: 100%|██████████| 7/7 [00:00<00:00, 88.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533A0>: 100%|██████████| 7/7 [00:00<00:00, 75.72 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919640>: 100%|██████████| 7/7 [00:00<00:00, 76.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC2B0>: 100%|██████████| 7/7 [00:00<00:00, 91.92 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006584_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000293_female_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919C10>: 100%|██████████| 7/7 [00:00<00:00, 83.63 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6A0>: 100%|██████████| 7/7 [00:00<00:00, 112.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD30>: 100%|██████████| 7/7 [00:00<00:00, 93.30 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F10>: 100%|██████████| 7/7 [00:00<00:00, 85.44 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000561_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005153_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC1C0>: 100%|██████████| 7/7 [00:00<00:00, 71.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>: 100%|██████████| 7/7 [00:00<00:00, 117.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D90>: 100%|██████████| 7/7 [00:00<00:00, 111.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53430>: 100%|██████████| 7/7 [00:00<00:00, 95.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9190D0>:  57%|█████▋    | 4/7 [00:00<00:00, 73.42 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001080_female_Asian_23.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003239_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53160>: 100%|██████████| 7/7 [00:00<00:00, 99.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A30>: 100%|██████████| 7/7 [00:00<00:00, 100.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1CD0>: 100%|██████████| 7/7 [00:00<00:00, 87.61 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D535B0>: 100%|██████████| 7/7 [00:00<00:00, 104.06 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901940>:  43%|████▎     | 3/7 [00:00<00:00, 67.44 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001191_male_Asian_25.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000620_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901C70>: 100%|██████████| 7/7 [00:00<00:00, 107.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3BB0>: 100%|██████████| 7/7 [00:00<00:00, 109.05 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECCA5E20>: 100%|██████████| 7/7 [00:00<00:00, 89.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1BB0>: 100%|██████████| 7/7 [00:00<00:00, 134.83 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001266_female_Asian_24.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000629_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB14250>: 100%|██████████| 7/7 [00:00<00:00, 78.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B040>: 100%|██████████| 7/7 [00:00<00:00, 100.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38B0>: 100%|██████████| 7/7 [00:00<00:00, 76.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99B700>: 100%|██████████| 7/7 [00:00<00:00, 75.67 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001841_female_Asian_40.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000595_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31E80>: 100%|██████████| 7/7 [00:00<00:00, 93.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1820>: 100%|██████████| 7/7 [00:00<00:00, 68.42 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F33A0>: 100%|██████████| 7/7 [00:00<00:00, 88.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BAC0>: 100%|██████████| 7/7 [00:00<00:00, 98.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53700>:  57%|█████▋    | 4/7 [00:00<00:00, 90.10 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003967_male_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003417_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901C70>: 100%|██████████| 7/7 [00:00<00:00, 113.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC691AF0>: 100%|██████████| 7/7 [00:00<00:00, 85.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EB0>: 100%|██████████| 7/7 [00:00<00:00, 88.29 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9014C0>: 100%|██████████| 7/7 [00:00<00:00, 98.34 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58BB0>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005251_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005270_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7E66850>: 100%|██████████| 7/7 [00:00<00:00, 83.84 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53D00>: 100%|██████████| 7/7 [00:00<00:00, 99.19 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58E80>: 100%|██████████| 7/7 [00:00<00:00, 84.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F10>: 100%|██████████| 7/7 [00:00<00:00, 95.37 Samples/s]                  \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001607_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001282_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53B50>: 100%|██████████| 7/7 [00:00<00:00, 106.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC700>: 100%|██████████| 7/7 [00:00<00:00, 80.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53400>: 100%|██████████| 7/7 [00:00<00:00, 85.22 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCF40>: 100%|██████████| 7/7 [00:00<00:00, 91.20 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000381_female_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004390_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1EB0>: 100%|██████████| 7/7 [00:00<00:00, 97.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A60>: 100%|██████████| 7/7 [00:00<00:00, 75.53 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61D60>: 100%|██████████| 7/7 [00:00<00:00, 82.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C619A0>: 100%|██████████| 7/7 [00:00<00:00, 109.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC490>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006389_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001094_male_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FA0>: 100%|██████████| 7/7 [00:00<00:00, 80.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9190A0>: 100%|██████████| 7/7 [00:00<00:00, 142.75 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD280>: 100%|██████████| 7/7 [00:00<00:00, 83.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA00>:  57%|█████▋    | 4/7 [00:00<00:00, 28.93 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006520_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDF10>: 100%|██████████| 7/7 [00:00<00:00, 59.21 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCCD0>: 100%|██████████| 7/7 [00:00<00:00, 69.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3490>: 100%|██████████| 7/7 [00:00<00:00, 76.09 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006399_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001881_female_Asian_50."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53E50>: 100%|██████████| 7/7 [00:00<00:00, 82.81 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD280>: 100%|██████████| 7/7 [00:00<00:00, 99.96 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCE20>: 100%|██████████| 7/7 [00:00<00:00, 92.23 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3760>: 100%|██████████| 7/7 [00:00<00:00, 67.01 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006934_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001822_female_Asian_18."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC910>: 100%|██████████| 7/7 [00:00<00:00, 86.44 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3160>: 100%|██████████| 7/7 [00:00<00:00, 95.73 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3610>: 100%|██████████| 7/7 [00:00<00:00, 94.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3160>: 100%|██████████| 7/7 [00:00<00:00, 105.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B20>:  43%|████▎     | 3/7 [00:00<00:00, 62.16 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000007_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003172_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD220>: 100%|██████████| 7/7 [00:00<00:00, 120.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919220>: 100%|██████████| 7/7 [00:00<00:00, 82.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3700>: 100%|██████████| 7/7 [00:00<00:00, 70.39 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD700>: 100%|██████████| 7/7 [00:00<00:00, 119.86 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005518_female_Asian_49.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000240_male_Asian_57."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3D90>: 100%|██████████| 7/7 [00:00<00:00, 87.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA00>: 100%|██████████| 7/7 [00:00<00:00, 81.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC6A0>: 100%|██████████| 7/7 [00:00<00:00, 91.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61E50>: 100%|██████████| 7/7 [00:00<00:00, 71.05 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000574_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006382_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919790>: 100%|██████████| 7/7 [00:00<00:00, 91.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1430>: 100%|██████████| 7/7 [00:00<00:00, 88.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D589D0>: 100%|██████████| 7/7 [00:00<00:00, 71.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1430>: 100%|██████████| 7/7 [00:00<00:00, 96.56 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001868_female_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003190_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A11C0>: 100%|██████████| 7/7 [00:00<00:00, 93.93 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D587C0>: 100%|██████████| 7/7 [00:00<00:00, 84.07 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1C40>: 100%|██████████| 7/7 [00:00<00:00, 75.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53FD0>: 100%|██████████| 7/7 [00:00<00:00, 78.61 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001215_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001053_male_Asian_26."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901B80>: 100%|██████████| 7/7 [00:00<00:00, 95.86 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58C40>: 100%|██████████| 7/7 [00:00<00:00, 82.10 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1580>: 100%|██████████| 7/7 [00:00<00:00, 85.00 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58760>: 100%|██████████| 7/7 [00:00<00:00, 74.04 Samples/s]                  \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003362_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003479_male_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1820>: 100%|██████████| 7/7 [00:00<00:00, 66.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68160>: 100%|██████████| 7/7 [00:00<00:00, 67.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68EE0>: 100%|██████████| 7/7 [00:00<00:00, 60.09 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3430>:  57%|█████▋    | 4/7 [00:00<00:00, 60.98 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003267_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F32B0>: 100%|██████████| 7/7 [00:00<00:00, 74.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536D0>: 100%|██████████| 7/7 [00:00<00:00, 112.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53580>: 100%|██████████| 7/7 [00:00<00:00, 103.87 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38E0>:  71%|███████▏  | 5/7 [00:00<00:00, 83.67 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003799_female_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006212_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D688B0>: 100%|██████████| 7/7 [00:00<00:00, 82.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3FD0>: 100%|██████████| 7/7 [00:00<00:00, 95.12 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D68F40>: 100%|██████████| 7/7 [00:00<00:00, 96.96 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBCCA0>: 100%|██████████| 7/7 [00:00<00:00, 99.80 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC6919D0>:  29%|██▊       | 2/7 [00:00<00:00, 45.08 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001989_male_Asian_50.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000302_female_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901970>: 100%|██████████| 7/7 [00:00<00:00, 106.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901490>: 100%|██████████| 7/7 [00:00<00:00, 111.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C615E0>: 100%|██████████| 7/7 [00:00<00:00, 36.83 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006158_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53850>: 100%|██████████| 7/7 [00:00<00:00, 46.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53A60>: 100%|██████████| 7/7 [00:00<00:00, 128.68 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A30>: 100%|██████████| 7/7 [00:00<00:00, 101.75 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58A00>: 100%|██████████| 7/7 [00:00<00:00, 121.29 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000597_male_Asian_57.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001067_male_Asian_24."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53220>: 100%|██████████| 7/7 [00:00<00:00, 126.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D90>: 100%|██████████| 7/7 [00:00<00:00, 111.27 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31F70>: 100%|██████████| 7/7 [00:00<00:00, 76.96 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001530_female_Asian_22.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000730_female_Asian_51."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD070>: 100%|██████████| 7/7 [00:00<00:00, 72.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1670>: 100%|██████████| 7/7 [00:00<00:00, 118.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D60>: 100%|██████████| 7/7 [00:00<00:00, 111.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD100>: 100%|██████████| 7/7 [00:00<00:00, 88.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53910>:  14%|█▍        | 1/7 [00:00<00:00, 24.74 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001546_male_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005536_female_Asian_39."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D539A0>: 100%|██████████| 7/7 [00:00<00:00, 80.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1310>: 100%|██████████| 7/7 [00:00<00:00, 73.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD6D0>: 100%|██████████| 7/7 [00:00<00:00, 35.34 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006211_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9194F0>: 100%|██████████| 7/7 [00:00<00:00, 47.40 Samples/s]                \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53FD0>: 100%|██████████| 7/7 [00:00<00:00, 120.28 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9199D0>: 100%|██████████| 7/7 [00:00<00:00, 84.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCFA0>:  43%|████▎     | 3/7 [00:00<00:00, 62.10 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000738_female_Asian_53.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003669_male_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53CA0>: 100%|██████████| 7/7 [00:00<00:00, 89.62 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDF10>: 100%|██████████| 7/7 [00:00<00:00, 88.67 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3D60>: 100%|██████████| 7/7 [00:00<00:00, 67.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC580>: 100%|██████████| 7/7 [00:00<00:00, 103.32 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003862_male_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004489_male_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6AC0>: 100%|██████████| 7/7 [00:00<00:00, 133.93 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9191F0>: 100%|██████████| 7/7 [00:00<00:00, 81.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3490>: 100%|██████████| 7/7 [00:00<00:00, 109.56 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC5E0>: 100%|██████████| 7/7 [00:00<00:00, 68.42 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005129_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001337_female_Asian_25."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC3D0>: 100%|██████████| 7/7 [00:00<00:00, 87.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD30>: 100%|██████████| 7/7 [00:00<00:00, 95.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCEB0>: 100%|██████████| 7/7 [00:00<00:00, 36.75 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006136_male_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC580>: 100%|██████████| 7/7 [00:00<00:00, 39.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1A30>: 100%|██████████| 7/7 [00:00<00:00, 90.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC610>: 100%|██████████| 7/7 [00:00<00:00, 138.15 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD9D0>:  29%|██▊       | 2/7 [00:00<00:00, 34.12 Samples/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006714_male_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003707_female_Asian_59."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC400>: 100%|██████████| 7/7 [00:00<00:00, 79.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58B80>: 100%|██████████| 7/7 [00:00<00:00, 88.10 Samples/s]                  \n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FD7C61BB0>: 100%|██████████| 7/7 [00:00<00:00, 126.67 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9195E0>: 100%|██████████| 7/7 [00:00<00:00, 90.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7E66820>:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005407_female_Asian_26.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001517-1_female_Asian_23."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61580>: 100%|██████████| 7/7 [00:00<00:00, 93.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31F10>: 100%|██████████| 7/7 [00:00<00:00, 103.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECA31E50>: 100%|██████████| 7/7 [00:00<00:00, 101.14 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7DF1AF0>: 100%|██████████| 7/7 [00:00<00:00, 72.86 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001002_female_Asian_42.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005271_male_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919490>: 100%|██████████| 7/7 [00:00<00:00, 75.82 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901C70>: 100%|██████████| 7/7 [00:00<00:00, 145.49 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1BC550>: 100%|██████████| 7/7 [00:00<00:00, 108.43 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533A0>: 100%|██████████| 7/7 [00:00<00:00, 85.99 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9198B0>:  29%|██▊       | 2/7 [00:00<00:00, 43.77 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001774-2_male_Asian_52.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000046_male_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD610>: 100%|██████████| 7/7 [00:00<00:00, 111.38 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919A90>: 100%|██████████| 7/7 [00:00<00:00, 105.11 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C61610>: 100%|██████████| 7/7 [00:00<00:00, 62.16 Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=384x512 at 0x7F8FEC8FD9D0>:  29%|██▊       | 2/7 [00:00<00:00, 27.92 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003602_male_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C615E0>: 100%|██████████| 7/7 [00:00<00:00, 61.84 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53DF0>: 100%|██████████| 7/7 [00:00<00:00, 84.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD610>: 100%|██████████| 7/7 [00:00<00:00, 106.55 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC370>:  29%|██▊       | 2/7 [00:00<00:00, 45.04 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000255_female_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003360_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC640>: 100%|██████████| 7/7 [00:00<00:00, 110.70 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDA00>: 100%|██████████| 7/7 [00:00<00:00, 107.13 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C613D0>: 100%|██████████| 7/7 [00:00<00:00, 89.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7C614F0>: 100%|██████████| 7/7 [00:00<00:00, 74.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE65B0>:  14%|█▍        | 1/7 [00:00<00:00, 55.74 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003713_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003471_male_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD310>: 100%|██████████| 7/7 [00:00<00:00, 108.40 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE6940>: 100%|██████████| 7/7 [00:00<00:00, 89.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE03D0>: 100%|██████████| 7/7 [00:00<00:00, 113.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC99BA90>: 100%|██████████| 7/7 [00:00<00:00, 99.77 Samples/s] \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53250>:  29%|██▊       | 2/7 [00:00<00:00, 33.82 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000591_female_Asian_55.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000550_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE00D0>: 100%|██████████| 7/7 [00:00<00:00, 81.02 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE00A0>: 100%|██████████| 7/7 [00:00<00:00, 73.56 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D533A0>: 100%|██████████| 7/7 [00:00<00:00, 136.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C340>: 100%|██████████| 7/7 [00:00<00:00, 123.27 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53310>:  71%|███████▏  | 5/7 [00:00<00:00, 62.12 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003720_male_Asian_54.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003010_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53430>: 100%|██████████| 7/7 [00:00<00:00, 77.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE0430>: 100%|██████████| 7/7 [00:00<00:00, 87.37 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBC3D0>: 100%|██████████| 7/7 [00:00<00:00, 79.16 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC901940>: 100%|██████████| 7/7 [00:00<00:00, 110.85 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001014_male_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006176_female_Asian_19."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECBBC730>: 100%|██████████| 7/7 [00:00<00:00, 50.25 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD1F0>: 100%|██████████| 7/7 [00:00<00:00, 37.64 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FFC1A20A0>: 100%|██████████| 7/7 [00:00<00:00, 110.59 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D536D0>: 100%|██████████| 7/7 [00:00<00:00, 101.78 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE0A30>:  29%|██▊       | 2/7 [00:00<00:00, 34.19 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003921_male_Asian_59.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003406_male_Asian_55."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58F10>: 100%|██████████| 7/7 [00:00<00:00, 94.95 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58DC0>: 100%|██████████| 7/7 [00:00<00:00, 100.88 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FDB50>: 100%|██████████| 7/7 [00:00<00:00, 110.23 Samples/s]                 \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD910>: 100%|██████████| 7/7 [00:00<00:00, 119.54 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD640>: 100%|██████████| 7/7 [00:00<00:00, 112.86 Samples/s]         \n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003346_female_Asian_19.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000615_male_Asian_56."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D53340>: 100%|██████████| 7/7 [00:00<00:00, 106.65 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919160>: 100%|██████████| 7/7 [00:00<00:00, 102.91 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D30>: 100%|██████████| 7/7 [00:00<00:00, 81.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD280>:  14%|█▍        | 1/7 [00:00<00:00, 25.02 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003781_female_Asian_56.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005516_female_Asian_52."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919FD0>: 100%|██████████| 7/7 [00:00<00:00, 101.48 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919D30>: 100%|██████████| 7/7 [00:00<00:00, 93.74 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8FD610>: 100%|██████████| 7/7 [00:00<00:00, 113.41 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9191F0>: 100%|██████████| 7/7 [00:00<00:00, 111.46 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE0F70>:  57%|█████▋    | 4/7 [00:00<00:00, 68.30 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/004207_male_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/001148_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE03A0>: 100%|██████████| 7/7 [00:00<00:00, 88.52 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCD60>: 100%|██████████| 7/7 [00:00<00:00, 93.90 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC9193D0>: 100%|██████████| 7/7 [00:00<00:00, 64.24 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE0520>: 100%|██████████| 7/7 [00:00<00:00, 89.61 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003102_female_Asian_20.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003034_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABE0250>: 100%|██████████| 7/7 [00:00<00:00, 99.08 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FC23A1D90>: 100%|██████████| 7/7 [00:00<00:00, 89.94 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECC98E80>: 100%|██████████| 7/7 [00:00<00:00, 98.49 Samples/s]                  \n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC919CD0>: 100%|██████████| 7/7 [00:00<00:00, 77.65 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/006006_female_Asian_18.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005410_female_Asian_58."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCCCD0>: 100%|██████████| 7/7 [00:00<00:00, 120.36 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F38B0>: 100%|██████████| 7/7 [00:00<00:00, 95.57 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC580>: 100%|██████████| 7/7 [00:00<00:00, 112.87 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FD7D58D90>: 100%|██████████| 7/7 [00:00<00:00, 75.92 Samples/s]\n",
      "Executing Pipeline:   0%|          | 0/7 [00:00<?, ? Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/000513_female_Asian_58.Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/003199_female_Asian_20."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3D90>: 100%|██████████| 7/7 [00:00<00:00, 63.31 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FAABCC580>: 100%|██████████| 7/7 [00:00<00:00, 53.51 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FEC8F3B80>: 100%|██████████| 7/7 [00:00<00:00, 90.83 Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=384x512 at 0x7F8FECB1C160>: 100%|██████████| 7/7 [00:00<00:00, 125.03 Samples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 7 image(s) found.\n",
      "Output directory set to /opt/ml/input/data/train/images/005018_female_Asian_49."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 이미지 augmentation\n",
    "for profile in profiles:\n",
    "    id, gender, race, age = profile.split(\"_\")\n",
    "    if int(age) < 60: # 60 미만 data Augmentation / 60 이상은 7번 process 진행\n",
    "        # images = os.listdir(path + '/' + profile)\n",
    "        # images = [image for image in images if not image.startswith('.')]\n",
    "        p = Augmentor.Pipeline(source_directory=path + '/' + profile, output_directory=path + '/' + profile)\n",
    "        p.flip_left_right(probability=0.7)\n",
    "        p.rotate(0.8, max_left_rotation=25, max_right_rotation=25)\n",
    "        p.random_erasing(0.4,0.15)\n",
    "        p.random_brightness(0.6, 0.5, 1)\n",
    "        p.process()\n",
    "        p.process()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일명 rename\n",
    "\n",
    "for profile in profiles:\n",
    "    id, gender, race, age = profile.split(\"_\")\n",
    "    images = os.listdir(path + '/' + profile)\n",
    "    images = [image for image in images if not image.startswith('.')]\n",
    "    i_c = 1\n",
    "    m = 1\n",
    "    n = 1\n",
    "\n",
    "    for image in images:\n",
    "        if image[0] not in [\"i\", 'n', 'm']:\n",
    "            if 'incorrect' in image:\n",
    "                os.rename(path + '/' + profile + '/' + image, path + '/' + profile + '/' + 'incorrect_mask_A{}.jpg'.format(str(i_c)))\n",
    "                i_c += 1\n",
    "            elif 'mask' in image:\n",
    "                os.rename(path + '/' + profile + '/' + image, path + '/' + profile + '/' + 'mask_A{}.jpg'.format(str(m)))\n",
    "                m += 1\n",
    "            else:\n",
    "                os.rename(path + '/' + profile + '/' + image, path + '/' + profile + '/' + 'normal_A{}.jpg'.format(str(n)))\n",
    "                n += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
