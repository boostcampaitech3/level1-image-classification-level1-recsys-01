{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0842351a-2a97-4fd9-9b38-9b3d718b56e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(augmentation='BaseAugmentation', batch_size=32, criterion='cross_entropy', data_dir='/opt/ml/input/data/train/images', dataset='MaskBaseDataset', epochs=30, log_interval=20, lr=0.001, lr_decay_step=20, model='MyModel', model_dir='./model', name='exp', optimizer='Adam', resize=[224, 224], seed=42, val_ratio=0.2, valid_batch_size=400)\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "Loaded pretrained weights for efficientnet-b7\n",
      "Epoch[0/30](20/472) || training loss 1.905 || training accuracy 49.53% || lr 0.001\n",
      "Epoch[0/30](40/472) || training loss 1.158 || training accuracy 64.22% || lr 0.001\n",
      "Epoch[0/30](60/472) || training loss 0.8166 || training accuracy 73.91% || lr 0.001\n",
      "Epoch[0/30](80/472) || training loss 0.8548 || training accuracy 72.34% || lr 0.001\n",
      "Epoch[0/30](100/472) || training loss 0.7468 || training accuracy 76.41% || lr 0.001\n",
      "Epoch[0/30](120/472) || training loss 0.6199 || training accuracy 80.31% || lr 0.001\n",
      "Epoch[0/30](140/472) || training loss 0.6228 || training accuracy 79.38% || lr 0.001\n",
      "Epoch[0/30](160/472) || training loss 0.6836 || training accuracy 76.88% || lr 0.001\n",
      "Epoch[0/30](180/472) || training loss 0.6228 || training accuracy 80.16% || lr 0.001\n",
      "Epoch[0/30](200/472) || training loss 0.5128 || training accuracy 85.00% || lr 0.001\n",
      "Epoch[0/30](220/472) || training loss 0.6798 || training accuracy 75.94% || lr 0.001\n",
      "Epoch[0/30](240/472) || training loss 0.5351 || training accuracy 82.97% || lr 0.001\n",
      "Epoch[0/30](260/472) || training loss 0.4898 || training accuracy 84.53% || lr 0.001\n",
      "Epoch[0/30](280/472) || training loss 0.5572 || training accuracy 80.94% || lr 0.001\n",
      "Epoch[0/30](300/472) || training loss 0.4977 || training accuracy 83.28% || lr 0.001\n",
      "Epoch[0/30](320/472) || training loss 0.4998 || training accuracy 84.22% || lr 0.001\n",
      "Epoch[0/30](340/472) || training loss 0.5364 || training accuracy 82.34% || lr 0.001\n",
      "Epoch[0/30](360/472) || training loss 0.5226 || training accuracy 82.34% || lr 0.001\n",
      "Epoch[0/30](380/472) || training loss 0.5444 || training accuracy 81.88% || lr 0.001\n",
      "Epoch[0/30](400/472) || training loss 0.551 || training accuracy 82.50% || lr 0.001\n",
      "Epoch[0/30](420/472) || training loss 0.4827 || training accuracy 84.06% || lr 0.001\n",
      "Epoch[0/30](440/472) || training loss 0.5568 || training accuracy 82.03% || lr 0.001\n",
      "Epoch[0/30](460/472) || training loss 0.4137 || training accuracy 86.09% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 0.95%! saving the best model..\n",
      "[Val] acc : 0.95%, loss:  5.0 || best acc : 0.95%, best loss:  5.0\n",
      "\n",
      "Epoch[1/30](20/472) || training loss 0.548 || training accuracy 82.50% || lr 0.001\n",
      "Epoch[1/30](40/472) || training loss 0.386 || training accuracy 86.72% || lr 0.001\n",
      "Epoch[1/30](60/472) || training loss 0.5206 || training accuracy 81.72% || lr 0.001\n",
      "Epoch[1/30](80/472) || training loss 0.4216 || training accuracy 85.94% || lr 0.001\n",
      "Epoch[1/30](100/472) || training loss 0.3418 || training accuracy 88.59% || lr 0.001\n",
      "Epoch[1/30](120/472) || training loss 0.4756 || training accuracy 82.97% || lr 0.001\n",
      "Epoch[1/30](140/472) || training loss 0.4293 || training accuracy 87.50% || lr 0.001\n",
      "Epoch[1/30](160/472) || training loss 0.4866 || training accuracy 84.38% || lr 0.001\n",
      "Epoch[1/30](180/472) || training loss 0.4085 || training accuracy 85.62% || lr 0.001\n",
      "Epoch[1/30](200/472) || training loss 0.4128 || training accuracy 85.47% || lr 0.001\n",
      "Epoch[1/30](220/472) || training loss 0.4008 || training accuracy 85.00% || lr 0.001\n",
      "Epoch[1/30](240/472) || training loss 0.5053 || training accuracy 82.19% || lr 0.001\n",
      "Epoch[1/30](260/472) || training loss 0.4466 || training accuracy 85.78% || lr 0.001\n",
      "Epoch[1/30](280/472) || training loss 0.3501 || training accuracy 88.59% || lr 0.001\n",
      "Epoch[1/30](300/472) || training loss 0.3876 || training accuracy 87.66% || lr 0.001\n",
      "Epoch[1/30](320/472) || training loss 0.3922 || training accuracy 85.62% || lr 0.001\n",
      "Epoch[1/30](340/472) || training loss 0.4191 || training accuracy 86.56% || lr 0.001\n",
      "Epoch[1/30](360/472) || training loss 0.4796 || training accuracy 83.59% || lr 0.001\n",
      "Epoch[1/30](380/472) || training loss 0.3687 || training accuracy 87.66% || lr 0.001\n",
      "Epoch[1/30](400/472) || training loss 0.4839 || training accuracy 84.53% || lr 0.001\n",
      "Epoch[1/30](420/472) || training loss 0.4596 || training accuracy 84.38% || lr 0.001\n",
      "Epoch[1/30](440/472) || training loss 0.4751 || training accuracy 85.16% || lr 0.001\n",
      "Epoch[1/30](460/472) || training loss 0.379 || training accuracy 87.03% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 2.62%! saving the best model..\n",
      "[Val] acc : 2.62%, loss:  3.7 || best acc : 2.62%, best loss:  3.7\n",
      "\n",
      "Epoch[2/30](20/472) || training loss 0.345 || training accuracy 88.59% || lr 0.001\n",
      "Epoch[2/30](40/472) || training loss 0.3811 || training accuracy 87.19% || lr 0.001\n",
      "Epoch[2/30](60/472) || training loss 0.4238 || training accuracy 86.72% || lr 0.001\n",
      "Epoch[2/30](80/472) || training loss 0.3532 || training accuracy 89.06% || lr 0.001\n",
      "Epoch[2/30](100/472) || training loss 0.3094 || training accuracy 90.31% || lr 0.001\n",
      "Epoch[2/30](120/472) || training loss 0.4094 || training accuracy 84.22% || lr 0.001\n",
      "Epoch[2/30](140/472) || training loss 0.4049 || training accuracy 85.00% || lr 0.001\n",
      "Epoch[2/30](160/472) || training loss 0.3968 || training accuracy 87.03% || lr 0.001\n",
      "Epoch[2/30](180/472) || training loss 0.4484 || training accuracy 85.94% || lr 0.001\n",
      "Epoch[2/30](200/472) || training loss 0.3346 || training accuracy 89.53% || lr 0.001\n",
      "Epoch[2/30](220/472) || training loss 0.4122 || training accuracy 85.94% || lr 0.001\n",
      "Epoch[2/30](240/472) || training loss 0.397 || training accuracy 85.78% || lr 0.001\n",
      "Epoch[2/30](260/472) || training loss 0.3609 || training accuracy 87.50% || lr 0.001\n",
      "Epoch[2/30](280/472) || training loss 0.3838 || training accuracy 85.94% || lr 0.001\n",
      "Epoch[2/30](300/472) || training loss 0.4017 || training accuracy 87.19% || lr 0.001\n",
      "Epoch[2/30](320/472) || training loss 0.4187 || training accuracy 86.09% || lr 0.001\n",
      "Epoch[2/30](340/472) || training loss 0.4267 || training accuracy 86.25% || lr 0.001\n",
      "Epoch[2/30](360/472) || training loss 0.3516 || training accuracy 87.97% || lr 0.001\n",
      "Epoch[2/30](380/472) || training loss 0.3547 || training accuracy 86.88% || lr 0.001\n",
      "Epoch[2/30](400/472) || training loss 0.3429 || training accuracy 89.22% || lr 0.001\n",
      "Epoch[2/30](420/472) || training loss 0.3687 || training accuracy 87.97% || lr 0.001\n",
      "Epoch[2/30](440/472) || training loss 0.3216 || training accuracy 88.91% || lr 0.001\n",
      "Epoch[2/30](460/472) || training loss 0.3786 || training accuracy 85.62% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 28.25%! saving the best model..\n",
      "[Val] acc : 28.25%, loss:  2.0 || best acc : 28.25%, best loss:  2.0\n",
      "\n",
      "Epoch[3/30](20/472) || training loss 0.3259 || training accuracy 87.97% || lr 0.001\n",
      "Epoch[3/30](40/472) || training loss 0.3444 || training accuracy 87.97% || lr 0.001\n",
      "Epoch[3/30](60/472) || training loss 0.3336 || training accuracy 88.28% || lr 0.001\n",
      "Epoch[3/30](80/472) || training loss 0.3635 || training accuracy 88.12% || lr 0.001\n",
      "Epoch[3/30](100/472) || training loss 0.3912 || training accuracy 85.62% || lr 0.001\n",
      "Epoch[3/30](120/472) || training loss 0.2955 || training accuracy 89.69% || lr 0.001\n",
      "Epoch[3/30](140/472) || training loss 0.369 || training accuracy 88.12% || lr 0.001\n",
      "Epoch[3/30](160/472) || training loss 0.3533 || training accuracy 87.97% || lr 0.001\n",
      "Epoch[3/30](180/472) || training loss 0.3567 || training accuracy 88.75% || lr 0.001\n",
      "Epoch[3/30](200/472) || training loss 0.3706 || training accuracy 87.19% || lr 0.001\n",
      "Epoch[3/30](220/472) || training loss 0.3515 || training accuracy 88.28% || lr 0.001\n",
      "Epoch[3/30](240/472) || training loss 0.3681 || training accuracy 87.34% || lr 0.001\n",
      "Epoch[3/30](260/472) || training loss 0.3552 || training accuracy 87.19% || lr 0.001\n",
      "Epoch[3/30](280/472) || training loss 0.2639 || training accuracy 90.78% || lr 0.001\n",
      "Epoch[3/30](300/472) || training loss 0.2965 || training accuracy 89.22% || lr 0.001\n",
      "Epoch[3/30](320/472) || training loss 0.3444 || training accuracy 90.62% || lr 0.001\n",
      "Epoch[3/30](340/472) || training loss 0.3197 || training accuracy 88.59% || lr 0.001\n",
      "Epoch[3/30](360/472) || training loss 0.2867 || training accuracy 90.16% || lr 0.001\n",
      "Epoch[3/30](380/472) || training loss 0.3116 || training accuracy 89.53% || lr 0.001\n",
      "Epoch[3/30](400/472) || training loss 0.3745 || training accuracy 88.28% || lr 0.001\n",
      "Epoch[3/30](420/472) || training loss 0.3741 || training accuracy 86.88% || lr 0.001\n",
      "Epoch[3/30](440/472) || training loss 0.437 || training accuracy 85.94% || lr 0.001\n",
      "Epoch[3/30](460/472) || training loss 0.351 || training accuracy 88.91% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 61.75%! saving the best model..\n",
      "[Val] acc : 61.75%, loss:  1.1 || best acc : 61.75%, best loss:  1.1\n",
      "\n",
      "Epoch[4/30](20/472) || training loss 0.3542 || training accuracy 87.97% || lr 0.001\n",
      "Epoch[4/30](40/472) || training loss 0.3431 || training accuracy 88.28% || lr 0.001\n",
      "Epoch[4/30](60/472) || training loss 0.3356 || training accuracy 88.12% || lr 0.001\n",
      "Epoch[4/30](80/472) || training loss 0.337 || training accuracy 88.28% || lr 0.001\n",
      "Epoch[4/30](100/472) || training loss 0.331 || training accuracy 87.66% || lr 0.001\n",
      "Epoch[4/30](120/472) || training loss 0.36 || training accuracy 88.12% || lr 0.001\n",
      "Epoch[4/30](140/472) || training loss 0.3886 || training accuracy 87.81% || lr 0.001\n",
      "Epoch[4/30](160/472) || training loss 0.3203 || training accuracy 88.44% || lr 0.001\n",
      "Epoch[4/30](180/472) || training loss 0.3907 || training accuracy 87.81% || lr 0.001\n",
      "Epoch[4/30](200/472) || training loss 0.3574 || training accuracy 87.50% || lr 0.001\n",
      "Epoch[4/30](220/472) || training loss 0.3061 || training accuracy 89.69% || lr 0.001\n",
      "Epoch[4/30](240/472) || training loss 0.3489 || training accuracy 89.06% || lr 0.001\n",
      "Epoch[4/30](260/472) || training loss 0.3655 || training accuracy 87.81% || lr 0.001\n",
      "Epoch[4/30](280/472) || training loss 0.2895 || training accuracy 91.25% || lr 0.001\n",
      "Epoch[4/30](300/472) || training loss 0.3198 || training accuracy 90.62% || lr 0.001\n",
      "Epoch[4/30](320/472) || training loss 0.348 || training accuracy 88.59% || lr 0.001\n",
      "Epoch[4/30](340/472) || training loss 0.399 || training accuracy 86.72% || lr 0.001\n",
      "Epoch[4/30](360/472) || training loss 0.3831 || training accuracy 87.50% || lr 0.001\n",
      "Epoch[4/30](380/472) || training loss 0.3449 || training accuracy 90.47% || lr 0.001\n",
      "Epoch[4/30](400/472) || training loss 0.3874 || training accuracy 86.72% || lr 0.001\n",
      "Epoch[4/30](420/472) || training loss 0.3723 || training accuracy 87.50% || lr 0.001\n",
      "Epoch[4/30](440/472) || training loss 0.3261 || training accuracy 88.12% || lr 0.001\n",
      "Epoch[4/30](460/472) || training loss 0.3204 || training accuracy 88.12% || lr 0.001\n",
      "Calculating validation results...\n",
      "[Val] acc : 58.86%, loss:  1.2 || best acc : 61.75%, best loss:  1.1\n",
      "\n",
      "Epoch[5/30](20/472) || training loss 0.3646 || training accuracy 88.28% || lr 0.001\n",
      "Epoch[5/30](40/472) || training loss 0.3136 || training accuracy 89.38% || lr 0.001\n",
      "Epoch[5/30](60/472) || training loss 0.3294 || training accuracy 88.12% || lr 0.001\n",
      "Epoch[5/30](80/472) || training loss 0.3286 || training accuracy 88.91% || lr 0.001\n",
      "Epoch[5/30](100/472) || training loss 0.3064 || training accuracy 89.22% || lr 0.001\n",
      "Epoch[5/30](120/472) || training loss 0.3775 || training accuracy 87.34% || lr 0.001\n",
      "Epoch[5/30](140/472) || training loss 0.3325 || training accuracy 90.00% || lr 0.001\n",
      "Epoch[5/30](160/472) || training loss 0.3136 || training accuracy 87.66% || lr 0.001\n",
      "Epoch[5/30](180/472) || training loss 0.3252 || training accuracy 89.69% || lr 0.001\n",
      "Epoch[5/30](200/472) || training loss 0.3281 || training accuracy 88.44% || lr 0.001\n",
      "Epoch[5/30](220/472) || training loss 0.2556 || training accuracy 92.34% || lr 0.001\n",
      "Epoch[5/30](240/472) || training loss 0.3847 || training accuracy 86.41% || lr 0.001\n",
      "Epoch[5/30](260/472) || training loss 0.328 || training accuracy 88.75% || lr 0.001\n",
      "Epoch[5/30](280/472) || training loss 0.2716 || training accuracy 91.56% || lr 0.001\n",
      "Epoch[5/30](300/472) || training loss 0.2655 || training accuracy 91.09% || lr 0.001\n",
      "Epoch[5/30](320/472) || training loss 0.3275 || training accuracy 90.00% || lr 0.001\n",
      "Epoch[5/30](340/472) || training loss 0.2845 || training accuracy 89.38% || lr 0.001\n",
      "Epoch[5/30](360/472) || training loss 0.3501 || training accuracy 88.28% || lr 0.001\n",
      "Epoch[5/30](380/472) || training loss 0.3344 || training accuracy 87.50% || lr 0.001\n",
      "Epoch[5/30](400/472) || training loss 0.32 || training accuracy 88.75% || lr 0.001\n",
      "Epoch[5/30](420/472) || training loss 0.2882 || training accuracy 90.16% || lr 0.001\n",
      "Epoch[5/30](440/472) || training loss 0.3371 || training accuracy 88.28% || lr 0.001\n",
      "Epoch[5/30](460/472) || training loss 0.2514 || training accuracy 91.72% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 81.08%! saving the best model..\n",
      "[Val] acc : 81.08%, loss: 0.63 || best acc : 81.08%, best loss: 0.63\n",
      "\n",
      "Epoch[6/30](20/472) || training loss 0.2714 || training accuracy 90.31% || lr 0.001\n",
      "Epoch[6/30](40/472) || training loss 0.3312 || training accuracy 88.91% || lr 0.001\n",
      "Epoch[6/30](60/472) || training loss 0.2301 || training accuracy 92.50% || lr 0.001\n",
      "Epoch[6/30](80/472) || training loss 0.3254 || training accuracy 90.16% || lr 0.001\n",
      "Epoch[6/30](100/472) || training loss 0.2833 || training accuracy 89.69% || lr 0.001\n",
      "Epoch[6/30](120/472) || training loss 0.248 || training accuracy 92.03% || lr 0.001\n",
      "Epoch[6/30](140/472) || training loss 0.2533 || training accuracy 91.09% || lr 0.001\n",
      "Epoch[6/30](160/472) || training loss 0.2384 || training accuracy 92.34% || lr 0.001\n",
      "Epoch[6/30](180/472) || training loss 0.3236 || training accuracy 88.12% || lr 0.001\n",
      "Epoch[6/30](200/472) || training loss 0.3533 || training accuracy 88.44% || lr 0.001\n",
      "Epoch[6/30](220/472) || training loss 0.3048 || training accuracy 90.62% || lr 0.001\n",
      "Epoch[6/30](240/472) || training loss 0.3415 || training accuracy 87.19% || lr 0.001\n",
      "Epoch[6/30](260/472) || training loss 0.3546 || training accuracy 88.44% || lr 0.001\n",
      "Epoch[6/30](280/472) || training loss 0.3435 || training accuracy 87.97% || lr 0.001\n",
      "Epoch[6/30](300/472) || training loss 0.3263 || training accuracy 88.28% || lr 0.001\n",
      "Epoch[6/30](320/472) || training loss 0.3201 || training accuracy 89.69% || lr 0.001\n",
      "Epoch[6/30](340/472) || training loss 0.3399 || training accuracy 88.44% || lr 0.001\n",
      "Epoch[6/30](360/472) || training loss 0.3352 || training accuracy 87.97% || lr 0.001\n",
      "Epoch[6/30](380/472) || training loss 0.2937 || training accuracy 90.00% || lr 0.001\n",
      "Epoch[6/30](400/472) || training loss 0.347 || training accuracy 88.91% || lr 0.001\n",
      "Epoch[6/30](420/472) || training loss 0.3078 || training accuracy 88.91% || lr 0.001\n",
      "Epoch[6/30](440/472) || training loss 0.2848 || training accuracy 90.31% || lr 0.001\n",
      "Epoch[6/30](460/472) || training loss 0.2579 || training accuracy 89.84% || lr 0.001\n",
      "Calculating validation results...\n",
      "[Val] acc : 72.75%, loss: 0.73 || best acc : 81.08%, best loss: 0.63\n",
      "\n",
      "Epoch[7/30](20/472) || training loss 0.2957 || training accuracy 90.47% || lr 0.001\n",
      "Epoch[7/30](40/472) || training loss 0.2671 || training accuracy 89.69% || lr 0.001\n",
      "Epoch[7/30](60/472) || training loss 0.2987 || training accuracy 90.16% || lr 0.001\n",
      "Epoch[7/30](80/472) || training loss 0.2645 || training accuracy 91.25% || lr 0.001\n",
      "Epoch[7/30](100/472) || training loss 0.309 || training accuracy 88.75% || lr 0.001\n",
      "Epoch[7/30](120/472) || training loss 0.3125 || training accuracy 90.00% || lr 0.001\n",
      "Epoch[7/30](140/472) || training loss 0.3582 || training accuracy 88.44% || lr 0.001\n",
      "Epoch[7/30](160/472) || training loss 0.2738 || training accuracy 91.25% || lr 0.001\n",
      "Epoch[7/30](180/472) || training loss 0.29 || training accuracy 90.31% || lr 0.001\n",
      "Epoch[7/30](200/472) || training loss 0.2883 || training accuracy 91.56% || lr 0.001\n",
      "Epoch[7/30](220/472) || training loss 0.2544 || training accuracy 90.94% || lr 0.001\n",
      "Epoch[7/30](240/472) || training loss 0.3122 || training accuracy 89.22% || lr 0.001\n",
      "Epoch[7/30](260/472) || training loss 0.2738 || training accuracy 91.41% || lr 0.001\n",
      "Epoch[7/30](280/472) || training loss 0.2986 || training accuracy 90.78% || lr 0.001\n",
      "Epoch[7/30](300/472) || training loss 0.2996 || training accuracy 89.69% || lr 0.001\n",
      "Epoch[7/30](320/472) || training loss 0.2925 || training accuracy 91.25% || lr 0.001\n",
      "Epoch[7/30](340/472) || training loss 0.3325 || training accuracy 88.28% || lr 0.001\n",
      "Epoch[7/30](360/472) || training loss 0.3155 || training accuracy 89.22% || lr 0.001\n",
      "Epoch[7/30](380/472) || training loss 0.2894 || training accuracy 90.62% || lr 0.001\n",
      "Epoch[7/30](400/472) || training loss 0.2654 || training accuracy 90.78% || lr 0.001\n",
      "Epoch[7/30](420/472) || training loss 0.2989 || training accuracy 90.00% || lr 0.001\n",
      "Epoch[7/30](440/472) || training loss 0.2705 || training accuracy 90.78% || lr 0.001\n",
      "Epoch[7/30](460/472) || training loss 0.304 || training accuracy 89.22% || lr 0.001\n",
      "Calculating validation results...\n",
      "[Val] acc : 79.18%, loss: 0.49 || best acc : 81.08%, best loss: 0.49\n",
      "\n",
      "Epoch[8/30](20/472) || training loss 0.2251 || training accuracy 92.34% || lr 0.001\n",
      "Epoch[8/30](40/472) || training loss 0.275 || training accuracy 90.94% || lr 0.001\n",
      "Epoch[8/30](60/472) || training loss 0.2936 || training accuracy 90.47% || lr 0.001\n",
      "Epoch[8/30](80/472) || training loss 0.2449 || training accuracy 92.34% || lr 0.001\n",
      "Epoch[8/30](100/472) || training loss 0.2595 || training accuracy 91.09% || lr 0.001\n",
      "Epoch[8/30](120/472) || training loss 0.3018 || training accuracy 89.69% || lr 0.001\n",
      "Epoch[8/30](140/472) || training loss 0.2948 || training accuracy 88.12% || lr 0.001\n",
      "Epoch[8/30](160/472) || training loss 0.3038 || training accuracy 91.25% || lr 0.001\n",
      "Epoch[8/30](180/472) || training loss 0.3056 || training accuracy 90.62% || lr 0.001\n",
      "Epoch[8/30](200/472) || training loss 0.2435 || training accuracy 92.03% || lr 0.001\n",
      "Epoch[8/30](220/472) || training loss 0.2674 || training accuracy 91.09% || lr 0.001\n",
      "Epoch[8/30](240/472) || training loss 0.3115 || training accuracy 89.53% || lr 0.001\n",
      "Epoch[8/30](260/472) || training loss 0.2619 || training accuracy 90.31% || lr 0.001\n",
      "Epoch[8/30](280/472) || training loss 0.2978 || training accuracy 89.53% || lr 0.001\n",
      "Epoch[8/30](300/472) || training loss 0.3168 || training accuracy 88.91% || lr 0.001\n",
      "Epoch[8/30](320/472) || training loss 0.3021 || training accuracy 90.31% || lr 0.001\n",
      "Epoch[8/30](340/472) || training loss 0.2849 || training accuracy 89.06% || lr 0.001\n",
      "Epoch[8/30](360/472) || training loss 0.3078 || training accuracy 88.44% || lr 0.001\n",
      "Epoch[8/30](380/472) || training loss 0.3315 || training accuracy 88.59% || lr 0.001\n",
      "Epoch[8/30](400/472) || training loss 0.2369 || training accuracy 92.34% || lr 0.001\n",
      "Epoch[8/30](420/472) || training loss 0.2375 || training accuracy 91.25% || lr 0.001\n",
      "Epoch[8/30](440/472) || training loss 0.3077 || training accuracy 90.62% || lr 0.001\n",
      "Epoch[8/30](460/472) || training loss 0.2384 || training accuracy 90.94% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 82.94%! saving the best model..\n",
      "[Val] acc : 82.94%, loss: 0.39 || best acc : 82.94%, best loss: 0.39\n",
      "\n",
      "Epoch[9/30](20/472) || training loss 0.3007 || training accuracy 92.50% || lr 0.001\n",
      "Epoch[9/30](40/472) || training loss 0.2366 || training accuracy 91.41% || lr 0.001\n",
      "Epoch[9/30](60/472) || training loss 0.2635 || training accuracy 90.94% || lr 0.001\n",
      "Epoch[9/30](80/472) || training loss 0.2468 || training accuracy 92.03% || lr 0.001\n",
      "Epoch[9/30](100/472) || training loss 0.2362 || training accuracy 92.19% || lr 0.001\n",
      "Epoch[9/30](120/472) || training loss 0.2096 || training accuracy 92.66% || lr 0.001\n",
      "Epoch[9/30](140/472) || training loss 0.2634 || training accuracy 91.41% || lr 0.001\n",
      "Epoch[9/30](160/472) || training loss 0.2777 || training accuracy 90.00% || lr 0.001\n",
      "Epoch[9/30](180/472) || training loss 0.2639 || training accuracy 90.62% || lr 0.001\n",
      "Epoch[9/30](200/472) || training loss 0.2436 || training accuracy 92.50% || lr 0.001\n",
      "Epoch[9/30](220/472) || training loss 0.2307 || training accuracy 93.12% || lr 0.001\n",
      "Epoch[9/30](240/472) || training loss 0.2333 || training accuracy 93.28% || lr 0.001\n",
      "Epoch[9/30](260/472) || training loss 0.2666 || training accuracy 91.56% || lr 0.001\n",
      "Epoch[9/30](280/472) || training loss 0.3079 || training accuracy 89.84% || lr 0.001\n",
      "Epoch[9/30](300/472) || training loss 0.2624 || training accuracy 90.78% || lr 0.001\n",
      "Epoch[9/30](320/472) || training loss 0.2408 || training accuracy 92.03% || lr 0.001\n",
      "Epoch[9/30](340/472) || training loss 0.3246 || training accuracy 90.00% || lr 0.001\n",
      "Epoch[9/30](360/472) || training loss 0.2933 || training accuracy 91.41% || lr 0.001\n",
      "Epoch[9/30](380/472) || training loss 0.2944 || training accuracy 90.62% || lr 0.001\n",
      "Epoch[9/30](400/472) || training loss 0.2738 || training accuracy 90.94% || lr 0.001\n",
      "Epoch[9/30](420/472) || training loss 0.3076 || training accuracy 89.22% || lr 0.001\n",
      "Epoch[9/30](440/472) || training loss 0.2697 || training accuracy 90.31% || lr 0.001\n",
      "Epoch[9/30](460/472) || training loss 0.2555 || training accuracy 90.78% || lr 0.001\n",
      "Calculating validation results...\n",
      "[Val] acc : 74.42%, loss:  0.6 || best acc : 82.94%, best loss: 0.39\n",
      "\n",
      "Epoch[10/30](20/472) || training loss 0.2699 || training accuracy 89.53% || lr 0.001\n",
      "Epoch[10/30](40/472) || training loss 0.2931 || training accuracy 88.59% || lr 0.001\n",
      "Epoch[10/30](60/472) || training loss 0.2181 || training accuracy 93.28% || lr 0.001\n",
      "Epoch[10/30](80/472) || training loss 0.2367 || training accuracy 91.72% || lr 0.001\n",
      "Epoch[10/30](100/472) || training loss 0.2869 || training accuracy 89.22% || lr 0.001\n",
      "Epoch[10/30](120/472) || training loss 0.2937 || training accuracy 90.62% || lr 0.001\n",
      "Epoch[10/30](140/472) || training loss 0.299 || training accuracy 90.47% || lr 0.001\n",
      "Epoch[10/30](160/472) || training loss 0.3204 || training accuracy 89.22% || lr 0.001\n",
      "Epoch[10/30](180/472) || training loss 0.2898 || training accuracy 90.62% || lr 0.001\n",
      "Epoch[10/30](200/472) || training loss 0.2801 || training accuracy 90.00% || lr 0.001\n",
      "Epoch[10/30](220/472) || training loss 0.2649 || training accuracy 91.88% || lr 0.001\n",
      "Epoch[10/30](240/472) || training loss 0.2744 || training accuracy 90.31% || lr 0.001\n",
      "Epoch[10/30](260/472) || training loss 0.249 || training accuracy 92.50% || lr 0.001\n",
      "Epoch[10/30](280/472) || training loss 0.2641 || training accuracy 91.56% || lr 0.001\n",
      "Epoch[10/30](300/472) || training loss 0.3137 || training accuracy 88.28% || lr 0.001\n",
      "Epoch[10/30](320/472) || training loss 0.2531 || training accuracy 91.41% || lr 0.001\n",
      "Epoch[10/30](340/472) || training loss 0.2143 || training accuracy 93.75% || lr 0.001\n",
      "Epoch[10/30](360/472) || training loss 0.2762 || training accuracy 91.09% || lr 0.001\n",
      "Epoch[10/30](380/472) || training loss 0.22 || training accuracy 93.12% || lr 0.001\n",
      "Epoch[10/30](400/472) || training loss 0.2165 || training accuracy 92.19% || lr 0.001\n",
      "Epoch[10/30](420/472) || training loss 0.2825 || training accuracy 90.78% || lr 0.001\n",
      "Epoch[10/30](440/472) || training loss 0.319 || training accuracy 89.22% || lr 0.001\n",
      "Epoch[10/30](460/472) || training loss 0.2486 || training accuracy 92.34% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 84.13%! saving the best model..\n",
      "[Val] acc : 84.13%, loss: 0.37 || best acc : 84.13%, best loss: 0.37\n",
      "\n",
      "Epoch[11/30](20/472) || training loss 0.2435 || training accuracy 91.88% || lr 0.001\n",
      "Epoch[11/30](40/472) || training loss 0.2412 || training accuracy 91.72% || lr 0.001\n",
      "Epoch[11/30](60/472) || training loss 0.3026 || training accuracy 90.31% || lr 0.001\n",
      "Epoch[11/30](80/472) || training loss 0.2926 || training accuracy 90.94% || lr 0.001\n",
      "Epoch[11/30](100/472) || training loss 0.2387 || training accuracy 91.41% || lr 0.001\n",
      "Epoch[11/30](120/472) || training loss 0.2706 || training accuracy 89.84% || lr 0.001\n",
      "Epoch[11/30](140/472) || training loss 0.2503 || training accuracy 91.72% || lr 0.001\n",
      "Epoch[11/30](160/472) || training loss 0.2407 || training accuracy 91.41% || lr 0.001\n",
      "Epoch[11/30](180/472) || training loss 0.2006 || training accuracy 93.12% || lr 0.001\n",
      "Epoch[11/30](200/472) || training loss 0.215 || training accuracy 93.12% || lr 0.001\n",
      "Epoch[11/30](220/472) || training loss 0.2403 || training accuracy 91.41% || lr 0.001\n",
      "Epoch[11/30](240/472) || training loss 0.2092 || training accuracy 93.75% || lr 0.001\n",
      "Epoch[11/30](260/472) || training loss 0.2144 || training accuracy 92.66% || lr 0.001\n",
      "Epoch[11/30](280/472) || training loss 0.2101 || training accuracy 92.66% || lr 0.001\n",
      "Epoch[11/30](300/472) || training loss 0.2438 || training accuracy 90.78% || lr 0.001\n",
      "Epoch[11/30](320/472) || training loss 0.2473 || training accuracy 91.09% || lr 0.001\n",
      "Epoch[11/30](340/472) || training loss 0.2764 || training accuracy 89.84% || lr 0.001\n",
      "Epoch[11/30](360/472) || training loss 0.2259 || training accuracy 91.41% || lr 0.001\n",
      "Epoch[11/30](380/472) || training loss 0.2844 || training accuracy 90.16% || lr 0.001\n",
      "Epoch[11/30](400/472) || training loss 0.2803 || training accuracy 91.72% || lr 0.001\n",
      "Epoch[11/30](420/472) || training loss 0.2495 || training accuracy 91.25% || lr 0.001\n",
      "Epoch[11/30](440/472) || training loss 0.2446 || training accuracy 92.19% || lr 0.001\n",
      "Epoch[11/30](460/472) || training loss 0.2015 || training accuracy 93.75% || lr 0.001\n",
      "Calculating validation results...\n",
      "[Val] acc : 77.01%, loss: 0.56 || best acc : 84.13%, best loss: 0.37\n",
      "\n",
      "Epoch[12/30](20/472) || training loss 0.232 || training accuracy 91.72% || lr 0.001\n",
      "Epoch[12/30](40/472) || training loss 0.2059 || training accuracy 93.12% || lr 0.001\n",
      "Epoch[12/30](60/472) || training loss 0.2557 || training accuracy 91.41% || lr 0.001\n",
      "Epoch[12/30](80/472) || training loss 0.2626 || training accuracy 91.56% || lr 0.001\n",
      "Epoch[12/30](100/472) || training loss 0.2572 || training accuracy 92.19% || lr 0.001\n",
      "Epoch[12/30](120/472) || training loss 0.3027 || training accuracy 89.84% || lr 0.001\n",
      "Epoch[12/30](140/472) || training loss 0.2998 || training accuracy 89.06% || lr 0.001\n",
      "Epoch[12/30](160/472) || training loss 0.2032 || training accuracy 93.44% || lr 0.001\n",
      "Epoch[12/30](180/472) || training loss 0.2348 || training accuracy 91.09% || lr 0.001\n",
      "Epoch[12/30](200/472) || training loss 0.2094 || training accuracy 93.44% || lr 0.001\n",
      "Epoch[12/30](220/472) || training loss 0.2111 || training accuracy 92.03% || lr 0.001\n",
      "Epoch[12/30](240/472) || training loss 0.2189 || training accuracy 92.50% || lr 0.001\n",
      "Epoch[12/30](260/472) || training loss 0.2196 || training accuracy 92.81% || lr 0.001\n",
      "Epoch[12/30](280/472) || training loss 0.2293 || training accuracy 92.03% || lr 0.001\n",
      "Epoch[12/30](300/472) || training loss 0.2565 || training accuracy 91.09% || lr 0.001\n",
      "Epoch[12/30](320/472) || training loss 0.2576 || training accuracy 92.03% || lr 0.001\n",
      "Epoch[12/30](340/472) || training loss 0.2324 || training accuracy 92.81% || lr 0.001\n",
      "Epoch[12/30](360/472) || training loss 0.2472 || training accuracy 91.72% || lr 0.001\n",
      "Epoch[12/30](380/472) || training loss 0.2424 || training accuracy 91.72% || lr 0.001\n",
      "Epoch[12/30](400/472) || training loss 0.2703 || training accuracy 91.88% || lr 0.001\n",
      "Epoch[12/30](420/472) || training loss 0.2382 || training accuracy 91.88% || lr 0.001\n",
      "Epoch[12/30](440/472) || training loss 0.2639 || training accuracy 89.53% || lr 0.001\n",
      "Epoch[12/30](460/472) || training loss 0.2312 || training accuracy 92.34% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 86.56%! saving the best model..\n",
      "[Val] acc : 86.56%, loss: 0.28 || best acc : 86.56%, best loss: 0.28\n",
      "\n",
      "Epoch[13/30](20/472) || training loss 0.1748 || training accuracy 93.44% || lr 0.001\n",
      "Epoch[13/30](40/472) || training loss 0.1879 || training accuracy 93.44% || lr 0.001\n",
      "Epoch[13/30](60/472) || training loss 0.2481 || training accuracy 93.12% || lr 0.001\n",
      "Epoch[13/30](80/472) || training loss 0.2641 || training accuracy 92.19% || lr 0.001\n",
      "Epoch[13/30](100/472) || training loss 0.2593 || training accuracy 89.53% || lr 0.001\n",
      "Epoch[13/30](120/472) || training loss 0.22 || training accuracy 93.59% || lr 0.001\n",
      "Epoch[13/30](140/472) || training loss 0.2336 || training accuracy 91.25% || lr 0.001\n",
      "Epoch[13/30](160/472) || training loss 0.2661 || training accuracy 90.31% || lr 0.001\n",
      "Epoch[13/30](180/472) || training loss 0.2438 || training accuracy 91.41% || lr 0.001\n",
      "Epoch[13/30](200/472) || training loss 0.2389 || training accuracy 91.56% || lr 0.001\n",
      "Epoch[13/30](220/472) || training loss 0.2207 || training accuracy 92.50% || lr 0.001\n",
      "Epoch[13/30](240/472) || training loss 0.2661 || training accuracy 90.31% || lr 0.001\n",
      "Epoch[13/30](260/472) || training loss 0.2386 || training accuracy 91.25% || lr 0.001\n",
      "Epoch[13/30](280/472) || training loss 0.2163 || training accuracy 92.66% || lr 0.001\n",
      "Epoch[13/30](300/472) || training loss 0.2227 || training accuracy 92.97% || lr 0.001\n",
      "Epoch[13/30](320/472) || training loss 0.2556 || training accuracy 91.56% || lr 0.001\n",
      "Epoch[13/30](340/472) || training loss 0.2013 || training accuracy 93.59% || lr 0.001\n",
      "Epoch[13/30](360/472) || training loss 0.2349 || training accuracy 92.50% || lr 0.001\n",
      "Epoch[13/30](380/472) || training loss 0.2418 || training accuracy 92.03% || lr 0.001\n",
      "Epoch[13/30](400/472) || training loss 0.214 || training accuracy 93.75% || lr 0.001\n",
      "Epoch[13/30](420/472) || training loss 0.2269 || training accuracy 92.50% || lr 0.001\n",
      "Epoch[13/30](440/472) || training loss 0.2301 || training accuracy 92.03% || lr 0.001\n",
      "Epoch[13/30](460/472) || training loss 0.1984 || training accuracy 92.50% || lr 0.001\n",
      "Calculating validation results...\n",
      "[Val] acc : 84.02%, loss: 0.36 || best acc : 86.56%, best loss: 0.28\n",
      "\n",
      "Epoch[14/30](20/472) || training loss 0.1993 || training accuracy 92.03% || lr 0.001\n",
      "Epoch[14/30](40/472) || training loss 0.1676 || training accuracy 95.16% || lr 0.001\n",
      "Epoch[14/30](60/472) || training loss 0.2435 || training accuracy 90.78% || lr 0.001\n",
      "Epoch[14/30](80/472) || training loss 0.2449 || training accuracy 92.19% || lr 0.001\n",
      "Epoch[14/30](100/472) || training loss 0.2152 || training accuracy 93.59% || lr 0.001\n",
      "Epoch[14/30](120/472) || training loss 0.2169 || training accuracy 92.19% || lr 0.001\n",
      "Epoch[14/30](140/472) || training loss 0.238 || training accuracy 92.19% || lr 0.001\n",
      "Epoch[14/30](160/472) || training loss 0.2538 || training accuracy 91.09% || lr 0.001\n",
      "Epoch[14/30](180/472) || training loss 0.2329 || training accuracy 92.66% || lr 0.001\n",
      "Epoch[14/30](200/472) || training loss 0.2017 || training accuracy 93.75% || lr 0.001\n",
      "Epoch[14/30](220/472) || training loss 0.2141 || training accuracy 92.97% || lr 0.001\n",
      "Epoch[14/30](240/472) || training loss 0.2466 || training accuracy 91.09% || lr 0.001\n",
      "Epoch[14/30](260/472) || training loss 0.2026 || training accuracy 93.44% || lr 0.001\n",
      "Epoch[14/30](280/472) || training loss 0.2495 || training accuracy 91.88% || lr 0.001\n",
      "Epoch[14/30](300/472) || training loss 0.2547 || training accuracy 91.41% || lr 0.001\n",
      "Epoch[14/30](320/472) || training loss 0.1874 || training accuracy 94.22% || lr 0.001\n",
      "Epoch[14/30](340/472) || training loss 0.2398 || training accuracy 92.19% || lr 0.001\n",
      "Epoch[14/30](360/472) || training loss 0.3064 || training accuracy 88.75% || lr 0.001\n",
      "Epoch[14/30](380/472) || training loss 0.2358 || training accuracy 92.34% || lr 0.001\n",
      "Epoch[14/30](400/472) || training loss 0.2215 || training accuracy 91.88% || lr 0.001\n",
      "Epoch[14/30](420/472) || training loss 0.2558 || training accuracy 91.72% || lr 0.001\n",
      "Epoch[14/30](440/472) || training loss 0.2376 || training accuracy 92.50% || lr 0.001\n",
      "Epoch[14/30](460/472) || training loss 0.3104 || training accuracy 87.97% || lr 0.001\n",
      "Calculating validation results...\n",
      "[Val] acc : 82.54%, loss: 0.41 || best acc : 86.56%, best loss: 0.28\n",
      "\n",
      "Epoch[15/30](20/472) || training loss 0.2245 || training accuracy 92.34% || lr 0.001\n",
      "Epoch[15/30](40/472) || training loss 0.2102 || training accuracy 91.56% || lr 0.001\n",
      "Epoch[15/30](60/472) || training loss 0.2025 || training accuracy 93.28% || lr 0.001\n",
      "Epoch[15/30](80/472) || training loss 0.2552 || training accuracy 90.62% || lr 0.001\n",
      "Epoch[15/30](100/472) || training loss 0.2115 || training accuracy 92.50% || lr 0.001\n",
      "Epoch[15/30](120/472) || training loss 0.2249 || training accuracy 92.50% || lr 0.001\n",
      "Epoch[15/30](140/472) || training loss 0.255 || training accuracy 91.88% || lr 0.001\n",
      "Epoch[15/30](160/472) || training loss 0.17 || training accuracy 94.06% || lr 0.001\n",
      "Epoch[15/30](180/472) || training loss 0.2018 || training accuracy 93.75% || lr 0.001\n",
      "Epoch[15/30](200/472) || training loss 0.2446 || training accuracy 93.91% || lr 0.001\n",
      "Epoch[15/30](220/472) || training loss 0.2037 || training accuracy 92.81% || lr 0.001\n",
      "Epoch[15/30](240/472) || training loss 0.194 || training accuracy 93.12% || lr 0.001\n",
      "Epoch[15/30](260/472) || training loss 0.1978 || training accuracy 92.81% || lr 0.001\n",
      "Epoch[15/30](280/472) || training loss 0.204 || training accuracy 92.81% || lr 0.001\n",
      "Epoch[15/30](300/472) || training loss 0.2376 || training accuracy 91.88% || lr 0.001\n",
      "Epoch[15/30](320/472) || training loss 0.2202 || training accuracy 93.12% || lr 0.001\n",
      "Epoch[15/30](340/472) || training loss 0.2043 || training accuracy 92.34% || lr 0.001\n",
      "Epoch[15/30](360/472) || training loss 0.1955 || training accuracy 93.59% || lr 0.001\n",
      "Epoch[15/30](380/472) || training loss 0.2498 || training accuracy 91.56% || lr 0.001\n",
      "Epoch[15/30](400/472) || training loss 0.2406 || training accuracy 92.66% || lr 0.001\n",
      "Epoch[15/30](420/472) || training loss 0.2305 || training accuracy 92.34% || lr 0.001\n",
      "Epoch[15/30](440/472) || training loss 0.2727 || training accuracy 91.88% || lr 0.001\n",
      "Epoch[15/30](460/472) || training loss 0.2265 || training accuracy 92.66% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 87.88%! saving the best model..\n",
      "[Val] acc : 87.88%, loss: 0.22 || best acc : 87.88%, best loss: 0.22\n",
      "\n",
      "Epoch[16/30](20/472) || training loss 0.2182 || training accuracy 92.81% || lr 0.001\n",
      "Epoch[16/30](40/472) || training loss 0.1815 || training accuracy 94.06% || lr 0.001\n",
      "Epoch[16/30](60/472) || training loss 0.1986 || training accuracy 93.12% || lr 0.001\n",
      "Epoch[16/30](80/472) || training loss 0.2295 || training accuracy 92.03% || lr 0.001\n",
      "Epoch[16/30](100/472) || training loss 0.2028 || training accuracy 93.75% || lr 0.001\n",
      "Epoch[16/30](120/472) || training loss 0.1855 || training accuracy 93.44% || lr 0.001\n",
      "Epoch[16/30](140/472) || training loss 0.1804 || training accuracy 93.44% || lr 0.001\n",
      "Epoch[16/30](160/472) || training loss 0.2494 || training accuracy 90.94% || lr 0.001\n",
      "Epoch[16/30](180/472) || training loss 0.2248 || training accuracy 92.50% || lr 0.001\n",
      "Epoch[16/30](200/472) || training loss 0.2254 || training accuracy 91.88% || lr 0.001\n",
      "Epoch[16/30](220/472) || training loss 0.2713 || training accuracy 91.25% || lr 0.001\n",
      "Epoch[16/30](240/472) || training loss 0.2481 || training accuracy 91.09% || lr 0.001\n",
      "Epoch[16/30](260/472) || training loss 0.2354 || training accuracy 91.88% || lr 0.001\n",
      "Epoch[16/30](280/472) || training loss 0.2341 || training accuracy 92.34% || lr 0.001\n",
      "Epoch[16/30](300/472) || training loss 0.2402 || training accuracy 91.25% || lr 0.001\n",
      "Epoch[16/30](320/472) || training loss 0.2482 || training accuracy 92.66% || lr 0.001\n",
      "Epoch[16/30](340/472) || training loss 0.1944 || training accuracy 93.59% || lr 0.001\n",
      "Epoch[16/30](360/472) || training loss 0.1981 || training accuracy 93.59% || lr 0.001\n",
      "Epoch[16/30](380/472) || training loss 0.244 || training accuracy 91.41% || lr 0.001\n",
      "Epoch[16/30](400/472) || training loss 0.2004 || training accuracy 93.59% || lr 0.001\n",
      "Epoch[16/30](420/472) || training loss 0.2698 || training accuracy 90.16% || lr 0.001\n",
      "Epoch[16/30](440/472) || training loss 0.2384 || training accuracy 92.34% || lr 0.001\n",
      "Epoch[16/30](460/472) || training loss 0.2711 || training accuracy 90.00% || lr 0.001\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 88.41%! saving the best model..\n",
      "[Val] acc : 88.41%, loss: 0.22 || best acc : 88.41%, best loss: 0.22\n",
      "\n",
      "Epoch[17/30](20/472) || training loss 0.1664 || training accuracy 94.06% || lr 0.001\n",
      "Epoch[17/30](40/472) || training loss 0.206 || training accuracy 92.19% || lr 0.001\n",
      "Epoch[17/30](60/472) || training loss 0.1735 || training accuracy 94.69% || lr 0.001\n",
      "Epoch[17/30](80/472) || training loss 0.1649 || training accuracy 95.31% || lr 0.001\n",
      "Epoch[17/30](100/472) || training loss 0.18 || training accuracy 94.06% || lr 0.001\n",
      "Epoch[17/30](120/472) || training loss 0.1906 || training accuracy 92.81% || lr 0.001\n",
      "Epoch[17/30](140/472) || training loss 0.2431 || training accuracy 91.88% || lr 0.001\n",
      "Epoch[17/30](160/472) || training loss 0.2408 || training accuracy 92.81% || lr 0.001\n",
      "Epoch[17/30](180/472) || training loss 0.1949 || training accuracy 93.91% || lr 0.001\n",
      "Epoch[17/30](200/472) || training loss 0.1492 || training accuracy 94.38% || lr 0.001\n",
      "Epoch[17/30](220/472) || training loss 0.2548 || training accuracy 92.34% || lr 0.001\n",
      "Epoch[17/30](240/472) || training loss 0.2185 || training accuracy 92.19% || lr 0.001\n",
      "Epoch[17/30](260/472) || training loss 0.2441 || training accuracy 91.25% || lr 0.001\n",
      "Epoch[17/30](280/472) || training loss 0.255 || training accuracy 91.88% || lr 0.001\n",
      "Epoch[17/30](300/472) || training loss 0.2264 || training accuracy 92.34% || lr 0.001\n",
      "Epoch[17/30](320/472) || training loss 0.1908 || training accuracy 92.97% || lr 0.001\n",
      "Epoch[17/30](340/472) || training loss 0.2254 || training accuracy 91.25% || lr 0.001\n",
      "Epoch[17/30](360/472) || training loss 0.2309 || training accuracy 92.97% || lr 0.001\n",
      "Epoch[17/30](380/472) || training loss 0.2298 || training accuracy 92.81% || lr 0.001\n",
      "Epoch[17/30](400/472) || training loss 0.2368 || training accuracy 91.09% || lr 0.001\n",
      "Epoch[17/30](420/472) || training loss 0.2444 || training accuracy 91.41% || lr 0.001\n",
      "Epoch[17/30](440/472) || training loss 0.1872 || training accuracy 94.06% || lr 0.001\n",
      "Epoch[17/30](460/472) || training loss 0.2171 || training accuracy 91.72% || lr 0.001\n",
      "Calculating validation results...\n",
      "[Val] acc : 79.02%, loss: 0.47 || best acc : 88.41%, best loss: 0.22\n",
      "\n",
      "Epoch[18/30](20/472) || training loss 0.2096 || training accuracy 91.88% || lr 0.001\n",
      "Epoch[18/30](40/472) || training loss 0.1945 || training accuracy 94.38% || lr 0.001\n",
      "Epoch[18/30](60/472) || training loss 0.1542 || training accuracy 95.62% || lr 0.001\n",
      "Epoch[18/30](80/472) || training loss 0.1804 || training accuracy 93.28% || lr 0.001\n",
      "Epoch[18/30](100/472) || training loss 0.1947 || training accuracy 93.28% || lr 0.001\n",
      "Epoch[18/30](120/472) || training loss 0.1807 || training accuracy 94.69% || lr 0.001\n",
      "Epoch[18/30](140/472) || training loss 0.2023 || training accuracy 92.34% || lr 0.001\n",
      "Epoch[18/30](160/472) || training loss 0.2267 || training accuracy 92.81% || lr 0.001\n",
      "Epoch[18/30](180/472) || training loss 0.1915 || training accuracy 92.97% || lr 0.001\n",
      "Epoch[18/30](200/472) || training loss 0.1771 || training accuracy 93.28% || lr 0.001\n",
      "Epoch[18/30](220/472) || training loss 0.1994 || training accuracy 93.12% || lr 0.001\n",
      "Epoch[18/30](240/472) || training loss 0.2434 || training accuracy 91.56% || lr 0.001\n",
      "Epoch[18/30](260/472) || training loss 0.2154 || training accuracy 92.50% || lr 0.001\n",
      "Epoch[18/30](280/472) || training loss 0.2137 || training accuracy 93.59% || lr 0.001\n",
      "Epoch[18/30](300/472) || training loss 0.2117 || training accuracy 92.34% || lr 0.001\n",
      "Epoch[18/30](320/472) || training loss 0.219 || training accuracy 93.12% || lr 0.001\n",
      "Epoch[18/30](340/472) || training loss 0.1614 || training accuracy 95.62% || lr 0.001\n",
      "Epoch[18/30](360/472) || training loss 0.1992 || training accuracy 94.06% || lr 0.001\n",
      "Epoch[18/30](380/472) || training loss 0.2136 || training accuracy 92.03% || lr 0.001\n",
      "Epoch[18/30](400/472) || training loss 0.2406 || training accuracy 91.56% || lr 0.001\n",
      "Epoch[18/30](420/472) || training loss 0.1845 || training accuracy 94.06% || lr 0.001\n",
      "Epoch[18/30](440/472) || training loss 0.1978 || training accuracy 93.75% || lr 0.001\n",
      "Epoch[18/30](460/472) || training loss 0.2019 || training accuracy 93.59% || lr 0.001\n",
      "Calculating validation results...\n",
      "[Val] acc : 84.05%, loss: 0.35 || best acc : 88.41%, best loss: 0.22\n",
      "\n",
      "Epoch[19/30](20/472) || training loss 0.1498 || training accuracy 95.78% || lr 0.001\n",
      "Epoch[19/30](40/472) || training loss 0.1964 || training accuracy 92.97% || lr 0.001\n",
      "Epoch[19/30](60/472) || training loss 0.2172 || training accuracy 93.75% || lr 0.001\n",
      "Epoch[19/30](80/472) || training loss 0.2428 || training accuracy 91.88% || lr 0.001\n",
      "Epoch[19/30](100/472) || training loss 0.2264 || training accuracy 92.19% || lr 0.001\n",
      "Epoch[19/30](120/472) || training loss 0.1969 || training accuracy 93.12% || lr 0.001\n",
      "Epoch[19/30](140/472) || training loss 0.2211 || training accuracy 91.41% || lr 0.001\n",
      "Epoch[19/30](160/472) || training loss 0.1756 || training accuracy 94.22% || lr 0.001\n",
      "Epoch[19/30](180/472) || training loss 0.1724 || training accuracy 94.69% || lr 0.001\n",
      "Epoch[19/30](200/472) || training loss 0.217 || training accuracy 92.66% || lr 0.001\n",
      "Epoch[19/30](220/472) || training loss 0.1865 || training accuracy 93.12% || lr 0.001\n",
      "Epoch[19/30](240/472) || training loss 0.2304 || training accuracy 92.81% || lr 0.001\n",
      "Epoch[19/30](260/472) || training loss 0.1826 || training accuracy 93.75% || lr 0.001\n",
      "Epoch[19/30](280/472) || training loss 0.2185 || training accuracy 92.97% || lr 0.001\n",
      "Epoch[19/30](300/472) || training loss 0.1665 || training accuracy 94.69% || lr 0.001\n",
      "Epoch[19/30](320/472) || training loss 0.1995 || training accuracy 93.44% || lr 0.001\n",
      "Epoch[19/30](340/472) || training loss 0.1626 || training accuracy 94.69% || lr 0.001\n",
      "Epoch[19/30](360/472) || training loss 0.1851 || training accuracy 93.91% || lr 0.001\n",
      "Epoch[19/30](380/472) || training loss 0.2012 || training accuracy 93.44% || lr 0.001\n",
      "Epoch[19/30](400/472) || training loss 0.2066 || training accuracy 93.12% || lr 0.001\n",
      "Epoch[19/30](420/472) || training loss 0.2335 || training accuracy 92.19% || lr 0.001\n",
      "Epoch[19/30](440/472) || training loss 0.21 || training accuracy 92.81% || lr 0.001\n",
      "Epoch[19/30](460/472) || training loss 0.185 || training accuracy 93.12% || lr 0.001\n",
      "Calculating validation results...\n",
      "[Val] acc : 87.38%, loss: 0.24 || best acc : 88.41%, best loss: 0.22\n",
      "\n",
      "Epoch[20/30](20/472) || training loss 0.191 || training accuracy 94.22% || lr 0.0005\n",
      "Epoch[20/30](40/472) || training loss 0.1353 || training accuracy 95.94% || lr 0.0005\n",
      "Epoch[20/30](60/472) || training loss 0.1475 || training accuracy 95.00% || lr 0.0005\n",
      "Epoch[20/30](80/472) || training loss 0.1425 || training accuracy 95.62% || lr 0.0005\n",
      "Epoch[20/30](100/472) || training loss 0.1328 || training accuracy 96.09% || lr 0.0005\n",
      "Epoch[20/30](120/472) || training loss 0.1644 || training accuracy 95.31% || lr 0.0005\n",
      "Epoch[20/30](140/472) || training loss 0.1571 || training accuracy 94.22% || lr 0.0005\n",
      "Epoch[20/30](160/472) || training loss 0.1142 || training accuracy 96.25% || lr 0.0005\n",
      "Epoch[20/30](180/472) || training loss 0.1258 || training accuracy 97.19% || lr 0.0005\n",
      "Epoch[20/30](200/472) || training loss 0.09642 || training accuracy 97.66% || lr 0.0005\n",
      "Epoch[20/30](220/472) || training loss 0.1316 || training accuracy 95.47% || lr 0.0005\n",
      "Epoch[20/30](240/472) || training loss 0.1069 || training accuracy 96.72% || lr 0.0005\n",
      "Epoch[20/30](260/472) || training loss 0.1497 || training accuracy 95.16% || lr 0.0005\n",
      "Epoch[20/30](280/472) || training loss 0.1257 || training accuracy 96.56% || lr 0.0005\n",
      "Epoch[20/30](300/472) || training loss 0.1599 || training accuracy 94.84% || lr 0.0005\n",
      "Epoch[20/30](320/472) || training loss 0.1307 || training accuracy 96.25% || lr 0.0005\n",
      "Epoch[20/30](340/472) || training loss 0.1104 || training accuracy 96.56% || lr 0.0005\n",
      "Epoch[20/30](360/472) || training loss 0.1512 || training accuracy 94.69% || lr 0.0005\n",
      "Epoch[20/30](380/472) || training loss 0.1129 || training accuracy 96.25% || lr 0.0005\n",
      "Epoch[20/30](400/472) || training loss 0.1565 || training accuracy 94.38% || lr 0.0005\n",
      "Epoch[20/30](420/472) || training loss 0.1086 || training accuracy 96.09% || lr 0.0005\n",
      "Epoch[20/30](440/472) || training loss 0.0941 || training accuracy 97.03% || lr 0.0005\n",
      "Epoch[20/30](460/472) || training loss 0.1318 || training accuracy 95.94% || lr 0.0005\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 90.48%! saving the best model..\n",
      "[Val] acc : 90.48%, loss: 0.15 || best acc : 90.48%, best loss: 0.15\n",
      "\n",
      "Epoch[21/30](20/472) || training loss 0.1009 || training accuracy 97.50% || lr 0.0005\n",
      "Epoch[21/30](40/472) || training loss 0.1178 || training accuracy 96.56% || lr 0.0005\n",
      "Epoch[21/30](60/472) || training loss 0.1204 || training accuracy 96.09% || lr 0.0005\n",
      "Epoch[21/30](80/472) || training loss 0.1291 || training accuracy 95.78% || lr 0.0005\n",
      "Epoch[21/30](100/472) || training loss 0.1353 || training accuracy 95.47% || lr 0.0005\n",
      "Epoch[21/30](120/472) || training loss 0.1005 || training accuracy 97.03% || lr 0.0005\n",
      "Epoch[21/30](140/472) || training loss 0.1482 || training accuracy 94.38% || lr 0.0005\n",
      "Epoch[21/30](160/472) || training loss 0.1071 || training accuracy 96.25% || lr 0.0005\n",
      "Epoch[21/30](180/472) || training loss 0.1252 || training accuracy 96.41% || lr 0.0005\n",
      "Epoch[21/30](200/472) || training loss 0.1135 || training accuracy 96.09% || lr 0.0005\n",
      "Epoch[21/30](220/472) || training loss 0.1066 || training accuracy 96.56% || lr 0.0005\n",
      "Epoch[21/30](240/472) || training loss 0.1227 || training accuracy 95.16% || lr 0.0005\n",
      "Epoch[21/30](260/472) || training loss 0.1137 || training accuracy 96.72% || lr 0.0005\n",
      "Epoch[21/30](280/472) || training loss 0.1131 || training accuracy 96.25% || lr 0.0005\n",
      "Epoch[21/30](300/472) || training loss 0.09154 || training accuracy 97.19% || lr 0.0005\n",
      "Epoch[21/30](320/472) || training loss 0.1367 || training accuracy 95.16% || lr 0.0005\n",
      "Epoch[21/30](340/472) || training loss 0.1019 || training accuracy 97.03% || lr 0.0005\n",
      "Epoch[21/30](360/472) || training loss 0.1389 || training accuracy 95.16% || lr 0.0005\n",
      "Epoch[21/30](380/472) || training loss 0.147 || training accuracy 94.06% || lr 0.0005\n",
      "Epoch[21/30](400/472) || training loss 0.161 || training accuracy 93.44% || lr 0.0005\n",
      "Epoch[21/30](420/472) || training loss 0.1557 || training accuracy 95.31% || lr 0.0005\n",
      "Epoch[21/30](440/472) || training loss 0.1289 || training accuracy 96.09% || lr 0.0005\n",
      "Epoch[21/30](460/472) || training loss 0.1042 || training accuracy 97.03% || lr 0.0005\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 90.71%! saving the best model..\n",
      "[Val] acc : 90.71%, loss: 0.13 || best acc : 90.71%, best loss: 0.13\n",
      "\n",
      "Epoch[22/30](20/472) || training loss 0.129 || training accuracy 96.09% || lr 0.0005\n",
      "Epoch[22/30](40/472) || training loss 0.1132 || training accuracy 96.41% || lr 0.0005\n",
      "Epoch[22/30](60/472) || training loss 0.1422 || training accuracy 95.47% || lr 0.0005\n",
      "Epoch[22/30](80/472) || training loss 0.1148 || training accuracy 96.56% || lr 0.0005\n",
      "Epoch[22/30](100/472) || training loss 0.08698 || training accuracy 97.34% || lr 0.0005\n",
      "Epoch[22/30](120/472) || training loss 0.1161 || training accuracy 96.56% || lr 0.0005\n",
      "Epoch[22/30](140/472) || training loss 0.1189 || training accuracy 95.16% || lr 0.0005\n",
      "Epoch[22/30](160/472) || training loss 0.1402 || training accuracy 95.62% || lr 0.0005\n",
      "Epoch[22/30](180/472) || training loss 0.1263 || training accuracy 95.47% || lr 0.0005\n",
      "Epoch[22/30](200/472) || training loss 0.1464 || training accuracy 95.47% || lr 0.0005\n",
      "Epoch[22/30](220/472) || training loss 0.08919 || training accuracy 96.88% || lr 0.0005\n",
      "Epoch[22/30](240/472) || training loss 0.1137 || training accuracy 97.03% || lr 0.0005\n",
      "Epoch[22/30](260/472) || training loss 0.1832 || training accuracy 94.53% || lr 0.0005\n",
      "Epoch[22/30](280/472) || training loss 0.14 || training accuracy 96.56% || lr 0.0005\n",
      "Epoch[22/30](300/472) || training loss 0.1059 || training accuracy 96.41% || lr 0.0005\n",
      "Epoch[22/30](320/472) || training loss 0.1341 || training accuracy 95.47% || lr 0.0005\n",
      "Epoch[22/30](340/472) || training loss 0.1344 || training accuracy 95.78% || lr 0.0005\n",
      "Epoch[22/30](360/472) || training loss 0.08804 || training accuracy 97.19% || lr 0.0005\n",
      "Epoch[22/30](380/472) || training loss 0.0975 || training accuracy 96.09% || lr 0.0005\n",
      "Epoch[22/30](400/472) || training loss 0.1307 || training accuracy 95.47% || lr 0.0005\n",
      "Epoch[22/30](420/472) || training loss 0.1165 || training accuracy 95.62% || lr 0.0005\n",
      "Epoch[22/30](440/472) || training loss 0.1015 || training accuracy 97.19% || lr 0.0005\n",
      "Epoch[22/30](460/472) || training loss 0.1071 || training accuracy 95.94% || lr 0.0005\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 91.01%! saving the best model..\n",
      "[Val] acc : 91.01%, loss: 0.14 || best acc : 91.01%, best loss: 0.13\n",
      "\n",
      "Epoch[23/30](20/472) || training loss 0.1011 || training accuracy 97.34% || lr 0.0005\n",
      "Epoch[23/30](40/472) || training loss 0.1019 || training accuracy 97.03% || lr 0.0005\n",
      "Epoch[23/30](60/472) || training loss 0.1231 || training accuracy 95.94% || lr 0.0005\n",
      "Epoch[23/30](80/472) || training loss 0.08839 || training accuracy 96.41% || lr 0.0005\n",
      "Epoch[23/30](100/472) || training loss 0.1133 || training accuracy 96.09% || lr 0.0005\n",
      "Epoch[23/30](120/472) || training loss 0.1205 || training accuracy 96.56% || lr 0.0005\n",
      "Epoch[23/30](140/472) || training loss 0.1039 || training accuracy 97.19% || lr 0.0005\n",
      "Epoch[23/30](160/472) || training loss 0.1269 || training accuracy 95.78% || lr 0.0005\n",
      "Epoch[23/30](180/472) || training loss 0.1163 || training accuracy 96.41% || lr 0.0005\n",
      "Epoch[23/30](200/472) || training loss  0.1 || training accuracy 98.28% || lr 0.0005\n",
      "Epoch[23/30](220/472) || training loss 0.0853 || training accuracy 97.34% || lr 0.0005\n",
      "Epoch[23/30](240/472) || training loss 0.08906 || training accuracy 97.50% || lr 0.0005\n",
      "Epoch[23/30](260/472) || training loss 0.1173 || training accuracy 96.56% || lr 0.0005\n",
      "Epoch[23/30](280/472) || training loss 0.06003 || training accuracy 98.75% || lr 0.0005\n",
      "Epoch[23/30](300/472) || training loss 0.08975 || training accuracy 97.19% || lr 0.0005\n",
      "Epoch[23/30](320/472) || training loss 0.1336 || training accuracy 95.94% || lr 0.0005\n",
      "Epoch[23/30](340/472) || training loss 0.1118 || training accuracy 97.03% || lr 0.0005\n",
      "Epoch[23/30](360/472) || training loss 0.1269 || training accuracy 95.62% || lr 0.0005\n",
      "Epoch[23/30](380/472) || training loss 0.1087 || training accuracy 96.56% || lr 0.0005\n",
      "Epoch[23/30](400/472) || training loss 0.1188 || training accuracy 95.78% || lr 0.0005\n",
      "Epoch[23/30](420/472) || training loss 0.1088 || training accuracy 97.66% || lr 0.0005\n",
      "Epoch[23/30](440/472) || training loss 0.08685 || training accuracy 97.03% || lr 0.0005\n",
      "Epoch[23/30](460/472) || training loss 0.09024 || training accuracy 97.50% || lr 0.0005\n",
      "Calculating validation results...\n",
      "[Val] acc : 89.97%, loss: 0.17 || best acc : 91.01%, best loss: 0.13\n",
      "\n",
      "Epoch[24/30](20/472) || training loss 0.07323 || training accuracy 97.97% || lr 0.0005\n",
      "Epoch[24/30](40/472) || training loss 0.09081 || training accuracy 96.88% || lr 0.0005\n",
      "Epoch[24/30](60/472) || training loss 0.1007 || training accuracy 96.72% || lr 0.0005\n",
      "Epoch[24/30](80/472) || training loss 0.129 || training accuracy 95.31% || lr 0.0005\n",
      "Epoch[24/30](100/472) || training loss 0.133 || training accuracy 95.62% || lr 0.0005\n",
      "Epoch[24/30](120/472) || training loss 0.09658 || training accuracy 96.56% || lr 0.0005\n",
      "Epoch[24/30](140/472) || training loss 0.1133 || training accuracy 96.25% || lr 0.0005\n",
      "Epoch[24/30](160/472) || training loss 0.09158 || training accuracy 97.03% || lr 0.0005\n",
      "Epoch[24/30](180/472) || training loss 0.1349 || training accuracy 95.94% || lr 0.0005\n",
      "Epoch[24/30](200/472) || training loss 0.1486 || training accuracy 95.47% || lr 0.0005\n",
      "Epoch[24/30](220/472) || training loss 0.1181 || training accuracy 96.09% || lr 0.0005\n",
      "Epoch[24/30](240/472) || training loss 0.133 || training accuracy 95.78% || lr 0.0005\n",
      "Epoch[24/30](260/472) || training loss 0.107 || training accuracy 96.72% || lr 0.0005\n",
      "Epoch[24/30](280/472) || training loss 0.09532 || training accuracy 96.09% || lr 0.0005\n",
      "Epoch[24/30](300/472) || training loss 0.1373 || training accuracy 95.00% || lr 0.0005\n",
      "Epoch[24/30](320/472) || training loss 0.1161 || training accuracy 96.41% || lr 0.0005\n",
      "Epoch[24/30](340/472) || training loss 0.1255 || training accuracy 96.25% || lr 0.0005\n",
      "Epoch[24/30](360/472) || training loss 0.118 || training accuracy 96.41% || lr 0.0005\n",
      "Epoch[24/30](380/472) || training loss 0.1032 || training accuracy 96.41% || lr 0.0005\n",
      "Epoch[24/30](400/472) || training loss 0.1226 || training accuracy 95.47% || lr 0.0005\n",
      "Epoch[24/30](420/472) || training loss 0.1235 || training accuracy 95.16% || lr 0.0005\n",
      "Epoch[24/30](440/472) || training loss 0.1482 || training accuracy 94.22% || lr 0.0005\n",
      "Epoch[24/30](460/472) || training loss 0.1302 || training accuracy 95.94% || lr 0.0005\n",
      "Calculating validation results...\n",
      "[Val] acc : 90.24%, loss: 0.16 || best acc : 91.01%, best loss: 0.13\n",
      "\n",
      "Epoch[25/30](20/472) || training loss 0.08672 || training accuracy 96.72% || lr 0.0005\n",
      "Epoch[25/30](40/472) || training loss 0.1061 || training accuracy 96.72% || lr 0.0005\n",
      "Epoch[25/30](60/472) || training loss 0.1211 || training accuracy 95.00% || lr 0.0005\n",
      "Epoch[25/30](80/472) || training loss 0.1009 || training accuracy 96.41% || lr 0.0005\n",
      "Epoch[25/30](100/472) || training loss 0.1105 || training accuracy 95.78% || lr 0.0005\n",
      "Epoch[25/30](120/472) || training loss 0.1046 || training accuracy 96.72% || lr 0.0005\n",
      "Epoch[25/30](140/472) || training loss 0.1076 || training accuracy 97.19% || lr 0.0005\n",
      "Epoch[25/30](160/472) || training loss 0.09168 || training accuracy 96.72% || lr 0.0005\n",
      "Epoch[25/30](180/472) || training loss 0.1092 || training accuracy 95.94% || lr 0.0005\n",
      "Epoch[25/30](200/472) || training loss 0.1039 || training accuracy 96.25% || lr 0.0005\n",
      "Epoch[25/30](220/472) || training loss 0.1047 || training accuracy 96.72% || lr 0.0005\n",
      "Epoch[25/30](240/472) || training loss 0.1219 || training accuracy 95.62% || lr 0.0005\n",
      "Epoch[25/30](260/472) || training loss 0.07588 || training accuracy 97.81% || lr 0.0005\n",
      "Epoch[25/30](280/472) || training loss 0.08007 || training accuracy 97.50% || lr 0.0005\n",
      "Epoch[25/30](300/472) || training loss 0.1061 || training accuracy 97.50% || lr 0.0005\n",
      "Epoch[25/30](320/472) || training loss 0.1066 || training accuracy 96.72% || lr 0.0005\n",
      "Epoch[25/30](340/472) || training loss 0.1279 || training accuracy 96.25% || lr 0.0005\n",
      "Epoch[25/30](360/472) || training loss 0.148 || training accuracy 95.00% || lr 0.0005\n",
      "Epoch[25/30](380/472) || training loss 0.09807 || training accuracy 96.56% || lr 0.0005\n",
      "Epoch[25/30](400/472) || training loss 0.1108 || training accuracy 96.25% || lr 0.0005\n",
      "Epoch[25/30](420/472) || training loss 0.1742 || training accuracy 94.22% || lr 0.0005\n",
      "Epoch[25/30](440/472) || training loss 0.1223 || training accuracy 95.47% || lr 0.0005\n",
      "Epoch[25/30](460/472) || training loss 0.1325 || training accuracy 95.47% || lr 0.0005\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 91.03%! saving the best model..\n",
      "[Val] acc : 91.03%, loss: 0.13 || best acc : 91.03%, best loss: 0.13\n",
      "\n",
      "Epoch[26/30](20/472) || training loss 0.07507 || training accuracy 98.28% || lr 0.0005\n",
      "Epoch[26/30](40/472) || training loss 0.09549 || training accuracy 97.19% || lr 0.0005\n",
      "Epoch[26/30](60/472) || training loss 0.06273 || training accuracy 98.91% || lr 0.0005\n",
      "Epoch[26/30](80/472) || training loss 0.111 || training accuracy 96.09% || lr 0.0005\n",
      "Epoch[26/30](100/472) || training loss 0.1013 || training accuracy 96.56% || lr 0.0005\n",
      "Epoch[26/30](120/472) || training loss 0.1191 || training accuracy 96.88% || lr 0.0005\n",
      "Epoch[26/30](140/472) || training loss 0.1262 || training accuracy 96.25% || lr 0.0005\n",
      "Epoch[26/30](160/472) || training loss 0.1359 || training accuracy 96.72% || lr 0.0005\n",
      "Epoch[26/30](180/472) || training loss 0.09109 || training accuracy 97.19% || lr 0.0005\n",
      "Epoch[26/30](200/472) || training loss 0.1237 || training accuracy 96.09% || lr 0.0005\n",
      "Epoch[26/30](220/472) || training loss 0.1118 || training accuracy 96.56% || lr 0.0005\n",
      "Epoch[26/30](240/472) || training loss 0.1294 || training accuracy 96.09% || lr 0.0005\n",
      "Epoch[26/30](260/472) || training loss 0.1186 || training accuracy 96.88% || lr 0.0005\n",
      "Epoch[26/30](280/472) || training loss 0.1037 || training accuracy 96.88% || lr 0.0005\n",
      "Epoch[26/30](300/472) || training loss 0.09747 || training accuracy 96.72% || lr 0.0005\n",
      "Epoch[26/30](320/472) || training loss 0.1175 || training accuracy 95.31% || lr 0.0005\n",
      "Epoch[26/30](340/472) || training loss 0.08901 || training accuracy 97.19% || lr 0.0005\n",
      "Epoch[26/30](360/472) || training loss 0.09698 || training accuracy 97.03% || lr 0.0005\n",
      "Epoch[26/30](380/472) || training loss 0.1199 || training accuracy 97.03% || lr 0.0005\n",
      "Epoch[26/30](400/472) || training loss 0.08741 || training accuracy 97.97% || lr 0.0005\n",
      "Epoch[26/30](420/472) || training loss 0.119 || training accuracy 95.78% || lr 0.0005\n",
      "Epoch[26/30](440/472) || training loss 0.1129 || training accuracy 96.09% || lr 0.0005\n",
      "Epoch[26/30](460/472) || training loss 0.09841 || training accuracy 97.03% || lr 0.0005\n",
      "Calculating validation results...\n",
      "New best model for val accuracy : 91.38%! saving the best model..\n",
      "[Val] acc : 91.38%, loss: 0.13 || best acc : 91.38%, best loss: 0.13\n",
      "\n",
      "Epoch[27/30](20/472) || training loss 0.08891 || training accuracy 97.50% || lr 0.0005\n",
      "Epoch[27/30](40/472) || training loss 0.0985 || training accuracy 96.25% || lr 0.0005\n",
      "Epoch[27/30](60/472) || training loss 0.09593 || training accuracy 96.72% || lr 0.0005\n",
      "Epoch[27/30](80/472) || training loss 0.1294 || training accuracy 96.88% || lr 0.0005\n",
      "Epoch[27/30](100/472) || training loss 0.1031 || training accuracy 96.09% || lr 0.0005\n",
      "Epoch[27/30](120/472) || training loss 0.1172 || training accuracy 96.41% || lr 0.0005\n",
      "Epoch[27/30](140/472) || training loss 0.1382 || training accuracy 95.94% || lr 0.0005\n",
      "Epoch[27/30](160/472) || training loss 0.09037 || training accuracy 97.19% || lr 0.0005\n",
      "Epoch[27/30](180/472) || training loss 0.1073 || training accuracy 97.19% || lr 0.0005\n",
      "Epoch[27/30](200/472) || training loss 0.1046 || training accuracy 96.72% || lr 0.0005\n",
      "Epoch[27/30](220/472) || training loss 0.1245 || training accuracy 96.72% || lr 0.0005\n",
      "Epoch[27/30](240/472) || training loss 0.09409 || training accuracy 96.88% || lr 0.0005\n",
      "Epoch[27/30](260/472) || training loss 0.104 || training accuracy 97.19% || lr 0.0005\n",
      "Epoch[27/30](280/472) || training loss 0.1115 || training accuracy 96.72% || lr 0.0005\n",
      "Epoch[27/30](300/472) || training loss 0.09093 || training accuracy 97.19% || lr 0.0005\n",
      "Epoch[27/30](320/472) || training loss 0.08325 || training accuracy 97.66% || lr 0.0005\n",
      "Epoch[27/30](340/472) || training loss 0.1063 || training accuracy 96.56% || lr 0.0005\n",
      "Epoch[27/30](360/472) || training loss 0.08081 || training accuracy 96.88% || lr 0.0005\n",
      "Epoch[27/30](380/472) || training loss 0.06902 || training accuracy 97.66% || lr 0.0005\n",
      "Epoch[27/30](400/472) || training loss 0.1481 || training accuracy 95.00% || lr 0.0005\n",
      "Epoch[27/30](420/472) || training loss 0.1851 || training accuracy 93.91% || lr 0.0005\n",
      "Epoch[27/30](440/472) || training loss 0.1486 || training accuracy 95.47% || lr 0.0005\n",
      "Epoch[27/30](460/472) || training loss 0.1347 || training accuracy 95.16% || lr 0.0005\n",
      "Calculating validation results...\n",
      "[Val] acc : 88.39%, loss: 0.22 || best acc : 91.38%, best loss: 0.13\n",
      "\n",
      "Epoch[28/30](20/472) || training loss 0.08693 || training accuracy 97.81% || lr 0.0005\n",
      "Epoch[28/30](40/472) || training loss 0.109 || training accuracy 97.34% || lr 0.0005\n",
      "Epoch[28/30](60/472) || training loss 0.1493 || training accuracy 94.84% || lr 0.0005\n",
      "Epoch[28/30](80/472) || training loss 0.112 || training accuracy 96.41% || lr 0.0005\n",
      "Epoch[28/30](100/472) || training loss 0.09539 || training accuracy 97.19% || lr 0.0005\n",
      "Epoch[28/30](120/472) || training loss 0.1025 || training accuracy 96.88% || lr 0.0005\n",
      "Epoch[28/30](140/472) || training loss 0.1091 || training accuracy 96.56% || lr 0.0005\n",
      "Epoch[28/30](160/472) || training loss 0.1107 || training accuracy 96.88% || lr 0.0005\n",
      "Epoch[28/30](180/472) || training loss 0.1082 || training accuracy 95.62% || lr 0.0005\n",
      "Epoch[28/30](200/472) || training loss 0.08747 || training accuracy 97.19% || lr 0.0005\n",
      "Epoch[28/30](220/472) || training loss 0.111 || training accuracy 96.41% || lr 0.0005\n",
      "Epoch[28/30](240/472) || training loss 0.09849 || training accuracy 97.03% || lr 0.0005\n",
      "Epoch[28/30](260/472) || training loss 0.1002 || training accuracy 96.56% || lr 0.0005\n",
      "Epoch[28/30](280/472) || training loss 0.1146 || training accuracy 96.56% || lr 0.0005\n",
      "Epoch[28/30](300/472) || training loss 0.1081 || training accuracy 97.19% || lr 0.0005\n",
      "Epoch[28/30](320/472) || training loss 0.08897 || training accuracy 97.97% || lr 0.0005\n",
      "Epoch[28/30](340/472) || training loss 0.09644 || training accuracy 97.03% || lr 0.0005\n",
      "Epoch[28/30](360/472) || training loss 0.09937 || training accuracy 96.72% || lr 0.0005\n",
      "Epoch[28/30](380/472) || training loss 0.1024 || training accuracy 97.03% || lr 0.0005\n",
      "Epoch[28/30](400/472) || training loss 0.1493 || training accuracy 95.31% || lr 0.0005\n",
      "Epoch[28/30](420/472) || training loss 0.09825 || training accuracy 96.88% || lr 0.0005\n",
      "Epoch[28/30](440/472) || training loss 0.1019 || training accuracy 96.72% || lr 0.0005\n",
      "Epoch[28/30](460/472) || training loss 0.1233 || training accuracy 95.47% || lr 0.0005\n",
      "Calculating validation results...\n",
      "[Val] acc : 90.34%, loss: 0.15 || best acc : 91.38%, best loss: 0.13\n",
      "\n",
      "Epoch[29/30](20/472) || training loss 0.1003 || training accuracy 96.25% || lr 0.0005\n",
      "Epoch[29/30](40/472) || training loss 0.1144 || training accuracy 96.09% || lr 0.0005\n",
      "Epoch[29/30](60/472) || training loss 0.1271 || training accuracy 95.78% || lr 0.0005\n",
      "Epoch[29/30](80/472) || training loss 0.119 || training accuracy 96.88% || lr 0.0005\n",
      "Epoch[29/30](100/472) || training loss 0.1113 || training accuracy 96.25% || lr 0.0005\n",
      "Epoch[29/30](120/472) || training loss 0.114 || training accuracy 96.88% || lr 0.0005\n",
      "Epoch[29/30](140/472) || training loss 0.09391 || training accuracy 97.34% || lr 0.0005\n",
      "Epoch[29/30](160/472) || training loss 0.09107 || training accuracy 97.19% || lr 0.0005\n",
      "Epoch[29/30](180/472) || training loss 0.1404 || training accuracy 94.84% || lr 0.0005\n",
      "Epoch[29/30](200/472) || training loss 0.1286 || training accuracy 96.09% || lr 0.0005\n",
      "Epoch[29/30](220/472) || training loss 0.1053 || training accuracy 96.25% || lr 0.0005\n",
      "Epoch[29/30](240/472) || training loss 0.09022 || training accuracy 97.03% || lr 0.0005\n",
      "Epoch[29/30](260/472) || training loss 0.08262 || training accuracy 97.50% || lr 0.0005\n",
      "Epoch[29/30](280/472) || training loss 0.08455 || training accuracy 97.97% || lr 0.0005\n",
      "Epoch[29/30](300/472) || training loss 0.1198 || training accuracy 96.09% || lr 0.0005\n",
      "Epoch[29/30](320/472) || training loss 0.08762 || training accuracy 97.03% || lr 0.0005\n",
      "Epoch[29/30](340/472) || training loss 0.09597 || training accuracy 97.03% || lr 0.0005\n",
      "Epoch[29/30](360/472) || training loss 0.08741 || training accuracy 97.03% || lr 0.0005\n",
      "Epoch[29/30](380/472) || training loss 0.09286 || training accuracy 96.88% || lr 0.0005\n",
      "Epoch[29/30](400/472) || training loss 0.1008 || training accuracy 95.62% || lr 0.0005\n",
      "Epoch[29/30](420/472) || training loss 0.09432 || training accuracy 96.09% || lr 0.0005\n",
      "Epoch[29/30](440/472) || training loss 0.0899 || training accuracy 97.66% || lr 0.0005\n",
      "Epoch[29/30](460/472) || training loss 0.127 || training accuracy 96.09% || lr 0.0005\n",
      "Calculating validation results...\n",
      "[Val] acc : 91.24%, loss: 0.13 || best acc : 91.38%, best loss: 0.13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cbe0059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "169c9b1b-17c9-482b-9960-163aa7670523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: efficientnet_pytorch in /opt/conda/lib/python3.8/site-packages (0.7.1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from efficientnet_pytorch) (1.10.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f6946e4-0423-4eb2-af25-bc555979811f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uncompress success\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    " \n",
    "try:\n",
    "    with zipfile.ZipFile(\"images.zip\") as zf:\n",
    "        zf.extractall()\n",
    "        print(\"uncompress success\")\n",
    " \n",
    "except:\n",
    "    print(\"uncompress fail\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86cb38b3-d9f9-4907-b4ce-df9a01a6d471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "Calculating inference results..\n",
      "Inference Done! Inference result saved at ./output/output.csv\n"
     ]
    }
   ],
   "source": [
    "!python inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda39a39-f5b6-4460-8a55-120db83eee21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
