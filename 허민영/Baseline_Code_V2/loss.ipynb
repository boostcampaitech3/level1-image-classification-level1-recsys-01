{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edae1378-b530-4d0e-9f3c-24f3d57e00ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# https://discuss.pytorch.org/t/is-this-a-correct-implementation-for-focal-loss-in-pytorch/43327/8\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None,\n",
    "                 gamma=2., reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob,\n",
    "            target_tensor,\n",
    "            weight=self.weight,\n",
    "            reduction=self.reduction\n",
    "        )\n",
    "\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes=3, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim) # 먼저 .log_softmax 함수를 통해 log softmax를 구함 (나중에 cross entropy loss를 계산하기 위함)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1)) # α/K\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence) # scatter_ 함수를 통해 target의 index에 해당하는 위치에 (1−α)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim)) # Log softmax와 target을 곱한 것의 음수를 취한 것이 cross entrophy loss가 됨\n",
    "\n",
    "\n",
    "# https://gist.github.com/SuperShinyEyes/dcc68a08ff8b615442e3bc6a9b55a354\n",
    "# [assert 조건] 이라 적었을 때 조건을 충족하지 않는다면 에러를 내라 할 때 사용\n",
    "# if/else문이나 try/except문처럼 조건에 해당하지 않는 경우에 대응하지 않는 이유는 '에러가 절대 나지 않는다는 확신'을 갖고 있지만 일단 저것이 맞는지 검증하기 위한 용도로 사용하기 때문임\n",
    "class F1Loss(nn.Module):\n",
    "    def __init__(self, classes=3, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.classes = classes\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "        assert y_pred.ndim == 2   \n",
    "        assert y_true.ndim == 1\n",
    "        y_true = F.one_hot(y_true, self.classes).to(torch.float32)\n",
    "        y_pred = F.softmax(y_pred, dim=1) # softmax를 통해 함수에 들어오는 값들을 0~1의 확률값으로 바꿈\n",
    "\n",
    "        tp = (y_true * y_pred).sum(dim=0).to(torch.float32) #실제값 T, 예측값 P\n",
    "        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32) #실제값 T, 예측값 N\n",
    "        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32) #실제값 F, 예측값 P\n",
    "        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32) #실제값 F, 예측값 N\n",
    "\n",
    "        precision = tp / (tp + fp + self.epsilon) #정밀도(모델이 True라고 예측한 정답 중에서 실제로 True인 비율)\n",
    "        recall = tp / (tp + fn + self.epsilon) #재현율(실제 데이터가 True인 것 중에서 모델이 True라고 예측한 비율)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + self.epsilon)\n",
    "        f1 = f1.clamp(min=self.epsilon, max=1 - self.epsilon) # 모든 요소를 [min, max]범위로 고정하여 Tensor로 출력\n",
    "        return 1 - f1.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "912b36ca-f0fe-4d06-910d-e3bec6a31951",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_criterion_entrypoints = {\n",
    "    'cross_entropy': nn.CrossEntropyLoss,\n",
    "    'focal': FocalLoss,\n",
    "    'label_smoothing': LabelSmoothingLoss,\n",
    "    'f1': F1Loss\n",
    "}\n",
    "\n",
    "\n",
    "def criterion_entrypoint(criterion_name):\n",
    "    return _criterion_entrypoints[criterion_name]\n",
    "\n",
    "\n",
    "def is_criterion(criterion_name):\n",
    "    return criterion_name in _criterion_entrypoints\n",
    "\n",
    "# **kwargs는 (키워드 = 특정 값) 형태로 함수를 호출할 수 있음. 결과값이 딕셔너리형태로 출력됨. 함수를 만들 때 키워드 인수는 가장 마지막으로 가야 함\n",
    "def create_criterion(criterion_name, **kwargs):\n",
    "    if is_criterion(criterion_name):\n",
    "        create_fn = criterion_entrypoint(criterion_name)\n",
    "        criterion = create_fn(**kwargs)\n",
    "    else:\n",
    "        raise RuntimeError('Unknown loss (%s)' % criterion_name)\n",
    "    return criterion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1455dacb-111b-4634-8f10-6e7dfbb77c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182fcc15-1892-4795-8f89-89d05b695cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8571a710-497a-4ae1-a9cf-80db6c239f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e12547-fd41-4f17-a275-c29a8a7db2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684b001e-01da-4ea5-9479-dc56fc98f6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e07ac1-28e5-4df6-a2ef-f2d470077e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3181e86a-5469-4d5b-ad92-b0746a1feac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e2c0f9-bfd7-4e29-b5d9-d78824f232eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
